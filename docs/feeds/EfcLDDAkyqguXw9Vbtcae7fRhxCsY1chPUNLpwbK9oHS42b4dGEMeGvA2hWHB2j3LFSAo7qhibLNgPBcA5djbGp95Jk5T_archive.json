{"id":"EfcLDDAkyqguXw9Vbtcae7fRhxCsY1chPUNLpwbK9oHS42b4dGEMeGvA2hWHB2j3LFSAo7qhibLNgPBcA5djbGp95Jk5T","title":"top scoring links : programming","displayTitle":"Reddit - Programming","url":"https://www.reddit.com/r/programming/top/.rss?sort=top&t=day&limit=6","feedLink":"https://www.reddit.com/r/programming/top/?sort=top&t=day&limit=6","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":6,"items":[{"title":"Engineering With ROR: Digest #8","url":"https://monorails.substack.com/p/engineering-with-ror-digest-8","date":1749424845,"author":"/u/Educational-Ad2036","guid":391,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1l6pw9q/engineering_with_ror_digest_8/"},{"title":"The Looming Problem of Slow & Brittle Proofs in SMT Verification (and a Step Toward Solving It)","url":"https://kirancodes.me/posts/log-proof-localisation.html","date":1749419861,"author":"/u/Gopiandcoshow","guid":394,"unread":true,"content":"<div><p>\nSadly, the story didn't quite end there, and when we moved to actually\ncheck the verification times of these rewritten programs, we found\nthat the programs were now failing to verify.\n</p><p>\nAs it turns out, <b>UNSAT cores are actually incomplete</b>: but not in an\nunsound way!\n</p><p>\nThe results from the SMT solver did indicate all the logically\nrelevant axioms that were needed for the proof, but it turns out that\nthis list doesn't capture all the facts that are needed for a proof to\ngo through — as it turns out, there's an entire class of additional\naxioms that I discovered that are missed: .\n</p><blockquote><p> – axioms in an SMT query that are logically irrelevant\n to the goal being proven but in practice are required for the proof\n to succeed.\n</p></blockquote><p>\nHow can this be possible? Well, it once again all comes back to our\nold friend, triggers and quantifier instantiations.\n</p><p>\nLet's go back to our program from before, but let's consider a\ndifferent set of triggers for these axioms:\n</p><div><pre><code>: , :  :: l,r = l \\/ r;\n\n:  :: l &gt; 0 = l;\n</code></pre></div><p>\nHere, we've set the trigger for the first axiom to be\n and , and the trigger for the second axiom to be\n.\n</p><p>\nNow the problem here is that if we're trying to prove the verification\ncondition from before:\n</p>\n\\begin{gather*}\nBG \\wedge (\\text{NonEmpty}(x) \\wedge \\text{NonEmpty}(y)) \\Rightarrow \\text{NonEmpty}(\\text{Append}(x,y))\n\\end{gather*}\n\n<p>\nThen the only logically relevant axiom, and the axiom that will show\nup in the UNSAT core, is axiom 1 as before. But if we try to verify\nour program with only this axiom, then verification would fail, as the\nSMT solver would never have the term  or  in its\ncontext. If we include both axioms, then axiom 2 acts as a : it gets instantiated during the proof search, and introduces a\nterm of  into the\ncontext, which can then enable the SMT solver to instantiate the\nlogically relevant one.\n</p><p>\nLong story short, if we want our proofs to go through, then it is not\nonly necessary to include the axioms in the UNSAT core in our\nlocalised programs, but we must also capture lurking axioms, but how\ncan we do this?\n</p><p>\nThis brings us to the final key idea in this work, which is to exploit\nSMT traces! SMT solvers, such as Z3, can be instructed to produce a\nlog of all the quantifier instantiations they make during the proof\nsearch – tools such as ETH-Zurich's <a href=\"https://github.com/viperproject/smt-scope\">Axiom Profiler</a> can use this\ninformation to produce a graph of all the instantiations made during\nthe proof search:\n</p><p>\nHere this graph represents the instantiations that were made in order\nto instantiate axiom 1 with x and y. The shaded boxes represent\ninstantiations of axioms, the square boxes are terms in the SMT\nsolver's context, and arrows denote dependencies between the two. From\nthe graph, we can see that in order for the logically relevant axiom\nto be instantiated, it depended on terms produced by the lurking axiom.\n</p><p>\nPutting it all together, in the final tool, alongside the axioms from\nthe UNSAT core, we extract the instantiation graph as well, and\nperform a breadth-first search to also include the necessary lurking\naxioms as well, and thereby were able to automatically rewrite Boogie\nprograms to reduce their verification times.\n</p></div>","contentLength":3134,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1l6o2ex/the_looming_problem_of_slow_brittle_proofs_in_smt/"},{"title":"Authoring an OpenRewrite recipe","url":"https://blog.frankel.ch/authoring-openrewrite-recipe/","date":1749399519,"author":"/u/nfrankel","guid":390,"unread":true,"content":"<div><p>My use case is the Kotlin package structure.\nIn Java, a class in the  package must respect a rigid folder structure: from the root, , , and then .\nIn Kotlin, you can put the same class in the same package at the root.\nThe official Kotlin documentation has recommendations on the source structure:</p></div><div><blockquote><div><p>In pure Kotlin projects, the recommended directory structure follows the package structure with the common root package omitted. For example, if all the code in the project is in the  package and its subpackages, files with the  package should be placed directly under the source root, and files in <code>org.example.kotlin.network.socket</code> should be in the network/socket subdirectory of the source root.</p></div></blockquote></div><div><p>The recipe will move the source files closer to the root packages per the above recommendation.\nWe could achieve the same with sysadmin tools such as , , or IDEs.\nWhile it could be possible to implement my idea with these tools, OpenRewrite has several benefits:</p></div><ul></ul><div><p>Before diving into the code, we must learn a bit about the API.</p></div>","contentLength":1018,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1l6g1u2/authoring_an_openrewrite_recipe/"},{"title":"Timeouts and cancellation for humans","url":"https://vorpus.org/blog/timeouts-and-cancellation-for-humans/","date":1749398986,"author":"/u/pkkm","guid":392,"unread":true,"content":"<p> code might be perfect and never fail, but unfortunately the\noutside world is less reliable. Sometimes, other people's programs\ncrash or freeze. Networks go down; printers <a href=\"https://en.wikipedia.org/wiki/Lp0_on_fire\">catch on fire</a>. Your code needs to be\nprepared for this: every time you read from the network, attempt to\nacquire an inter-process lock, or send an HTTP request, there are at\nleast three possibilities you need to think about:</p><ul><li>It might hang forever, never succeeding or failing: days pass,\nleaves fall, winter comes, yet still our request waits, yearning for\na response that will never come.</li></ul><p>The first two are straightforward enough. To handle that last case,\nthough, you need timeouts. Pretty much every place your program\ninteracts with another program or person or system, it needs a\ntimeout, and if you don't have one, that's a latent bug.</p><p>Let's be honest: if you're like most developers, your code probably\nhas  of bugs caused by missing timeouts. Mine certainly does.\nAnd it's weird – since this need is so ubiqituous, and so fundamental\nto doing I/O correctly, you'd think that every programming environment\nwould provide easy and robust ways to apply timeouts to arbitrary\noperations. But... they don't. In fact, most timeout APIs are so\ntedious and error-prone that it's just not practical for developers to\nreliably get this right. So don't feel bad – it's not your fault your\ncode has all those timeout bugs, it's the fault of those I/O\nlibraries!</p><p>But now I'm, uh, <a href=\"https://trio.readthedocs.io\">writing an I/O library</a>. And not just any I/O library, but\none whose whole selling point is that it's obsessed with being easy to\nuse. So I wanted to make sure that in my library – Trio – you can\neasily and reliably apply timeouts to arbitrary I/O operations. But\ndesigning a user-friendly timeout API is a surprisingly tricky task,\nso in this blog post I'm going to do a deep dive into the landscape of\npossible designs – and in particular the many precursors that inspired\nme – and then explain what I came up with, and why I think it's a real\nimprovement on the old state-of-the-art. And finally, I'll discuss how\nTrio's ideas could be applied more broadly, and in particular, I'll\ndemonstrate a prototype implementation for good old synchronous\nPython.</p><p>So – what's so hard about timeout handling?</p><div><p>The simplest and most obvious way to handle timeouts is to go through\neach potentially-blocking function in your API, and give it a\n argument. In the Python standard library you'll see this\nin APIs like :</p><pre>lock = threading.Lock()\n\n# Wait at most 10 seconds for the lock to become available\nlock.acquire(timeout=10)\n</pre><p>If you use the  module for networking, it works the same\nway, except that the timeout is set on the socket object instead of\npassed to every call:</p><pre>sock = socket.socket()\n\n# Set the timeout once\nsock.settimeout(10)\n# Wait at most 10 seconds to establish a connection to the remote host\nsock.connect(...)\n# Wait at most 10 seconds for data to arrive from the remote host\nsock.recv(...)\n</pre><p>This is a little more convenient than having to remember to pass in\nexplicit timeouts every time (and we'll discuss the convenience issue\nmore below) but it's important to understand that this is a purely\ncosmetic change. The semantics are the same as we saw with\n: each method call gets its own separate 10 second\ntimeout.</p><p>So what's wrong with this? It seems straightforward enough. And if we\nalways wrote code directly against these low level APIs, then it would\nprobably be sufficient. But – programming is about abstraction. Say we\nwant to fetch a file from <a href=\"https://en.wikipedia.org/wiki/Amazon_S3\">S3</a>. We might do that with\nboto3, using <a href=\"https://botocore.readthedocs.io/en/latest/reference/services/s3.html#S3.Client.get_object\">S3.Client.get_object</a>.\nWhat does  do? It makes a series of HTTP\nrequests to the S3 servers, by calling into the <a href=\"http://python-requests.org/\">requests</a> library for each one. And then each\ncall to  internally makes a series of calls to the\n module to do the actual network communication .</p><p>From the user's point of view, these are three different APIs that\nfetch data from a remote service:</p><div><pre></pre></div><p>Sure, they're at different levels of abstraction, but the whole idea\nof abstracting away such details is that the user doesn't have to\ncare. So if our plan is to use  arguments everywhere, then\nwe should expect these each to take a  argument:</p><div><pre></pre></div><p>Now here's the problem: if this is how we're doing things, then\nactually implementing these functions is a pain in the butt. Why?\nWell, let's take a simplified example. When processing HTTP response,\nthere comes a point when we've seen the  header, and\nnow we need to read that many bytes to fetch the actual response body.\nSo somewhere inside  there's a loop like:</p><div><pre></pre></div><p>Now we'll modify this loop to add timeout support. We want to be able\nto say \"I'm willing to wait at most 10 seconds to read the response\nbody\". But we can't just pass the timeout argument through to\n, because imagine the first call to  takes 6 seconds –\nnow for our overall operation to complete in 10 seconds, our second\n call has to be given a timeout of 4 seconds. With the\n approach, every time we pass between levels of\nabstraction we need to write some annoying gunk to recalculate\ntimeouts:</p><div><pre></pre></div><p>(And even this is actually simplified because we're pretending that\n takes a  argument – if you wanted to this for\nreal you'd have to call  before every socket method, and\nthen probably use some / thing to set it back or\nelse risk confusing some other part of your program.)</p><p>In practice, nobody does this – all the higher-level Python libraries\nI know of that take  arguments, just pass them through\nunchanged to the lower layers. And this breaks abstraction. For\nexample, here are two popular Python APIs you might use today, and\nthey look like they take similar  arguments:</p><div><pre></pre></div><p>But in fact these two  arguments mean totally different\nthings. The first one means \"try to acquire the lock, but give up\nafter 10 seconds\". The second one means \"try to fetch the given URL,\nbut give up if at any point any individual low-level socket operation\ntakes more than 10 seconds\". Probably the whole reason you're using\n is that you don't want to think about low-level sockets,\nbut sorry, you have to anyway. In fact it is currently  to guarantee that  will return in \nfinite time: if a malicious or misbehaving server sends at least 1\nbyte every 10 seconds, then our  call above will keep\nresetting its timeout over and over and never return.</p><p>I don't mean to pick on  here – this problem is everywhere\nin Python APIs. I'm using  as the example because Kenneth\nReitz is famous for his obsession with making its API as obvious and\nintuitive as possible, and this is one of the rare places where he's\nfailed. I think this is the only part of the requests API that gets a\n<a href=\"http://docs.python-requests.org/en/master/user/quickstart/#timeouts\">big box in the documentation warning you that it's counterintuitive</a>.\nSo like... if even Kenneth Reitz can't get this right, I think we can\nconclude that \"just slap a  argument on it\" does not lead\nto APIs fit for human consumption.</p></div><div><p>If  arguments don't work, what can we do instead? Well,\nhere's one option that some people advocate. Notice how in our\n example above, we converted the incoming relative\ntimeout (\"10 seconds from the moment I called this function\") into an\nabsolute deadline (\"when the clock reads 12:01:34.851\"), and then\nconverted back before each socket call. This code would get simpler if\nwe wrote the whole API in terms of  arguments, instead of\n arguments. This makes things simple for library\nimplementors, because you can just pass the deadline down your\nabstraction stack:</p><div><pre></pre></div><p>But this approach also has a downside: it succeeds in moving the\nannoying bit out of the library internals, and and instead puts it on\nthe person using the API. At the outermost level where timeout policy\nis being set, your library's users probably want to say something like\n\"give up after 10 seconds\", and if all you take is a \nargument then they have to do the conversion by hand every time. Or\nyou could have every function take both  and \narguments, but then you need some boilerplate in every function to\nnormalize them, raise an error if both are specified, and so forth.\nDeadlines are an improvement over raw timeouts, but it feels like\nthere's still some missing abstraction here.</p></div><div><div><p>Here's the missing abstraction: instead of supporting two different\narguments:</p><div><pre></pre></div><p>we can encapsulate the timeout expiration information into an object\nwith a convenience constructor:</p><div><pre></pre></div><p>That looks nice and natural for users, but since it uses an absolute\ndeadline internally, it's easy for library implementors too.</p><p>And once we've gone this far, we might as well make things a bit more\nabstract. After all, a timeout isn't the only reason you might want to\ngive up on some blocking operation; \"give up after 10 seconds have\npassed\" is a special case of \"give up after &lt;some arbitrary condition\nbecomes true&gt;\". If you were using  to implement a web\nbrowser, you'd want to be able to say \"start fetching this URL, but\ngive up when the 'stop' button gets pressed\". And libraries mostly\ntreat this  object as totally opaque in any case – they\njust pass it through to lower-level calls, and trust that eventually\nsome low-level primitives will interpret it appropriately. So instead\nof thinking of this object as encapsulating a deadline, we can start\nthinking of it as encapsulating an arbitrary \"should we give up now\"\ncheck. And in honor of its more abstract nature, instead of calling it\na  let's call this new thing a :</p><div><pre></pre></div><p>So promoting the cancellation condition to a first-class object makes\nour timeout API easier to use, and  makes it\ndramatically more powerful: now we can handle not just timeouts, but\nalso arbitrary cancellations, which is a very common requirement when\nwriting concurrent code. (For example, it lets us express things like:\n\"run these two redundant requests in parallel, and as soon as one of\nthem finishes then cancel the other one\".) This is a  idea. As\nfar as I know, it originally comes from Joe Duffy's <a href=\"https://blogs.msdn.microsoft.com/pfxteam/2009/05/22/net-4-cancellation-framework/\">cancellation\ntokens</a>\nwork in C#, and Go <a href=\"https://golang.org/pkg/context/\">context objects</a> are essentially the same idea.\nThose folks are pretty smart! In fact, cancel tokens also solve some\nother problems that show up in traditional cancellation systems.</p></div><div><p>In our little tour of timeout and cancellation APIs, we started with\ntimeouts. If you start with cancellation instead, then there's another\ncommon pattern you'll see in lots of systems: a method that lets you\ncancel a single thread (or task, or whatever your framework uses as a\nthread-equivalent), by waking it up and throwing in some kind of\nexception. Examples include asyncio's <a href=\"https://docs.python.org/3/library/asyncio-task.html#asyncio.Task.cancel\">Task.cancel</a>,\nCurio's <a href=\"https://curio.readthedocs.io/en/latest/reference.html#Task.cancel\">Task.cancel</a>,\npthread cancellation, Java's <a href=\"https://docs.oracle.com/javase/8/docs/api/java/lang/Thread.html#interrupt--\">Thread.interrupt</a>,\nC#'s <a href=\"https://msdn.microsoft.com/en-us/library/system.threading.thread.interrupt(v=vs.110).aspx\">Thread.Interrupt</a>,\nand so forth. In their honor, I'll call this the \"thread interrupt\"\napproach to cancellation.</p><p>In the thread-interrupt approach, cancellation is a point-in-time\n that's directed at a : one call → one\nexception in one thread/task. There are two issues here.</p><p>The problem with scale is fairly obvious: if you have a single\nfunction you'd like to call normally  you might need to cancel\nit, then you have to spawn a new thread/task/whatever just for that:</p><pre>http_thread = spawn_new_thread(requests.get, \"https://...\")\n# Arrange that http_thread.interrupt() will be called if someone\n# clicks the stop button\nstop_button.on_click = http_thread.interrupt\ntry:\n    http_response = http_thread.wait_for_result()\nexcept Interrupted:\n    ...\n</pre><p>Here the thread isn't being used for concurrency; it's just an awkward\nway of letting you delimit the scope of the cancellation.</p><p>Or, what if you have a big complicated piece of work that you want to\ncancel – for example, something that internally spawns multiple worker\nthreads? In our example above, if  spawned some\nadditional backgrounds threads, they might be left hanging when we\ncancel the first thread. Handling this correctly would require some\ncomplex and delicate bookkeeping.</p><p>Cancel tokens solve this problem: the work they cancel is \"whatever\nthe token was passed into\", which could be a single function, or a\ncomplex multi-tiered set of thread pools, or anything in between.</p><p>The other problem with the thread-interrupt approach is more subtle:\nit treats cancellation as an . Cancel tokens, on the other\nhand, model cancellation as a : they start out in the\nuncancelled state, and eventually transition into the cancelled state.</p><p>This is subtle, but it makes cancel tokens less error-prone. One way\nto think of this is the <a href=\"https://lwn.net/Articles/25137/\">edge-triggered/level-triggered distinction</a>: thread-interrupt APIs provide\nedge-triggered notification of cancellations, as compared to\nlevel-triggered for cancel tokens. Edge-triggered APIs are notoriously\ntricky to use. You can see an example of this in Python's\n<a href=\"https://docs.python.org/3/library/threading.html#threading.Event\">threading.Event</a>:\neven though it's called \"event\", it actually has an internal boolean\nstate; cancelling a cancel token is like setting an Event.</p><p>That's all pretty abstract. Let's make it more concrete. Consider the\ncommon pattern of using a / to make sure that a\nconnection is shut down properly. Here's a rather artificial example\nof a function that makes a Websocket connection, sends a message, and\nthen makes sure to close it, regardless of whether \nraises an exception: </p><div><pre></pre></div><p>Now suppose we start this function running, but at some point the\nother side drops off the network and our  call hangs\nforever. Eventually, we get tired of waiting, and cancel it.</p><p>With a thread-interrupt style edge-triggered API, this causes the\n call to immediately raise an exception, and then our\nconnection cleanup code automatically runs. So far so good. But here's\nan interesting fact about the websocket protocol: it has <a href=\"https://tools.ietf.org/html/rfc6455#section-5.5.1\">a \"close\"\nmessage</a> you're\nsupposed to send before closing the connection. In general this is a\ngood thing; it allows for cleaner shutdowns. So when we call\n, it'll try to send this message. But... in this case,\nthe reason we're trying to close the connection is because we've given\nup on the other side accepting any new messages. So now \nalso hangs forever.</p><p>If we used a cancel token, this doesn't happen:</p><div><pre></pre></div><p>Once the cancel token is triggered, then  future operations on\nthat token are cancelled, so the call to  doesn't get\nstuck. It's a less error-prone paradigm.</p><p>It's kind of interesting how so many older APIs could get this wrong.\nIf you follow the path we did in this blog post, and start by thinking\nabout applying a timeout to a complex operation composed out of\nmultiple blocking calls, then it's obvious that if the first call uses\nup the whole timeout budget, then any future calls should fail\nimmediately. Timeouts are naturally level-triggered. And then when we\ngeneralize from timeouts to arbitrary cancellations, the insight\ncarries over. But if you only think about timeouts for primitive\noperations then this never arises; or if you start with a generic\ncancellation API and then use it to implement timeouts (like e.g.\nTwisted and asyncio do), then the advantages of level-triggered\ncancellation are easy to miss.</p></div><div><p>So cancel tokens have really great semantics, and are certainly better\nthan raw timeouts or deadlines, but they still have a usability\nproblem: to write a function that supports cancellation, you have to\naccept this boilerplate argument and then make sure to pass it on to\nevery subroutine you call. And remember, a correct and robust program\nhas to support cancellation in <em>every function that ever does I/O,\nanywhere in your stack</em>. If you ever get lazy and leave it out, or\njust forget to pass it through to any particular subroutine call, then\nyou have a latent bug.</p><p>Humans suck at this kind of boilerplate. I mean, not you, I'm sure\nyou're a very diligent programmer who makes sure to implement correct\ncancellation support in every function and also flosses every day.\nBut... perhaps some of your co-workers are not so diligent? Or maybe\nyou depend on some library that someone else wrote – how much do you\ntrust your third-party vendors to get this right? As the size of your\nstack grows then the chance that everyone everywhere always gets this\nright approaches zero.</p><p>Can I back that up with any real examples? Well, consider this: in\nboth C# and Go, the most prominent languages that use this approach\nand have been advocating it for a number of years, the underlying\nnetworking primitives <em>still do not have cancel token support</em>.\nThese are like... THE fundamental operations that might hang for\nreasons outside your control and that you need to be prepared to time\nout or cancel, but... I guess they just haven't gotten around to\nimplementing it yet? Instead their socket layers support an older\nmechanism for setting <a href=\"https://msdn.microsoft.com/en-us/library/system.net.sockets.socket.receivetimeout(v=vs.110).aspx\">timeouts</a>\nor <a href=\"https://golang.org/pkg/net/#IPConn.SetDeadline\">deadlines</a> on\ntheir socket objects, and if you want to use cancel tokens you have to\nfigure out how to bridge between the two different systems yourself.</p><p>The Go standard library does provide one example of how to do this:\ntheir function for establishing a network connection (basically the\nequivalent of Python's ) does accept a cancel token.\nImplementing this requires <a href=\"https://github.com/golang/go/blob/bf0f69220255941196c684f235727fd6dc747b5c/src/net/fd_unix.go#L99-L141\">40 lines of source code</a>,\na background task, and the first try <a href=\"https://github.com/golang/go/issues/16523\">had a race condition that took a\nyear to be discovered in production</a>. So... in Go if you\nwant to use cancel tokens (or s, in Go parlance), then I\nguess that's what you need to implement every time you use any socket\noperation? Good luck?</p><p>I don't mean to make fun. This stuff is hard. But C# and Go are huge\nprojects maintained by teams of highly-skilled full-time developers\nand backed by Fortune 50 companies. If they can't get it right, who\ncan? Not me. I'm one human trying to reinvent I/O in Python. I can't\nafford to make things that complicated.</p></div></div><div><p>Remember way back at the beginning of this post, we noted that Python\nsocket methods don't take individual timeout arguments, but instead\nlet you set the timeout once on the socket so it's implicitly passed\nto every method you call? And in the section just above, we noticed\nthat C# and Go do pretty much the same thing? I think they're on to\nsomething. Maybe we should accept that when you have some data that\nhas to be passed through to every function you call, that's something\nthe computer should handle, rather than making flaky humans do the\nwork – but in a general way that supports complex abstractions, not\njust sockets.</p><div><p>Here's how you impose a 10 second timeout on an HTTP request in Trio:</p><div><pre></pre></div><div><pre></pre></div><p>But since this post is about the underlying design, we'll focus on the\nprimitive version. (Credit: the idea of using  blocks for\ntimeouts is something I first saw in Dave Beazley's Curio, though I\nchanged a bunch. I'll hide the details in a footnote: .)</p><p>You should think of  as creating a cancel\ntoken, but it doesn't actually expose any  object\npublically. Instead, the cancel token is pushed onto an invisible\ninternal stack, and automatically applied to any blocking operations\ncalled inside the  block. So  doesn't have to do\nanything to pass this through – when it eventually sends and receives\ndata over the network, those primitive calls will automatically have\nthe deadline applied.</p><p>When an operation is cancelled, it raises a  exception,\nwhich is used to unwind the stack back out to the appropriate  block. Cancel scopes can be nested; \nexceptions know which scope triggered them, and will keep propagating\nuntil they reach the corresponding  block. (As a consequence,\nyou should always let the Trio runtime take care of raising and\ncatching  exceptions, so that it can properly keep track\nof these relationships.)</p><p>Supporting nesting is important because some operations may want to\nuse timeouts internally as an implementation detail. For example, when\nyou ask Trio to make a TCP connection to a hostname that has multiple\nIP addresses associated with it, it uses a \"happy eyeballs\" algorithm\nto <a href=\"https://trio.readthedocs.io/en/latest/reference-io.html#trio.open_tcp_stream\">run multiple connections attempts in parallel with a staggered\nstart</a>.\nThis requires an <a href=\"https://github.com/python-trio/trio/blob/d063d672de15edc231b14c0a9bc3673e5275a9dc/trio/_highlevel_open_tcp_stream.py#L260-L265\">internal timeout</a>\nto decide when it's time to initiate the next connection attempt. But\nusers shouldn't have to care about that! If you want to say \"try to\nconnect to , but give up after 10 seconds\", then\nthat's just:</p><div><pre></pre></div><p>And everything works; thanks to the cancel scope nesting rules, it\nturns out  handles this correctly with no\nadditional code.</p></div><div><p>Writing code that's correct in the face of cancellation can be tricky.\nIf a  exception were to suddenly materialize in a place\nthe user wasn't prepared for it – perhaps when their code was half-way\nthrough manipulating some delicate data structure – it could corrupt\ninternal state and cause hard-to-track-down bugs. On the other hand, a\ntimeout and cancellation system doesn't do much good if you don't\nnotice cancellations relatively promptly. So an important challenge\nfor any system is to first pick a \"goldilocks rule\" that checks often\nenough, but not too often, and then somehow communicate this rule to\nusers so that they can make sure their code is prepared.</p><p>In Trio's case, this is pretty straightforward. We already, for other\nreasons, use Python's async/await syntax to annotate blocking\nfunctions. The main thing does is let you look at the text of any\nfunction and immediately see which points might block waiting for\nsomething to happen. Example:</p><div><pre></pre></div><p>Here we can see that the call to  blocks, because it has\nthe special  keyword. You can't call  – or any\nother of Trio's built-in blocking primitives – without using this\nkeyword, because they're marked as async functions. And then Python\nenforces that if you want to use the  keyword, then you have\nto mark the calling function as async as well, which means that all\n of  will also use the \nkeyword. This makes sense, since if  calls a\nblocking function, that makes it a blocking function too. In many\nother systems, whether a function might block is something you can\nonly determine by examining all of its potential callees, and all\ntheir callees, etc.; async/await takes this global runtime property\nand makes it visible at a glance in the source code.</p><p>Trio's cancel scopes then piggy-back on this system: we declare that\nwhenever you see an , that's a place where you might have to\nhandle a  exception – either because it's a call to one\nof Trio's primitives which directly check for cancellation, or because\nit's a call to a function that indirectly calls one of those\nprimitives, and thus might see a  exception come bubbling\nout. This has several nice properties. It's extremely easy to explain\nto users. It covers all the functions where you absolutely need\ntimeout/cancellation support to avoid infinite hangs – only functions\nthat block can get stuck blocking forever. It means that any function\nthat does I/O on a regular basis also automatically checks for\ncancellation on a regular basis, so most of the time you don't need to\nworry about this (though for the occasional long-running pure\ncomputation, you may want to add some explicit cancellation checks by\ncalling  – which you have to do anyway to let\nthe scheduler work!). Blocking functions tend to have a <a href=\"https://docs.python.org/3/library/exceptions.html#os-exceptions\">large variety\nof failure modes</a>,\nso in many cases any cleanup required to handle \nexceptions will be shared with that needed to handle, for example, a\nmisbehaving network peer. And Trio's cooperative multi-tasking system\nalso uses the  points to mark places where the scheduler\nmight switch to another task, so you already have to be careful about\nleaving data structures in inconsistent states across an .\nCancellation and async/await go together like peanut butter and\nchocolate.</p></div><div><p>While checking for cancellation at all blocking primitive calls makes\na great default, there are some very rare cases where you want to\ndisable this and take explicit control over cancellation. They're so\nrare that I don't have a simple example to use here (though there are\na few arcane examples in the Trio source that you can grep for if\nyou're really curious). To provide this escape hatch, you can set a\ncancel scope to \"shield\" its contents from outside cancellations. It\nlooks like this:</p><div><pre></pre></div><p>To support composition, shielding is sensitive to the cancel scope\nstack: it only blocks outer cancel scopes from applying, and has no\neffect on inner scopes. In our example above, our shield doesn't have\nany affect on any cancel scopes that might be used  – those still behave normally. Which is good, because\nwhatever  does internally is its own private\nimplementation detail. And in fact, <a href=\"https://github.com/python-trio/trio/blob/07d144e701ae8ad46d393f6ca1d1294ea8fc2012/trio/_timeouts.py#L65-L66\">use a\ncancel scope internally</a>!\n</p><p>One reason that  is an attribute on cancel scopes instead of\nhaving a special \"shield scope\" is that it makes it convenient to\nimplement this kind of nesting, because we can re-use cancel scope's\nexisting stack structure. The other reason is that anywhere you're\ndisabling external timeouts, you need to think about what you're going\nto do instead to make sure things can't hang forever, and having a\ncancel scope right there makes it easy to apply a new timeout that's\nunder the local code's control:</p><div><pre></pre></div><p>Now if you're a Trio user please forget you read this section; if you\nthink you need to use shielding then you almost certainly should\nrethink what you're trying to do. But if you're an I/O runtime\nimplementer looking to add cancel scope support, then this is an\nimportant feature.</p></div><div><p>Finally, there's one more feature of Trio that should be mentioned\nhere. So far in this essay, I haven't discussed concurrency much at\nall; timeouts and cancellation are largely independent, and everything\nabove applies even to straightforward single-threaded synchronous\ncode. But we did make some assumptions that might seem trivial: that\nif you call a function inside a  block, then (a) the execution\nwill actually happen inside the  block, and (b) any exceptions\nit throws will propagate back to the  block so it can catch\nthem. Unfortunately, many threading and concurrency libraries violate\nthis, specifically in the case where some work is spawned or\nscheduled:</p><div><pre></pre></div><p>If we were only looking at the  block alone, this would seem\nperfectly innocent. But when we look at how  is\nimplemented, we realize that it's likely that we'll exit the \nblock before the background task finishes, so there's some ambiguity:\nshould the timeout apply to the background task or not? And then if it\ndoes apply, then how should we handle the  exception? For\nmost system, unhandled exceptions in background threads/tasks are\nsimply discarded.</p><p>However, these problems don't arise in Trio, because of its unique\napproach to concurrency. Trio's <a href=\"https://trio.readthedocs.io/en/latest/reference-core.html#tasks-let-you-do-multiple-things-at-once\">nursery system</a>\nmeans that child tasks are always integrated into the call stack,\nwhich effectively becomes a call tree. Concretely, the way this is\nenforced is that Trio has no global \nprimitive; instead, if you want to spawn a child task, you have to\nfirst open a \"nursery\" block (for the <a href=\"http://www.dictionary.com/browse/nursery\">child to live in</a>, get it?), and then the\nlifetime of that child is tied to the  block that created the\nnursery:</p><div><pre></pre></div><p>This system has many advantages, but the relevant one here is that it\npreserves the key assumptions that cancel scopes rely on. Any given\nnursery is either inside or outside the cancel scope – we can tell by\nchecking whether the  block encloses the\n block. And then it's straightforward to\nsay that if a nursery is inside a cancel scope, then that scope should\napply to all children in that nursery. This means that if we apply a\ntimeout to a function, it can't \"escape\" by spawning a child task –\nthe timeout applies to the child task too. (The exception is if you\npass an outside nursery into the function, then it can spawn tasks\ninto that nursery, which can escape the timeout. But then this is\nobvious to the caller, because they have to provide the nursery – the\npoint is to make it clear what's going on, not to make it impossible\nto spawn background tasks.)</p></div><div><p>Returning to our initial example: I've been doing some initial work on\nporting  to run on Trio (<a href=\"https://github.com/python-trio/urllib3/issues/1\">you can help!</a>), and so far it\nlooks like the Trio version will not only handle timeouts better than\nthe traditional synchronous version, but that it will be able to do\nthis using  – all the places where you'd want to\ncheck for cancellation are the ones where Trio does so automatically,\nand all the places where you need special care to handle the resulting\nexceptions are places where  is prepared to handle\narbitrary exceptions for other reasons.</p><p>There are no free lunches; cancellation handling can still be a source\nof bugs, and requires care when writing code. But Trio's cancel scopes\nare dramatically easier to use – and therefore more reliable – than\nany other system I've found. Hopefully we can make timeout bugs the\nexception rather than the rule.</p></div></div><div><p>So... that's great if you're using Trio. Is this something that only\nworks in Trio's context, or is it more general? What kind of\nadaptations would need to be made to use this in other environments?</p><p>If you want to implement cancel scopes, then you'll need:</p><ul><li>Some kind of implicit context-local storage to track the cancel\nscope stack. If you're using threads, then thread-local storage\nworks; if you're using something more exotic, then you'll need to\nfigure out the equivalent in your system. (So for example, in Go\nyou'd need goroutine-local storage, which famously <a href=\"https://stackoverflow.com/questions/31932945/does-go-have-something-like-threadlocal-from-java\">doesn't exist</a>.)\nThis can be a bit tricky; for example in Python, we need something\nlike <a href=\"https://www.python.org/dev/peps/pep-0568/\">PEP 568</a> to iron\nout some bad interactions <a href=\"https://github.com/python-trio/trio/issues/264\">between cancel scopes and generators</a>.</li><li>A way to delimit the boundaries of a cancel scope. Python's \nblocks work great; other options would include dedicated syntax, or\nrestricting cancel scopes to individual function calls like\n (though this could force\nawkward factorings, and you'd need to figure out some way to expose\nthe cancel scope object).</li><li>A strategy for unwinding the stack back to the appropriate cancel\nscope after a timeout/cancellation occurs. Exceptions work great, so\nlong as you have a way to catch them at cancel scope boundaries –\nthis is another reason that Python's  blocks work so well\nfor this. But if your language uses, say, error code returns instead\nof exceptions, then I'm sure you could build some stack unwinding\nconvention out of those.</li><li>A story for how cancel scopes integrate with your concurrency API\n(if any). Of course the ideal is something like Trio's nursery\nsystem (which also has many other advantages, but that's a whole\n'nother blog post). But even without that, you could for example\ndeem that any new tasks spawned inside a cancel scope inherit that\ncancel scope, regardless of when they finish. (Unless they opt out\nusing something like the shielding feature.)</li><li>Some rule to determine which operations are cancellable and\ncommunicate that to the user. As noted above, async/await works\nperfectly for this, but if you aren't using async/await then other\nconventions are certainly possible. Languages with rich static type\nsystems might be able to exploit them somehow. Worst case you could\njust be careful to document it on each function.</li><li>Cancel scope integration for all of the blocking I/O primitives you\ncare about. This is reasonably straightforward if you're building a\nsystem from scratch. Async systems have an advantage here because\nintegrating everything into an event loop already forces you to\nreimplement all your I/O primitives in some uniform way, which gives\nyou an excellent opportunity to add uniform cancellation handling at\nthe same time.</li></ul><div><p>Our original motivating examples involved , an ordinary\nsynchronous library. And pretty much everything above applies equally\nto synchronous or concurrent code. So I think it's interesting to\nexplore the idea of using these in classic synchronous Python. Maybe\nwe can fix  so it doesn't have to apologize for its\n argument!</p><p>There are a few limitations we'll have to accept:</p><ul><li>It won't be ubiquitous – libraries will have to make sure that they\nonly use \"scope-enabled\" blocking operations. Perhaps in the long\nrun we could imagine this becoming part of the standard library and\nintegrated into all the standard primitives, but even then there\nwill still be third-party extension libraries that do their own I/O\nwithout going through the standard library. On the other hand, a\nlibrary like  can be careful to only use scope-enabled\nlibraries, and then document that it itself is scope-enabled. (This\nis perhaps the biggest advantage an async library like Trio has when\nit comes to timeouts and cancellation: being async doesn't make a\ndifference per se, but an async library is forced to reimplement all\nthe basic I/O primitives to integrate them into its I/O loop; and if\nyou're reimplementing everything , it's easy to make\ncancellation support consistent.)</li><li>There's no marker like  to show which operations are\ncancellable. This means that users will have to take somewhat more\ncare and check the documentation for individual functions – but\nthat's still less work then what it currently takes to make timeouts\nwork right.</li><li>Python's underlying synchronous primitives generally only support\ncancellation due to timeouts, not arbitrary events, so we probably\ncan't provide a  operation. But this\nlimitation doesn't seem too onerous, because if you have a\nsingle-threaded synchronous program and the single thread is stuck\nin some blocking operation, then who's going to call \nanyway?</li></ul><p>Summing up: it can't be quite as nice as what Trio provides, but it'd\nstill be pretty darn useful, and certainly nicer than what we have\nnow.</p></div><div><p>One of the original motivations for this blog post was talking to\n<a href=\"https://github.com/1st1\">Yury</a> about whether we could retrofit any\nof Trio's improvements back into asyncio. Looking at asyncio through\nthe lens of the above analysis, a few things jump out at us:</p><ul><li>There's some impedence mismatch between the cancel scope model of\nimplicit stateful arbitrarily-scale cancel tokens, and asyncio's\ncurrent task-oriented, edge-triggered cancellation (and then the\ns layer has a slightly different cancellation model\nagain), so we'd need some story for how to meld those together. Or\nmaybe it would be possible to migrate s to a stateful\ncancellation model?</li><li>Without nurseries, there's no reliable way to propagate cancellation\nacross tasks, and there are a lot of different operations that are\nsort of like spawning a task but at a different level of abstraction\n(e.g. ). You could have a rule that any new tasks\nalways inherit their spawner's cancel scopes, but I'm not sure\nwhether this would be a good idea or not – it needs some thought.</li><li>Without a generic mechanism for propagating exceptions back up the\nstack, there's no way to reliably route  exceptions\nback to the original scope; generally asyncio simply prints and\ndiscards unhandled exceptions from s. Maybe that's fine?</li></ul><p>Unfortunately asyncio's in a bit of a tricky position, because it's\nbuilt on an architecture derived from the previous decade of\nexperience with async I/O in Python... and then after that\narchitecture was locked in, it added new syntax to Python that\ninvalidated all that experience. But hopefully it's still possible to\nadapt some of these lessons – at least with some compromises.</p></div><div><p>If you're working in another language, I'd love to hear how the cancel\nscope idea adapts – if at all. For example, it'll definitely need some\nadjustment for languages that don't use exceptions, or that are\nmissing the kind of user-extensible syntax that Python's \nblocks provide.</p></div></div>","contentLength":34786,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1l6fubf/timeouts_and_cancellation_for_humans/"},{"title":"7 years of development: discipline in software engineering","url":"https://www.fossable.org/projects/sandpolis/7-years-of-development/","date":1749392725,"author":"/u/fossable","guid":395,"unread":true,"content":"<p><a href=\"https://github.com/fossable/sandpolis/commit/0422e1a3f0b3c28b9305d52e6181f1b5e3d22c88\">June 7th 2025</a>\nmarks 7 long years of development on\n<a href=\"https://github.com/fossable/sandpolis\">Sandpolis</a>, an attempt to build the\nultimate remote administration/management tool for sysadmins like you and me.</p><p>For 7 years I thought about and/or worked on this project almost daily, and yet\nit's still nowhere near being finished, not even MVP-level. Am I the worst\nsoftware developer ever to touch a keyboard?</p><p>Quite a few things happened in the last 7 years: college, a job, a wife, a\nhouse, a child, a full rewrite from Java to Rust...</p><p>... is what I would have said, but I now realize those are shallow excuses.</p><p>What's slowing down this project is a critical quality that's becoming as scarce\nas  in software engineering: .</p><h2>Discipline in the software engineering discipline</h2><p>If your project is fueled by necessity, curiosity, or excitement alone, it's\nunlikely to reach 100%.</p><p>That's primarily what motivated these last 7 years of development on Sandpolis.\nI'd have a satisfying streak of progress in some interesting area until I got\nstuck. And since solving hard problems is hard, I'd jump to somewhere else and\nrepeat.</p><p>Unlike other crafts, in software engineering, it really is possible to build the\nroof before you finish building the walls. And, as if this was Minecraft, it's\nalso possible to build that roof so it doesn't even eventually line up with the\nwalls.</p><p>Nevertheless, at one point in 2019, I had an application that technically\nworked. The server side was entirely Java (~50K lines) with a cute little iOS\nfrontend app in Swift (~10K lines). Let's admire it for a second:</p><p>Back then, I thought Java was quite alright. Modern features made the language\ndecently comfortable. I don't remember exactly what prompted it, but at some\npoint, I decided to rewrite everything in Rust - probably a case of cosmic rays\nin my brain, much like in my code.</p><p>So, while my curiosity took me down an exciting new path with the most hyped\nlanguage of the decade, I no longer had a working application (a grievous\nmistake). Rewrites are extremely costly and rarely the right answer. By that\npoint, I was experienced enough to know better, but I let the decision make\nitself instead of taking a strategic path.</p><p>Since this was just a side project, I usually worked on the fun stuff over the\nhard stuff. After a while, what you're left with is a project full of holes.\nParts of it are certainly nicely done, but if it's not possible to unite those\npieces into a working whole, you can't get off the launchpad.</p><p> is what unites a project into a working whole. It's what allows you\nto solve the hard problems. It's what keeps you on a path going forward when\ntemptations arise.</p><p>Surely there are some people out there with a side project that they enjoy\ncoding just for the sake of coding, but I always aspired to make my programs\nactually do something useful. Maybe even something that no one else has ever\ndone before.</p><p>Now that AI development tools are here to stay, discipline in software\nengineering is more important than ever. It's just a classic problem reframed:</p><ul><li>Why remember directions when the GPS is always right?</li><li>Why learn long division when everyone has a calculator within arms reach?</li><li>Why practice handwriting when we type almost everything?</li></ul><p>The general reason in all of those cases, and likewise in software engineering,\nis doing those things leads to  (sometimes of things you wouldn't\nexpect). Which is something that AIs don't, and maybe can't, have.</p><p> is what causes you to do the things that lead to long-term\nunderstanding, even when a shortcut is right in front of you.</p><p>I'm not suggesting you uninstall copilot and stop prompting ChatGPT for code,\nbut I am saying it's extremely easy to mistakenly take it too far.</p><h2>How to practice discipline when coding</h2><p>In general, do the highest priority thing until it's 100% done, even when it's\nnot the most enjoyable part.</p><h3>Don't let problems on the critical path leave your L1 cache</h3><p>For example, the data model in Sandpolis is critical for everything else to\nwork. When I got stuck on this hard problem early on, I diverted my attention to\nother aspects that weren't as important like how user passwords are handled to\navoid <a href=\"https://shuck.sh/\">hash shucking attacks</a>.</p><p>Sometimes when I'm stuck on a problem, I can work on something else in the\nmeantime and a solution to my original problem suddenly presents itself, as if\nmy unconscious brain was thinking about it the whole time. Once a problem leaves\nyour L1 cache because you haven't thought about it in a while, you're no longer\nmaking progress on it. In fact, it's the opposite of progress because you slowly\nstart to lose context which will take effort to regain.</p><p>That's why it's best to mostly stay on the critical path than to hop around.\nIt's OK to do some side quests here and there, but don't let them subvert the\nmain questline.</p><h3>Minimize the length of time the software is broken</h3><p>To make real improvements in software, you usually have to break things first.\nThe longer it takes to get your application compiling or running again, the more\ncostly the improvement becomes. Once a change starts taking weeks, the full\ncontext becomes hard to keep in your L1 cache and the probability of\n increases.</p><p>I'm a repeat offender when it comes to this. I've made many fundamental\nimprovements very low in the stack that affects basically everything, but I've\nfailed to propagate that change completely for a long time, usually due to some\ndifficult edge case that I didn't think about initially.</p><p>As a corollary, don't get tempted to rewrite so easily. Rewriting is the\nultimate form of breaking your software. My favorite discussion on why rewriting\nis bad is Spolsky's\n<a href=\"https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/\">Things You Should Never Do. Part I</a>.</p><p>Usually, both in software and in life, it's better to pay now rather than pay\nlater. It's going to cost much more time and energy to change a function\nprototype after it has hundreds of call sites than when it has none or just a\nfew. In other words, <em>do it right or do it again</em>.</p><p>It takes experience to predict what's going to be worth paying your time into in\nthe future and what will be a waste when it becomes quickly irrelevant. Of\ncourse, it's still important to have a healthy amount of YAGNI (you ain't gonna\nneed it) to stay working on the things that actually matter.</p><p>As an aside, you can combine \"pay later\" with the witty \"later is never\" quip to\nderive: \"pay never\", which sounds like a sweet deal until you realize that it\nturns your software into concrete over time - impossible to change without a\njackhammer.</p><p>For the rest of the year, I'm going to focus on perfecting the data model in\nSandpolis. When I accomplish that, I'll have momentum to move onto other (more\ninteresting) features.</p><p>Look forward to a very different 8th year anniversary post!</p>","contentLength":6663,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1l6dem0/7_years_of_development_discipline_in_software/"},{"title":"Probably Faster Than You Can Count: Scalable Log Search with Probabilistic Techniques · Vega Security Blog","url":"https://blog.vega.io/posts/probabilistic_techniques/","date":1749388033,"author":"/u/Duckuks","guid":393,"unread":true,"content":"<p>Imagine you want to build a system that needs to search through petabytes of log data, with new logs streaming in at multiple terabytes per day. Using traditional data structures and <a href=\"https://en.wikipedia.org/wiki/Exact_algorithm\" target=\"_blank\">exact algorithms</a> it’s hard to keep up with the pressure of such scale. Database indices grow unwieldy, memory requirements explode, and query times stretch from milliseconds to minutes or even hours. When working at this scale, the pursuit of 100% precision can become your worst enemy.</p><p>Following up on our exploration of log search engines in <a href=\"https://blog.vega.io/posts/log_search_engines/\" target=\"_blank\">“Search Logs Faster than Sonic”</a>, it’s time to introduce a class of solutions that isn’t very common in the standard software engineer’s toolbox but shines best at extreme scale: probabilistic data structures and approximation algorithms.</p><p>These tools aren’t just a part of theoretical computer science. They’re working behind the scenes in systems you likely use every day. Redis, ElasticSearch, ClickHouse rely on them to optimize lookups and provide estimations in queries that would otherwise crash the servers or take forever to complete.</p><p>The basic idea is simple, there is a trade-off between accuracy and performance. Sometimes a small compromise on accuracy can results in massive performance gains while still producing a sufficient result. Instead of keeping track of everything exactly (which gets expensive fast), these structures / algorithms maintain a good-enough approximation that requires far less memory and processing time. It’s like estimating the number of rubber ducks I have in my collection instead of counting each one – you might be off by a few, but you’ll get a good-enough answer fast, without searching for the ones my cats have “sharded” across the apartment.</p><p>Let’s explore how these techniques can help process massive amounts of logs without breaking your infrastructure budget.</p><h2>The Challenge of Data Sharding \n    </h2><p>When working with massive datasets, high-scale systems often split data into smaller, more manageable horizontal partition of data called <a href=\"https://en.wikipedia.org/wiki/Shard_%28database_architecture%29\" target=\"_blank\">shards</a>.</p><p>When you want to query this data, you need to know which shards contain relevant information. Otherwise, you’re forced to read from all of them leading to many expensive io operations whether the shards should be read from disk or over network (e.g. from s3).</p><p>The simplest pruning approach is time-based filtering. Each shard tracks its minimum and maximum timestamps:</p><pre tabindex=\"0\"><code>Shard_1: 2023-01-01T00:00:00Z to 2023-01-01T06:00:00Z\nShard_2: 2023-01-01T03:00:00Z to 2023-01-01T09:00:00Z\nShard_3: 2023-01-01T06:00:00Z to 2023-01-01T12:00:00Z\n...\n</code></pre><p>When a query comes in requesting data for a specific timeframe:</p><pre tabindex=\"0\"><code data-lang=\"kql\">@Table\n| where timestamp &gt; '2023-01-01T07:00:00Z'\n</code></pre><p>We can immediately eliminate  from consideration.\nThis concept is widely used, for example elasticsearch organizes data into time-based indices and shards within those indices, ClickHouse partitions tables by date ranges and S3-based data lakes organize files into prefixes and time-based partitions.</p><p>But what about other filter conditions? Consider this simple query:</p><pre tabindex=\"0\"><code data-lang=\"kql\">@Table\n| where source.ip = \"192.168.1.1\" AND timestamp &gt; '2023-01-01T07:00:00Z'\n</code></pre><p>Time-based pruning helps with the timestamp condition, but we still need to check all remaining shards for the specific IP.</p><p>A naive approach might be to maintain an exact index of all values for each field using a hashmap. The shard can be skipped if the filtered value isn’t present:</p><pre tabindex=\"0\"><code>Shard_2 contains:\n  source.ip: {\"192.168.1.1\", \"10.0.0.1\", ... 10,000s more IPs}\n</code></pre><p>The problem is for high-cardinality fields like user IDs, request paths or if you’re really unlucky some uuid as storing and checking complete value lists consumes enormous amounts of memory and processing time.</p><p>A Bloom filter solves this by providing a memory efficient way to answer a simple question: “Could this value exist in this shard?” It can tell you with certainty when something is NOT in the dataset (no false-negative), while occasionally producing false positives.</p><p>You can think of Bloom filters like trying to guess what your coworker is heating up in the office microwave just by the smell, so you know if it’s worth asking for a bite.\nSmells carry less information than the full dish, but if you recognize the scent of leftover fried chicken, you can usually make a decent guess.\nThe problem is that scents can overlap so you might think it’s fried chicken, but it’s actually reheated chicken nuggets 😕 (that’s a false positive).\nBut if none of the familiar smells are present, you know for sure it’s not what you’re hoping for (no false negatives).</p><p>Here’s how a Bloom filter works:</p><ul><li>Start with a bit array of  bits, all initially set to 0</li><li>Choose  different hash functions (scents) that each map an input to one of the  array positions</li><li>To add an element, run it through all  hash functions to get  array positions, then set all those positions to 1</li><li>To check if an element exists, run it through all  hash functions to get  positions\nIf ALL positions contain a 1, the element is PROBABLY in the set (it could be a false positive due to hash collisions)</li><li>Otherwise, the element is DEFINITELY not in the set.</li></ul><p>What I like about Bloom filters is that both adding and searching are done in a time-complexity which doesn’t depend on the data, it depends solely on the number of chosen hash function  which of-course affect the false positive rate.\nSo you can control the trade-off between memory usage and false positive rate!\nThe probability of a false positive is approximately:</p><p>$$\np ≈ (1 - e^(\\frac{-kn}{m}))^k\n$$</p><ul><li> is the size of the bit array</li><li> is the number of elements in the set</li><li> is the number of hash functions</li></ul><p>So for our use case, for each shard and each “relevant” field (we’ll touch on when to avoid Bloom filters later on) in the table’s schema, we can maintain a separate Bloom filter that tracks all values for that field in that shard.\nThis lets us quickly eliminate shards that definitely don’t contain our target values.</p><p>So let’s say you estimate a particular field will have  in a shard of data and you’re willing to retrieve shards without relevant data (false positives) at a rate of \\(1\\%\\).\nYou would need approximately:</p><p>$$\nm = -\\frac{n \\cdot \\ln(p)}{(\\ln 2)^2}\n= -\\frac{1000 \\cdot \\ln(0.01)}{(\\ln 2)^2}\n\\approx 9585 \\text{ Bits} \\approx 1198 \\text{ Bytes} \\approx 1.17 \\text{ KB}\n$$</p><p>And you would need approximately:\n$$\nk = \\frac{m}{n} \\cdot \\ln 2\n= \\frac{9585}{1000} \\cdot \\ln 2\n\\approx 6.64 = 7 \\text{ hash functions}\n$$</p><p>The point is that this is dramatically more space-efficient than storing the complete set of elements.\nHere’s a simple implementation:</p><div><pre tabindex=\"0\"><code data-lang=\"rust\"></code></pre></div><p>As I mentioned you can find them everywhere, for example:</p><ul><li><a href=\"https://lucene.apache.org/core/4_5_0/codecs/org/apache/lucene/codecs/bloom/BloomFilteringPostingsFormat.html\" target=\"_blank\">Elasticsearch</a> is based on Apache Lucene search which uses Bloom filters in engine for efficient term lookups.</li><li><a href=\"https://cassandra.apache.org/doc/4.1/cassandra/operating/bloom_filters.html\" target=\"_blank\">Cassandra</a> uses Bloom filters to avoid checking every SSTable data file for the partition being requested.</li><li><a href=\"https://clickhouse.com/docs/en/optimize/skipping-indexes\" target=\"_blank\">ClickHouse</a> uses Bloom filters them to skip indexes.</li><li><a href=\"https://grafana.com/blog/2024/04/09/grafana-loki-3.0-release-all-the-new-features/#query-acceleration-with-bloom-filters\" target=\"_blank\">Loki</a> uses Bloom filters to accelerate queries by skipping irrelevant logs as well.</li></ul><h2>When Bloom Filters Fall Short \n    </h2><p>Bloom filters shine when you’re looking for something specific and rare, the classic “needle in a haystack” scenario. But they quickly lose their edge when that needle becomes a recurring pattern.</p><p>A classic example is multi-tenancy. When handling logs from many tenants, it’s common to have a  field. In that case most queries if not all will filter on a specific :</p><pre tabindex=\"0\"><code data-lang=\"kql\">@AuthLogs\n| where tenant_name = 'ducks-corp'\n...\n</code></pre><p>As mentioned earlier, shards are often partitioned by time ranges so that we could skip irrelevant data when filtering by timestamp. The problem is that logs from many tenants are usually mixed together across time so their logs are likely to show up in almost every shard. That means a Bloom filter on  will be pretty useless as it will return “maybe” for almost every shard and we’ll still need to scan all of them.</p><p>The  example is a pretty extreme case, let’s take a proper example, say you’re hunting for activity related to a single user “ducker”</p><pre tabindex=\"0\"><code data-lang=\"kql\">@AuthLogs\n| where actor.username == \"ducker\" and timestamp &gt; ago(7d)\n</code></pre><p>You’re in a large organization:</p><ul><li>1TB worth of data is ingested per day.</li><li>Authentication logs make up about 5% of the total → 50 GB/day.</li><li>Each log entry averages around 1 KB → roughly 50 million  entries per day.</li><li>Each shard contains about 1 million entries → 50 shards per day.</li></ul><p>Now assuming our suspect  appears in just  of the logs, that’s 10,000 logs total per day.\n<em>Note that  may be a power IT user that is shared across many people or a user that is being used by some automation.</em>\nIf the data is  then each shard has 200 matching entries. Under a , the chance of a shard having zero matches is:\n$$\nP(\\text{no match}) = (1 - 0.0002)^{1,000,000} \\approx 1.35^{-87}\n$$\nIn both cases, Bloom filters mark every shard as a “maybe”, offering no pruning.\nIt’s important to note that although having large shards have their benefits, the larger the shard the more likely that even low-frequency value will appear at least once. So basically it will be much harder for Bloom filters to prune any shard…</p><p>So now we understand that Bloom filters are optimized for infrequent matches. When the match rate is high, the bit array becomes saturated.</p><p><strong>A More General Rule of Thumb</strong>\nBloom filters become ineffective when:</p><ul><li>The value you’re searching for is not rare so it <strong>appears frequently across many shards</strong>.</li><li>Each shard is  that even rare terms still appear often.</li><li>The field being filtered has , e.g. categorical field like  or .</li></ul><p>So before reaching for a Bloom filter, consider: how rare is the thing you’re looking for? If the answer is “not very” you may just be wasting CPU cycles hashing your way to scanning most of the shards anyway…</p><h3>Alternative Approach: Data Partitioning \n    </h3><p>A simple solution for fields that are too common for Bloom filters is to partition your data by the values of those fields. Instead of probabilistic filtering, you group data by field values into separate shards.</p><p>Going back to our  example, partitioned shards would look like:</p><pre tabindex=\"0\"><code>Shard_1: tenant=ducks-corp, 2023-01-01T00:00:00Z to 2023-01-01T06:00:00Z\nShard_2: tenant=ducks-inc , 2023-01-01T00:00:00Z to 2023-01-01T06:00:00Z\n...\n</code></pre><p>Now when you query <code>| where tenant_name == \"ducks-inc\"</code>, the system only needs to scan shards tagged with . It can skip everything else no probabilistic guessing needed.</p><p>This approach works best for  fields with a small, fixed number of possible values like tenant names, regions, or event types. Partitioning by high-cardinality fields like user IDs or UUIDs would create too many tiny shards, making the search operation inefficient (we will probably cover shard merging in a future post).</p><h2>Beyond Membership: What Else Can We Prune? \n    </h2><p>Here’s a challenge: what about the following query which a Bloom filters can’t handle at all?</p><pre tabindex=\"0\"><code data-lang=\"kql\">@AuthLogs\n| where FailedAttempts &gt; 10\n</code></pre><p>Think about it for a moment. Bloom filters are designed for exact membership testing (“is X in the set?”), but this query asks “show me all of the logs with a value greater than 10.” How would you skip irrelevant shards?</p><p><em>Hint: Just like Bloom filters, you would need to store some metadata about the numeric values in a shard.</em></p><p>The answer: for each numeric field, store the  range:</p><pre tabindex=\"0\"><code>Shard_1: FailedAttempts: min=0, max=5\nShard_2: FailedAttempts: min=3, max=15\nShard_3: FailedAttempts: min=12, max=25\n</code></pre><p>Now  can immediately skip Shard_1 (max=5), while  can skip Shard_3 (min=12).</p><p>Here’s another puzzle, what about this query?</p><pre tabindex=\"0\"><code data-lang=\"kql\">@AuthLogs\n| where UserAgent contains \"Chrome/91\"\n</code></pre><p>How would you efficiently skip shards that definitely don’t contain that substring? Bloom filters work for exact matches, but substring searches are trickier…</p><p>Throughout our examples, we’ve made an important assumption that’s worth calling out: . Once written, they don’t change. This assumption breaks down when you need to update or delete data, which brings us to our next topic.</p><h3>Cuckoo Filters: When Elements Need to Leave the Nest \n    </h3><p>Bloom filters have one big limitation: they don’t forget. Once you add an element, you can’t remove it, because different elements might “share” the same bits. Clearing bits for one element could accidentally wipe out another leading to .\nOne workaround is to use a , which maintains a counter for each bit position rather than a single bit. When adding an element, you increment the counters; when removing, you decrement them. An element exists if all its positions have counts greater than zero. But this comes at a cost, as each position now requires multiple bits to store the counter.</p><p>That’s where Cuckoo filters come in as a more elegant alternative, named after the cuckoo bird’s charming habit of tossing other birds eggs out of the nest.\nUnlike Bloom filters, which use a bit array, Cuckoo filters use a fixed-size hash table to store fingerprints: small, fixed-size representations of the original items. Each fingerprint has two possible “homes” in the table, determined by hash functions. When both are full, the filter evicts an existing fingerprint to its alternate location, just like the cuckoo evicts its nest-mates, and repeats this process until it finds space.</p><p>Instead of a bit array, Cuckoo filters use a fixed-size hash table that stores short “fingerprints”, which are small hashes derived from the inserted values. These fingerprints are much shorter than the original items, which helps save space. Each fingerprint has two possible positions in the table, chosen using two different hash functions. If both positions are already occupied, the filter selects one of the existing fingerprints, evicts it (just like the cuckoo evicts its nest-mates) and moves it to its alternate location. If that spot is also full, the process continues by evicting again until an empty slot is found or the filter gives up after a fixed number of attempts.</p><p>Because each fingerprint is tied to a specific spot, deletion is possible by simply removing it the fingerprint if you find it in one of the expected slots.</p><ul><li>Deletion of elements (ideal for expiring old data)</li><li>Lower false positive rates compared to Bloom filters</li><li>Comparable or better space efficiency</li></ul><p>The trade-off? potentially slower insertions due to the evictions logic and slightly slower lookup.</p><p>Typically for security monitoring purposes you might need to answer questions like:</p><blockquote><p>“How many unique IP addresses attempted to authenticate to our VPN in the last 24 hours?”</p></blockquote><pre tabindex=\"0\"><code data-lang=\"kql\">@VPNLogs\n| where timestamp &gt; ago(24h)\n| summarize unique_ips = dcount(source_ip)\n</code></pre><blockquote><p>“How many distinct hosts communicated with domains on our watchlist this week?”</p></blockquote><pre tabindex=\"0\"><code data-lang=\"kql\">@DNSLogs\n| where timestamp &gt; ago(7d) and query.domain in (&lt;watchlist_domains&gt;)\n| summarize unique_hosts = dcount(source_host)\n</code></pre><blockquote><p>“How many different user accounts accessed our internal data-sensitive database this month?”</p></blockquote><pre tabindex=\"0\"><code data-lang=\"kql\">@DBLogs\n| where timestamp &gt; ago(30d) and db_name == \"sensitive_data_db\"\n| summarize unique_users = dcount(actor.username)\n</code></pre><p>These seem like simple questions, but at scale, they become challenging.\nThe naive approach to counting unique items is straightforward, collect items into a set and return the size:</p><div><pre tabindex=\"0\"><code data-lang=\"rust\"></code></pre></div><p>The problem with this approach is that the memory requirements grow linearly with the number of unique elements. In a large scale data system, we can expect millions of unique IP addresses, hundreds of thousands of unique user accounts, and tens of thousands of unique hostnames. So you need to keep track of all of them, plus apart from the size of the raw data there is a significant overhead from the hash-set data structure itself.</p><p>The real problem isn’t just the memory for a single count. In practice, you’re running dozens of these queries simultaneously:</p><ul><li>Different time windows (hourly, daily, weekly, monthly)</li><li>Different log sources (VPN, auth, DNS, network traffic)</li><li>Different groupings (by region, department, risk level)</li></ul><p>What seemed like a simple counting problem quickly consumes gigabytes of memory.</p><p>Finally distributing exact counting across multiple machines requires coordination to avoid double-counting elements which can be tricky as well.</p><h2>Enter HyperLogLog++: Counting Without Remembering \n    </h2><p>HyperLogLog++ solves this using a different approach. Instead of “remembering” every element, it tries to estimate how many unique elements there are using the statistical properties of hash functions. The estimates are pretty accurate while using a tiny, fixed amount of memory.</p><p>The high-level idea is hashing each element and looking for rare patterns in the binary representation. The rarer the pattern you’ve observed, the more elements you’ve likely processed.</p><p>Think of it like estimating the population of a city by sampling random people and asking where they were born. If you ask 100 people and find that the most remote birthplace is someone from a tiny village 500 miles away, you can infer that the city probably has a pretty large population. The logic behind it is that the odds of randomly finding someone from such a remote place is low unless there are many people to sample from.\nAnother classic analogy is coin flips: if someone tells you they flipped 5 heads in a row, you might guess they’ve done around 32 flips total, since the probability of getting 5 consecutive heads is about \\(\\frac{1}{32}\\). The longer the streak of heads, the more flips they’ve likely made.</p><p>HyperLogLog works similarly but with binary patterns. Here’s the intuition:</p><ul><li>Hash everything consistently: Every element gets run through a hash function, giving us a random-looking binary string</li><li>Count leading zeros: Look at how many zeros appear at the start of each hash</li><li>Track the maximum: Keep track of the longest run of leading zeros you’ve ever seen</li><li>Estimate from extremes: The longer the maximum run of zeros, the more unique elements you’ve probably processed</li></ul><p>So similar to the coin flip analogy, if you’ve seen a hash starting ith 5 zeros  it safe to assume you’ve processed roughly \\(2^5 = 32\\) different elements since the probability of any single hash starting with 5 zero is about \\(\\frac{1}{32}\\). This of course only works if your hash function produces uniformly random bits so each bit position should be 0 or 1 with equal probability, independent of the input data or other bit positions just like coin flips.</p><p>You’re probably thinking now that relying on a single “maximum” doesn’t sound like a good idea, just like I thought when I first read about it. You might get lucky and see a very rare pattern early, leading to a massive overestimate, or unlucky and never see rare patterns, leading to underestimation. HyperLogLog++ addresses this problem by using multiple independent estimates and combining them to get a much more stable result.</p><h3>The HyperLogLog++ Algorithm \n    </h3><p>Instead of keeping one maximum, HyperLogLog++ maintains many buckets, each tracking the maximum leading zeros for a subset of elements. This provides multiple independent estimates that can be averaged for better accuracy.\nHere’s how it actually works:</p><ol><li> using a good hash function</li><li> Use the first  bits to choose a bucket ( total buckets), and count leading zeros in the . For example for the hash  and , we split it as  so the bucket index is 10 ( in binary) and we count 2 leading zeros in the remaining part.</li><li> If this is the longest run of zeros seen for this bucket, update it</li><li> Combine all bucket values using harmonic mean and bias correction</li></ol><p>The formula for the  of a set of \\(n\\) positive real numbers \\(x_1, x_2, \\dots, x_n\\) is:</p><p>$$\nH = \\frac{n}{\\sum_{i=1}^{n} \\frac{1}{x_i}}\n$$</p><p>Why use harmonic mean when estimating the count?\nEach bucket value represents the maximum leading zeros observed, which corresponds to an estimated count of \\({2^{buckets}}\\) elements. Say you have 4 buckets with values \\([2, 2, 2, 6]\\), representing estimated counts of \\([4, 4, 4, 64]\\) elements respectively.</p><ul><li>Using arithmetic mean: \\(\\frac{4 + 4 + 4 + 64}{4} = 19\\)</li><li>Using harmonic mean: \\(\\frac{4}{\\frac{1}{4} + \\frac{1}{4} + \\frac{1}{4} + \\frac{1}{64}} \\approx 5.1\\)</li></ul><p>As you can see the harmonic mean is much less sensitive to that one outlier bucket that got lucky with a rare pattern, giving a more stable estimate.</p><p>The actual formula the algorithm use is:</p><p>$$\n\\frac{\\alpha \\cdot m^2}{\\sum 2^{-{buckets}}}\n$$</p><p>Based on the harmonic mean but adds:</p><ul><li>An extra factor of \\(m\\) (so \\(m^2\\) instead of m) - to scale from “average per bucket” to “total count”</li><li>The \\(\\alpha\\) constant - used to correct mathematical biases in the harmonic mean estimation and its value depends on the number of buckets.</li></ul><p>So for the 4 buckets from the example before with an \\(\\alpha = 0.568\\) will actually get \\(\\frac{0.568 \\times 4^2}{\\frac{1}{2^1} + \\frac{1}{2^1} + \\frac{1}{2^1} + \\frac{1}{2^8}} \\approx 11.9\\) total elements.</p><blockquote><p>Note: there’s no predefined alpha for 4 buckets as using HLL with such a small number is not supported in the original algorithm</p></blockquote><p>This raw estimate has systematic biases, especially when most buckets are still empty (value 0). HyperLogLog++ detects this and switches to a more accurate method for small datasets, plus uses pre-computed correction tables to fix predictable errors across different cardinality ranges.</p><div align=\"center\"><img src=\"https://blog.vega.io/posts/probabilistic_techniques/hll_1024_buckets_lucky_estimation.png\" alt=\"HyperLogLog bucket distribution showing a lucky estimation\"><p>\n    HyperLogLog with 1,024 buckets estimating 1,000 unique elements. Each bucket represents the maximum number of leading zeros + 1 seen. This \"lucky\" run achieved 0.2% error, showing how bucket values distribute across the hash space. <a href=\"https://djhworld.github.io/hyperloglog/counting/\" target=\"_blank\">Try playing with this online calculator</a></p></div><p>Here’s a simplified rust implementation:</p><div><pre tabindex=\"0\"><code data-lang=\"rust\"></code></pre></div><h3>Choosing the Right Precision \n    </h3><p>For most applications, \\(4,096\\) buckets (\\(2^{12}\\)) hit the sweet spot of good accuracy with minimal memory overhead. You can play with different configurations using this <a href=\"https://djhworld.github.io/hyperloglog/counting/\" target=\"_blank\">HyperLogLog calculator</a> which also has a nice visualization.</p><p>To see how significant the memory reduction can be, here’s an example: Say you’re tracking 1 million unique users from authentication logs each username is 10 characters long on average.</p><p>Using HLL++ with 4,096 buckets requires approximately 32KB of memory. According to <a href=\"https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/40671.pdf\" target=\"_blank\"></a>, the standard error of the cardinality can be calculated using:\n$$\n\\text{SE} \\approx \\frac{1.04}{\\sqrt{m}} \\rightarrow \\frac{1.04}{\\sqrt{4096}} \\approx 0.01625\n$$\nAn error of \\(1.625\\%\\) which in our example is \\(\\pm 16,250\\), it means the estimated cardinality will most likely fall between 983,750 and 1,016,250.</p><p>Now let’s write a small Rust program to see how much memory we would need to store 1 million unique usernames each 10 characters long using a hash-set for exact count:</p><div><pre tabindex=\"0\"><code data-lang=\"rust\"></code></pre></div><p>Now let’s see how much memory that actually takes with :</p><div><pre tabindex=\"0\"><code data-lang=\"bash\"></code></pre></div><p>The measurement shows 93.4 MB total memory usage. This includes overhead from String allocations, HashSet internal structure, and the format! macro. While the code could obviously be optimized, that’s a \\(\\frac{93.4 * 1024^2}{32 * 1024} = 2988.8\\)x memory reduction for a small accuracy loss – a trade-off worth taking for most applications.</p><h3>When HyperLogLog++ Stumbles \n    </h3><p>HyperLogLog++ has some important limitations worth knowing:</p><ul><li>: For datasets with fewer than ~100 unique elements, the probabilistic nature introduces more error than it’s worth. A simple hash set would be more accurate and use similar memory.</li><li>: In distributed systems, you often need to combine cardinality estimates from multiple sources. While you can merge HyperLogLog++ structures (by taking the maximum value for each bucket), the error accumulates with each merge operation.</li><li>: Unlike exact approaches, you can’t ask “have I seen element X before?”. You can only get total counts (making it unsuitable for deduplication tasks).</li><li>: HyperLogLog++ assumes your hash function produces truly random bits. If your data has patterns that survive hashing (like sequential IDs), accuracy can suffer. This is rare with good hash functions, but good to know.</li></ul><p>This algorithm is the basis for cardinality estimation for most search engines for example:</p><p><strong>Further Reading on HyperLogLog:</strong></p><p>We’ve explored how probabilistic data structures like Bloom filters and HyperLogLog++ can be used for shard pruning and cardinality estimation in large-scale log processing systems, trading small amounts of accuracy for massive gains in memory efficiency and query performance.</p><p>If you’re interested in learning more about probabilistic structures, here are some more useful ones: Count-Min Sketches estimate item frequencies, MinHash enables fast set similarity, and Quantile Sketches provide accurate percentile calculations. We may explore them in future posts.</p><p>Probabilistic structures are just one part of building a scalable log search system. We’ve already looked at query planning and optimization in distributed search in our blog post <a href=\"https://blog.vega.io/posts/distributed_search_optimizations/\" target=\"_blank\">“Hidden Complexities of Distributed SQL”</a>. Future posts will cover other critical challenges like high-throughput indexing for real-time ingestion, shard merging strategies to improve search efficiency by minimizing number of shards queried, tokenization and indexing design choices for different search capabilities, and distributed query coordination. All essential for systems that process terabytes of logs every day.</p>","contentLength":25093,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://www.reddit.com/r/programming/comments/1l6bpt5/probably_faster_than_you_can_count_scalable_log/"}],"tags":["dev","reddit"]}