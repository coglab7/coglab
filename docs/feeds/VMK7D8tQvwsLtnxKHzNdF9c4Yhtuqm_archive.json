{"id":"VMK7D8tQvwsLtnxKHzNdF9c4Yhtuqm","title":"Hacker News: Best","displayTitle":"HN","url":"https://hnrss.org/best","feedLink":"https://news.ycombinator.com/best","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":30,"items":[{"title":"The last six months in LLMs, illustrated by pelicans on bicycles","url":"https://simonwillison.net/2025/Jun/6/six-months-in-llms/","date":1749368317,"author":"swyx","guid":202,"unread":true,"content":"<a href=\"https://simonwillison.net/2025/Jun/6/six-months-in-llms/#ai-worlds-fair-2025-20.jpeg\">#</a><p>Also in March, OpenAI launched the \"GPT-4o  native multimodal image generation’ feature they had been promising us for a year.</p><p>This was one of the most successful product launches of all time. They signed up 100 million new user accounts in a week! They had <a href=\"https://simonwillison.net/2025/May/13/launching-chatgpt-images/\">a single hour</a> where they signed up a million new accounts, as this thing kept on going viral again and again and again.</p><p>I took a photo of my dog, Cleo, and told it to dress her in a pelican costume, obviously.</p><p>But look at what it did—it added a big, ugly sign in the background saying Half Moon Bay.</p><p>I didn’t ask for that. My artistic vision has been completely compromised!</p><p>This was my first encounter with ChatGPT’s new memory feature, where it consults pieces of your previous conversation history without you asking it to.</p><p>I told it off and it gave me the pelican dog costume that I really wanted.</p><p>But this was a warning that we risk losing control of the context.</p><p>As a power user of these tools, I want to stay in complete control of what the inputs are. Features like ChatGPT memory are taking that control away from me.</p><p>I don’t like them. I turned it off.</p>","contentLength":1122,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44215352"},{"title":"My experiment living in a tent in Hong Kong's jungle","url":"https://corentin.trebaol.com/Blog/8.+The+Homelessness+Experiment","date":1749314409,"author":"5mv2","guid":237,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44210736"},{"title":"Washington Post's Privacy Tip: Stop Using Chrome, Delete Meta Apps (and Yandex)","url":"https://tech.slashdot.org/story/25/06/07/035249/washington-posts-privacy-tip-stop-using-chrome-delete-metas-apps-and-yandex","date":1749313993,"author":"miles","guid":236,"unread":true,"content":"<div>\n\t\t\t\n\t\t \t\n\t\t\t\tMeta's Facebook and Instagram apps \"were <a href=\"https://yro.slashdot.org/story/25/06/03/205251/meta-and-yandex-are-de-anonymizing-android-users-web-browsing-identifiers\">siphoning people's data through a digital back door</a> for months,\" <a href=\"https://www.msn.com/en-us/news/technology/meta-found-a-new-way-to-violate-your-privacy-here-s-what-you-can-do/ar-AA1GecPs\">writes a Washington Post tech columnist</a>, citing researchers who found no privacy setting could've stopped what Meta and Yandex were doing, since those two companies \"circumvented privacy and security protections that Google set up for Android devices.<p>\n\n\"But their tactics underscored some privacy vulnerabilities in web browsers or apps. These steps can reduce your risks.\"\n\n</p><i><strong>Stop using the Chrome browser.</strong> Mozilla's <a href=\"https://www.mozilla.org/en-US/firefox/\">Firefox</a>, the <a href=\"https://brave.com/\">Brave</a> browser and <a href=\"https://duckduckgo.com/app\">DuckDuckGo</a>'s browser block many common methods of tracking you from site to site. Chrome, the most popular web browser, does not... For iPhone and Mac folks, Safari also has strong privacy protections. <a href=\"https://www.washingtonpost.com/technology/2024/07/30/safari-best-browser-privacy/\">It's not perfect</a>, though.  No browser protections are foolproof. The researchers said Firefox on Android devices was partly susceptible to the data harvesting tactics they identified, in addition to Chrome. (DuckDuckGo and Brave largely did block the tactics, the researchers said....)<strong>Delete Meta and Yandex apps on your phone, if you have them.</strong> The tactics described by the European researchers showed that Meta and Yandex are unworthy of your trust. (Yandex is not popular in the United States.)    It might be wise to delete their apps, which give the companies more latitude to collect information that websites generally cannot easily obtain, including your approximate location, your phone's battery level and what other devices, like an Xbox, are connected to your home WiFi.<p>\n\nKnow, too, that even if you don't have Meta apps on your phone, and even if you don't use Facebook or Instagram at all, Meta might still harvest information on your activity across the web.</p></i></div>","contentLength":1742,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44210689"},{"title":"Bill Atkinson has died","url":"https://daringfireball.net/linked/2025/06/07/bill-atkinson-rip","date":1749313198,"author":"romanhn","guid":235,"unread":true,"content":"<p>From his family, on Atkinson’s Facebook page:</p><blockquote><p>We regret to write that our beloved husband, father, and\nstepfather Bill Atkinson passed away on the night of Thursday,\nJune 5th, 2025, due to pancreatic cancer. He was at home in\nPortola Valley in his bed, surrounded by family. We will miss him\ngreatly, and he will be missed by many of you, too. He was a\nremarkable person, and the world will be forever different because\nhe lived in it. He was fascinated by consciousness, and as he has\npassed on to a different level of consciousness, we wish him a\njourney as meaningful as the one it has been to have him in our\nlives. He is survived by his wife, two daughters, stepson,\nstepdaughter, two brothers, four sisters, and dog, Poppy.</p></blockquote><p>One of the great heroes in not just Apple history, but computer history. If you want to cheer yourself up, go to Andy Hertzfeld’s Folklore.org site and (re-)read all the entries about Atkinson. Here’s just one, with <a href=\"https://folklore.org/Round_Rects_Are_Everywhere.html\">Steve Jobs inspiring Atkinson to invent the roundrect</a>. Here’s another (surely near and dear to my friend <a href=\"https://inessential.com/2002/06/25/deleting_code.html\">Brent Simmons’s heart</a>) with <a href=\"https://www.folklore.org/Negative_2000_Lines_Of_Code.html\">this kicker of a closing line</a>: “I’m not sure how the managers reacted to that, but I do know that after a couple more weeks, they stopped asking Bill to fill out the form, and he gladly complied.”</p><p>Some of his code and algorithms are among the most efficient and elegant ever devised. The original Macintosh team was chock full of geniuses, but Atkinson might have been the most essential to making the impossible possible under the extraordinary technical limitations of that hardware. <a href=\"https://www.google.com/search?q=bill+atkinson+dithering+algorithm\">Atkinson’s genius dithering algorithm</a> was my inspiration for the name of <a href=\"https://en.wikipedia.org/wiki/Atkinson_dithering\">Dithering</a>, my podcast with Ben Thompson. I find that effect beautiful and love that it continues to prove useful, like on the <a href=\"https://play.date/\">Playdate</a> and <a href=\"https://daringfireball.net/linked/2016/06/10/bitcam\">apps like BitCam</a>.</p><p>I say this with no hyperbole: Bill Atkinson may well have been the best computer programmer who ever lived. Without question, he’s on the short list. What a man, what a mind, what gifts to the world he left us.</p>","contentLength":2021,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44210606"},{"title":"Falsehoods programmers believe about aviation","url":"https://flightaware.engineering/falsehoods-programmers-believe-about-aviation/","date":1749248433,"author":"cratermoon","guid":234,"unread":true,"content":"<p>At FlightAware, our software needs to gracefully handle all sorts of weird and wonderful situations. While we as engineers might hope for aviation data to be clean and well-standardized, the real world is messy.</p><p>There are a lot of assumptions one could make when designing data types and schemas for aviation data that turn out to be inaccurate. In the spirit of <a href=\"https://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/?ref=flightaware.engineering\">Patrick McKenzie’s classic piece on names</a>, here are some false assumptions one might make about aviation. While many of these are simply common misconceptions, some of these assumptions have bitten our customers at various points, and others have caused issues in our own systems over the years.</p><p>Together they are illustrative of the situations that Hyperfeed, our flight tracking engine, is responsible for correctly interpreting in order to provide a clean and consistent data feed for our website, apps, and APIs.</p><ul><li>Flights depart from a gate</li><li>Flights depart within a few hours of the time they were scheduled to</li><li>Flights depart <a href=\"https://www.flightaware.com/live/flight/PDT5965/history/20250508/2224Z/KCHO/KCLT?ref=flightaware.engineering\">within a day</a> of the time they were scheduled to</li><li>Airplanes (excluding helicopters) take off and land at airports</li><li>Flights are identified by a flight number consisting of an airline’s code plus some numbers, like UAL1234</li><li>Flights <a href=\"https://www.flightaware.com/live/flight/C6031/history/20250521/1752Z/KBID/KFMH?ref=flightaware.engineering\">are identified by either</a> an airline flight number like UAL1234, or the aircraft’s registration like N12345, B6459, or FHUVL</li><li>A flight identifier like B6459 is unambiguously either a registration (<a href=\"https://www.flightaware.com/live/flight/B6459?ref=flightaware.engineering\" rel=\"noreferrer\">B–6459</a>), an airline flight number (<a href=\"https://www.flightaware.com/live/flight/JBU459?ref=flightaware.engineering\" rel=\"noreferrer\">B6 459</a>), or something else</li><li>Flights with multiple flight numbers unambiguously have one “main” flight number</li><li>Flights don’t use the code of some entirely unrelated airline in their flight identifier</li><li>No flights use the same flight number within a day</li><li>Surely at least no flights use the same flight number at the same time?</li><li>Okay fine, separate flights from the same major passenger airline that depart within a few minutes of each other would not <a href=\"https://www.flightaware.com/live/flight/AAL2586/history/20250509/1935Z/TBPB/KCLT?ref=flightaware.engineering\">both</a> have the <a href=\"https://www.flightaware.com/live/flight/AAL2586/history/20250508/1935Z/TBPB/KCLT?ref=flightaware.engineering\">same</a> flight number… right?</li></ul><ul><li>Terminal and gate numbers have a consistent naming scheme</li><li>Airports always have two unique identifiers: a 4-letter Civil Aviation Organization (ICAO) code and a 3-letter International Air Transport Association (IATA) code</li><li>Airports always have three unique identifiers: an ICAO, an IATA, and a regionally-administered location code</li><li>Airports have at least one well-known identifier of some sort</li></ul><ul><li>Waypoint names are unique</li><li>Flight information from Air Navigation Service Providers is accurate</li><li>Okay,  accurate; they wouldn’t indicate that a flight had departed unless it really had</li><li>If they indicate that a flight plan has been cancelled, then that flight definitely isn’t going to operate — it wouldn’t simply be due to someone editing the flight plan</li><li>At least their radar data accurately identifies each aircraft</li><li>Radars with overlapping coverage areas agree on the location of a target they can both see</li><li>If they send us a flight plan with the ICAO identifier of a known airport as the destination, then there must have been some intention of arriving there</li><li>If an aircraft diverts to another destination, it won’t <a href=\"https://www.flightaware.com/live/flight/AAL1372/history/20250516/1410Z/KMIA/KRIC?ref=flightaware.engineering\">divert again</a></li></ul><ul><li>ADS-B messages only come from aircraft</li><li>ADS-B messages only come from aircraft and airport service vehicles</li><li>ADS-B messages only come from vehicles of some kind</li><li>ADS-B messages always include the correct flight identification</li><li>Transponders are correctly programmed to indicate the aircraft type (helicopter, airplane, balloon, etc)</li><li>You can always determine a aircraft’s registration number from its ADS-B messages</li><li>Transponders are programmed with the correct Mode S address</li><li>All of the transponders on a single aircraft are programmed with the same Mode S address</li><li>Nobody will ever set their flight identification to weird things like NULL</li><li>People will remember to update the transponder when the aircraft’s registration changes</li><li>ADS-B messages are always received exactly as they were transmitted</li><li>No one ever transmits false ADS-B messages</li><li>Transponders never break and rodents never chew through cables</li></ul><p>Thanks to my colleagues who contributed to or reviewed this collection of falsehoods: Mark Duell, Paul Durandt, Karina Elizondo, Matt Higgins, Thomas Kyanko, Nathan Reed, and Amy Szczepanski.</p>","contentLength":4128,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44205590"},{"title":"How we decreased GitLab repo backup times from 48 hours to 41 minutes","url":"https://about.gitlab.com/blog/2025/06/05/how-we-decreased-gitlab-repo-backup-times-from-48-hours-to-41-minutes/","date":1749224585,"author":"nayak","guid":233,"unread":true,"content":"<p>Repository backups are a critical component of any robust disaster recovery strategy. However, as repositories grow in size, the process of creating reliable backups becomes increasingly challenging.  Our own <a href=\"https://gitlab.com/gitlab-org/gitlab\">Rails repository</a> was taking 48 hours to back up — forcing impossible choices between backup frequency and system performance. We wanted to tackle this issue for our customers and for our own users internally.</p><p>Ultimately, we traced the issue to a 15-year-old Git function with O(N²) complexity and fixed it with an algorithmic change, <strong>reducing backup times exponentially</strong>. The result: lower costs, reduced risk, and backup strategies that actually scale with your codebase.</p><p>This turned out to be a Git scalability issue that affects anyone with large repositories. Here's how we tracked it down and fixed it.</p><p>First, let's look at the problem. As organizations scale their repositories and backups grow more complex, here are some of the challenges they can face:</p><ul><li><strong>Time-prohibitive backups:</strong> For very large repositories, creating a repository backup could take several hours, which can hinder the ability to schedule regular backups.</li><li> Extended backup processes can consume substantial server resources, potentially impacting other operations.</li><li> Finding adequate maintenance windows for such lengthy processes can be difficult for teams running 24/7 operations.</li><li> Long-running processes are more susceptible to interruptions from network issues, server restarts, and system errors, which can force teams to restart the entire very long backup process from scratch.</li><li> Because it takes a long time to create a backup, the repository might have changed a lot during the process, potentially creating an invalid backup or interrupting the backup because objects are no longer available.</li></ul><p>These challenges can lead to compromising on backup frequency or completeness – an unacceptable trade-off when it comes to data protection. Extended backup windows can force customers into workarounds. Some might adopt external tooling, while others might reduce backup frequency, resulting in potential inconsistent data protection strategies across organizations.</p><p>Now, let's dig into how we identified a performance bottleneck, found a resolution, and deployed it to help cut backup times.</p><p>GitLab's repository backup functionality relies on the <a href=\"https://git-scm.com/docs/git-bundle\"></a> command, which captures a complete snapshot of a repository, including all objects and references like branches and tags. This bundle serves as a restoration point for recreating the repository in its exact state.</p><p>However, the implementation of the command suffered from poor scalability related to reference count, creating a performance bottleneck. As repositories accumulated more references, processing time increased exponentially. In our largest repositories containing millions of references, backup operations could extend beyond 48 hours.</p><p>To identify the root cause of this performance bottleneck, we analyzed a flame graph of the command during execution.</p><p>A flame graph displays the execution path of a command through its stack trace. Each bar corresponds to a function in the code, with the bar's width indicating how much time the command spent executing within that particular function.</p><p>When examining the flame graph of  running on a repository with 10,000 references, approximately 80% of the execution time is consumed by the <code>object_array_remove_duplicates()</code> function. This function was introduced to Git in the <a href=\"https://gitlab.com/gitlab-org/git/-/commit/b2a6d1c686\">commit b2a6d1c686</a> (bundle: allow the same ref to be given more than once, 2009-01-17).</p><p>To understand this change, it's important to know that  allows users to specify which references to include in the bundle. For complete repository bundles, the  flag packages all references.</p><p>The commit addressed a problem where users providing duplicate references through the command line – such as <code>git bundle create main.bundle main main</code> - would create a bundle without properly handling the duplicated main reference. Unbundling this bundle in a Git repository would break, because it tries to write the same ref twice. The code to avoid duplication uses nested  loops that iterate through all references to identify duplicates. This O(N²) algorithm becomes a significant performance bottleneck in repositories with large reference counts, consuming substantial processing time.</p><h3 tabindex=\"-1\">The fix: From O(N²) to efficient mapping </h3><p>To resolve this performance issue, we contributed an upstream fix to Git that replaces the nested loops with a map data structure. Each reference is added to the map, which automatically ensures only a single copy of each reference is retained for processing.</p><p>This change dramatically enhances the performance of  and enables much better scalability in repositories with large reference counts. Benchmark testing on a repository with 10,000 references demonstrates a 6x performance improvement.</p><pre><code>Benchmark 1: bundle (refcount = 100000, revision = master)\n  Time (mean ± σ): \t14.653 s ±  0.203 s\t[User: 13.940 s, System: 0.762 s]\n  Range (min … max):   14.237 s … 14.920 s\t10 runs\n\nBenchmark 2: bundle (refcount = 100000, revision = HEAD)\n  Time (mean ± σ):  \t2.394 s ±  0.023 s\t[User: 1.684 s, System: 0.798 s]\n  Range (min … max):\t2.364 s …  2.425 s\t10 runs\n\nSummary\n  bundle (refcount = 100000, revision = HEAD) ran\n\t6.12 ± 0.10 times faster than bundle (refcount = 100000, revision = master)\n</code></pre><p>The patch was accepted and <a href=\"https://gitlab.com/gitlab-org/git/-/commit/bb74c0abbc31da35be52999569ea481ebd149d1d\">merged</a> into upstream Git. At GitLab, we backported this fix to ensure our customers could benefit immediately, without waiting for the next Git release.</p><h2 tabindex=\"-1\">The result: Dramatically decreased backup times </h2><p>The performance gains from this improvement have been nothing short of transformative:</p><ul><li><strong>From 48 hours to 41 minutes:</strong> Creating a backup of our largest repository () now takes just 1.4% of the original time.</li><li> The improvement scales reliably across repository sizes.</li><li> We significantly reduced server load during backup operations.</li><li> While backup creation sees the most dramatic improvement, all bundle-based operations that operate on many references benefit.</li></ul><h2 tabindex=\"-1\">What this means for GitLab customers </h2><p>For GitLab customers, this enhancement delivers immediate and tangible benefits on how organizations approach repository backup and disaster recovery planning:</p><ul><li><strong>Transformed backup strategies</strong><ul><li>Enterprise teams can establish comprehensive nightly schedules without impacting development workflows or requiring extensive backup windows.</li><li>Backups can now run seamlessly in the background during nightly schedules, instead of needing to be dedicated and lengthy.</li></ul></li><li><strong>Enhanced business continuity</strong><ul><li>With backup times reduced from days to minutes, organizations significantly minimize their recovery point objectives (RPO). This translates to reduced business risk – in a disaster scenario, you're potentially recovering hours of work instead of days.</li></ul></li><li><strong>Reduced operational overhead</strong><ul><li>Less server resource consumption and shorter maintenance windows.</li><li>Shorter backup windows mean reduced compute costs, especially in cloud environments, where extended processing time translates directly to higher bills.</li></ul></li><li><strong>Future-proofed infrastructure</strong><ul><li>Growing repositories no longer force difficult choices between backup frequency and system performance.</li><li>As your codebase expands, your backup strategy can scale seamlessly alongside it</li></ul></li></ul><p>Organizations can now implement more robust backup strategies without compromising on performance or completeness. What was once a challenging trade-off has become a straightforward operational practice.</p><p>Starting with the <a href=\"https://about.gitlab.com/releases/2025/05/15/gitlab-18-0-released/\">GitLab 18.0</a> release, all GitLab customers regardless of their license tier can already fully take advantage of these improvements for their <a href=\"https://docs.gitlab.com/administration/backup_restore/backup_gitlab/\">backup</a> strategy and execution. There is no further change in configuration required.</p><p>This breakthrough is part of our ongoing commitment to scalable, enterprise-grade Git infrastructure. While the improvement of 48 hours to 41 minutes for backup creation time represents a significant milestone, we continue to identify and address performance bottlenecks throughout our stack.</p><p>We're particularly proud that this enhancement was contributed upstream to the Git project, benefiting not just GitLab users but the broader Git community. This collaborative approach to development ensures that improvements are thoroughly reviewed, widely tested, and available to all.</p><blockquote><p>Deep infrastructure work like this is how we approach performance at GitLab. Join the GitLab 18 virtual launch event to see what other fundamental improvements we're shipping. <a href=\"https://about.gitlab.com/eighteen/\">Register today!</a></p></blockquote>","contentLength":8485,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44201975"},{"title":"Meta: Shut down your invasive AI Discover feed","url":"https://www.mozillafoundation.org/en/campaigns/meta-shut-down-your-invasive-ai-discover-feed-now/","date":1749223990,"author":"speckx","guid":232,"unread":true,"content":"<p data-block-key=\"ox7g0\"><b>Meta is quietly turning private AI chats into public content — and too many people don’t realize it’s happening.</b></p><p data-block-key=\"a6hs9\">That’s why the Mozilla community is demanding that Meta:</p><ol><li data-block-key=\"f4j6n\"><b>Shut down the Discover feed</b> until real privacy protections are in place.</li><li data-block-key=\"3q7uu\"><b>Make all AI interactions private by default</b> with no public sharing option unless explicitly enabled through informed consent.</li><li data-block-key=\"ddf8c\"><b>Provide full transparency</b> about how many users have unknowingly shared private information.</li><li data-block-key=\"cfiao\"><b>Create a universal, easy-to-use opt-out system</b> for all Meta platforms that prevents user data from being used for AI training.</li><li data-block-key=\"8j7da\"><b>Notify all users whose conversations may have been made public</b>, and allow them to delete their content permanently.</li></ol><p data-block-key=\"3i8bo\">Meta is blurring the line between private and public — and it’s happening at the cost of our privacy. People have the right to know when they’re speaking in public, especially when they believe they’re speaking in private.</p><p data-block-key=\"9cait\">If you agree, add your name to demand Meta shut down its invasive AI feed — and guarantee that no private conversations are made public without clear, explicit, and informed opt-in consent.</p>","contentLength":1126,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44201872"},{"title":"Self-hosting your own media considered harmful according to YouTube","url":"https://www.jeffgeerling.com/blog/2025/self-hosting-your-own-media-considered-harmful","date":1749185998,"author":"DavideNL","guid":231,"unread":true,"content":"<p>I purposefully avoid demonstrating any of the tools (with a suffix that rhymes with \"car\") that are popularly used to circumvent purchasing movie, TV, and other media content, or any tools that automatically slurp up YouTube content.</p><p>In fact, in my own house, for multiple decades, I've purchased physical media (CDs, DVDs, and more recently, Blu-Rays), and only have legally-acquired content on my NAS. Streaming services used to be a panacea but are now fragmented and mostly full of garbage—and lots of ads. We just wanted to be able to watch TV shows and movies without hassle (and I'm happy to pay for physical media that I want to watch).</p><p>But this morning, as I was finishing up work on a video about a new mini Pi cluster, I got a cheerful email from YouTube saying my video on LibreELEC on the Pi 5 (<a href=\"https://t.co/qR9s0UZzon\">here's the original YouTube link - now dead</a>) was removed because it promoted:</p><blockquote><p><strong>Dangerous or Harmful Content</strong>\n  Content that describes how to get unauthorized or free access to audio or audiovisual content, software, subscription services, or games that usually require payment isn't allowed on YouTube.</p></blockquote><p>I never described any of that stuff, only how to self-host your own media library.</p><blockquote><p>YouTube has just reinstated <a href=\"https://www.youtube.com/watch?v=3hFas54xFtg\">the video</a>, after what I presume is a human review process. I wish it didn't take making noise on socials to get past the 'AI deny' process :(</p></blockquote><p>In  case, I was happy to see my appeal granted within an hour of the strike being placed on the channel. (Nevermind the fact the video had been live for  at that point, with nary a problem!)</p><p>So I thought, this case will be similar:</p><ul><li>The video's been up for over a year, without issue</li><li>The video's had over a million views</li><li>The video doesn't promote or highlight any tools used to circumvent copyright, get around paid subscriptions, or reproduce any content illegally</li></ul><p>Slam-dunk, right? Well, not according to whomever reviewed my appeal. Apparently self-hosted open source media library management is harmful.</p><p>Who knew open source software could be so ?</p><p>So along that theme, I've re-uploaded the video to Internet Archive, free for anyone to download and view at their leisure.</p><p><em>Yes, even those rebels running LibreELEC on their Raspberry Pis!</em></p><p>Some in the fediverse ask why I'm not on Peertube. Here's the problem (and it's not insurmountable): , there's no easy path towards sustainable content production when the audience for the content is 100x smaller, and the number of patrons/sponsors remains proportionally the same.</p><p>I was never able to sustain my open source work based on patronage, and content production is the same—just more expensive to maintain to any standard (each video takes between 10-300 hours to produce, and I have a family to feed, and <a href=\"https://www.jeffgeerling.com/tags/crohns\">US health insurance companies to fund</a>).</p><p>YouTube was, and still is, a creative anomaly. I'm hugely thankful to my <a href=\"https://www.patreon.com/c/geerlingguy\">Patreon</a>, <a href=\"https://github.com/sponsors/geerlingguy\">GitHub</a>, and <a href=\"https://www.floatplane.com/channel/JeffGeerling/home\">Floatplane</a> supporters—and I hope to have direct funding fully able to support my work someday. But until that time, YouTube's AdSense revenue and vast reach is a kind of 'golden handcuff.'</p><p>Maybe the handcuffs are fools-gold, and I just don't see it yet.</p>","contentLength":3094,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44197932"},{"title":"The impossible predicament of the death newts","url":"https://crookedtimber.org/2025/06/05/occasional-paper-the-impossible-predicament-of-the-death-newts/","date":1749130848,"author":"bdr","guid":230,"unread":true,"content":"<p>So a few days ago I <a href=\"https://crookedtimber.org/2025/05/31/newt/\">posted about newts</a>, and I mentioned that there was an American newt that was ridiculously toxic. But then (I said) there wasn’t space or time to go into why.&nbsp; And&nbsp;of course I was immediately bombarded by many* comments and e-mails asking why.&nbsp;<p>Well, fine.&nbsp; The world’s most toxic newt is </p>, the Rough-Skinned Newt, a modest little amphibian native to the North American Pacific Northwest, west of the Cascades from around Santa Cruz, CA up to the Alaska Panhandle.</p><p>It’s so toxic that the poison from a single newt can easily kill several adult humans. You could literally die from licking this newt, just once.<p>(But note that the newt is toxic, not venomous. It doesn’t bite or sting. You could handle one safely, as long as you washed your hands thoroughly afterwards. Very, very thoroughly.)</p><p>Okay, but… why?&nbsp; Lots of newts are mildly toxic.&nbsp; Why is this particularly newt so </p> toxic?</p><p>Turns out this is a fairly deep rabbit hole!&nbsp; I’ll try to teal deer it.</p><p>The simple version: the newt is in an arms race with the common garter snake, .&nbsp; The garter snake is a small-to-medium sized snake that is common all over North America.&nbsp; It’s a slim, elegant little creature that is usually found in or near water.&nbsp; And while it will eat pretty much anything it can catch, the garter snake particularly likes amphibians: small frogs, salamanders and newts.&nbsp; And in the Pacific Northwest, it  likes snacking on the Rough-Skinned Newt.</p><p>So the garter snakes of the Pacific Northwest have been evolving resistance to tetrodotoxin.&nbsp; (As you may recall, tetrodotoxin is the stuff that <a href=\"https://crookedtimber.org/2025/03/14/occasional-paper-the-interesting-home-life-of-the-blue-ringed-octopus/\">makes the blue-ringed octopus so deadly</a>.&nbsp; It’s produced by symbiotic bacteria that live in the newt’s body, mostly on its skin.)&nbsp; And as the garter snakes evolve resistance, the newts have to evolve ever greater toxicity.&nbsp; And as the newts get more toxic… right.&nbsp; Feedback loop!&nbsp; That’s the simple version.</p><p>Except this is biology, so of course it’s not that simple.</p><p>One thing to keep in mind is that nothing in nature is free. The newt’s toxicity comes with a cost: the metabolic load of supporting all those bacteria.&nbsp; More toxicity means more bacteria means more load.&nbsp; A very toxic newt has to consume more calories than its less-toxic cousin.<p>Meanwhile, evolving resistance also comes at a cost.&nbsp; We don’t know that directly, but we can infer it pretty well.&nbsp; If resistance to tetrodotoxin were cheap and easy, everything would evolve it.&nbsp; </p><p>There have actually been attempts to measure the effect on the snakes!&nbsp; They haven’t found them, but keep in mind that tetrodotoxin is a neurotoxin.&nbsp; To resist it, you have to make changes to the biochemistry of your nervous system.&nbsp; Even a small snake has a very very complex nervous system, where those changes might show up in ways that are hard to measure.&nbsp; Like, if the resistant snakes were clumsier or had slower reflexes, sure, we could see that.&nbsp; But maybe they’re suffering from much more subtle neurological effects, like being prone to insomnia or hallucinations or sexual dysfunction.&nbsp; Or maybe they’re just a bit dim.&nbsp; </p><p>We don’t know, but we’re pretty sure there must be something.&nbsp; &nbsp;We know that </p><a href=\"https://link.springer.com/article/10.1007/s10886-024-01517-7?fromPaywallRec=true\">garter snakes outside of the Pacific Northwest are much less resistant to tetrodotoxin</a>.&nbsp; They’ll drop dead from doses that their Oregon cousins simply ignore.&nbsp; So evolving the resistance must have some cost or drawback.<p>(Note that this means the newt is double-whammied:&nbsp; not only does it suffer the metabolic load of carrying around all those bacteria, but it also has to evolve resistance to tetrodotoxin, accepting whatever negative effects that brings.&nbsp; And things are only going to get worse.)</p><p>Now: when the snakes eat Rough-Skinned Newts, they may sometimes show signs of discomfort. The snake may visibly gag.&nbsp; It may writhe in obvious unease.&nbsp; In some cases, it may go into respiratory distress.&nbsp; Eating the newt looks pretty unpleasant.&nbsp; Yet the snakes persist.</p><p>Okay then — if evolving toxin resistance carries a cost, and if&nbsp;</p> eating the newts is unpleasant, then why then do garter snakes insist on eating newts?&nbsp; They cheerfully eat frogs, fish, and other non-toxic prey items.&nbsp; Why don’t they just eat those, and leave the poor newts alone?<p>Turns out there is an answer:&nbsp; </p><a href=\"https://link.springer.com/article/10.1023/B:JOEC.0000045585.77875.09\">the garter snakes sequester the tetrodotoxin</a>, storing it in their livers.&nbsp; This makes them toxic to their own predators.&nbsp; (Of which there are plenty.&nbsp; They’re not large snakes, so they’re hunted by everything from raccoons to ravens.)&nbsp; But they don’t harbor the bacteria, so they don’t produce tetrodotoxin of their own. So eventually, the toxin that they’ve ingested breaks down.&nbsp; And then they need to eat another newt to refresh their defense.<p>(If you are That Guy:&nbsp; now you can name a snake that is poisonous without being venomous.)</p><p>So this explains why the snakes go after the newts particularly, preferring them to less toxic prey.&nbsp; They </p> to eat toxic newts.&nbsp; And it explains why the newts keep evolving to be more toxic: the snake may want to eat newts generally, but if an individual newt packs enough of a wallop, the snake <a href=\"https://link.springer.com/article/10.1007/s00049-010-0057-z\">may just retch it up and go after a different one</a>.&nbsp; Newts with weaker poison?&nbsp; They get eaten.&nbsp; Snakes with less resistance?&nbsp; Have trouble finding newts they can choke down, and don’t get to steal their poison.&nbsp; So the arms race continues.<p>This also explains why the newts, despite being very toxic to anything that’s not a garter snake, haven’t evolved aposematic coloring or signals.&nbsp; “Aposematic” is just a fancy word for “warning”, meaning something — usually color — that tells the world Do Not Mess With Me:</p><img decoding=\"async\" src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fres.cloudinary.com%2Frainforest-cruises%2Fimages%2Fc_fill%2Cg_auto%2Ff_auto%2Cq_auto%2Fw_2560%2Ch_1861%2Fv1627055916%2FPoison-Dart-Frogs-Facts-rana-de-dardo-envenenada-amarillenta%2FPoison-Dart-Frogs-Facts-rana-de-dardo-envenenada-amarillenta.jpg&amp;f=1&amp;nofb=1&amp;ipt=08b23ddaf5aa7edcd44506b627b0819a1169f932e06f09d41f146f6d24d69d9c\" alt=\"13 Interesting Poison Dart Frogs Facts - Rainforest Cruises\" width=\"237\" height=\"172\"><img loading=\"lazy\" decoding=\"async\" src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fguloinnature.com%2Fwp-content%2Fuploads%2F2022%2F08%2F8-1-e1664541955412.png&amp;f=1&amp;nofb=1&amp;ipt=7a5788815878ecb746369fb7609cbab7d9ef55e63314cba4ceef46de08284727\" alt=\"What is aposematic coloration? | Gulo in Nature\" width=\"273\" height=\"174\"><img loading=\"lazy\" decoding=\"async\" src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fwww.color-meanings.com%2Fwp-content%2Fuploads%2F2023%2F06%2Fstriped-lionfish-close-up-blue-background-14878-768x491.jpeg&amp;f=1&amp;nofb=1&amp;ipt=d517fafecdfbd90d6e7acca301a9ab884dc3355231a4a71a2e0461e46de29459\" alt=\"Aposematic Coloration: Nature's Brightly Colored Warning Signs | Color ...\" width=\"361\" height=\"231\"><img loading=\"lazy\" decoding=\"async\" src=\"https://newbeautifulera.wordpress.com/wp-content/uploads/2013/03/gary-larsen.png?w=500\" alt=\"Gary Larsen\" width=\"181\" height=\"232\">[The Far Side by Gary Larsen, copyright 1984]<p>The Rough-Skinned Newt, like many newts, has a brightly colored underside that it can flash when threatened.&nbsp; But the rest of it is a dull mottled grey, camouflage.&nbsp; Presumably that’s because if the newt ever tried to evolve full-body colors like an Amazonian poison dart frog, it would just be a big “come eat me” sign to garter snakes.&nbsp; Probably a certain number of newts get eaten by birds or fish or whatever anyway because they’re not aposematic enough.&nbsp; The bird or fish may not survive the experience, but that’s not much comfort to the newt.</p><p>In sum: the unfortunate newt is not once, not twice, but three times screwed over here.&nbsp; They have to be extra-toxic, carrying that metabolic load, just to </p> make the garter snakes think twice about eating them.&nbsp; Then they have to evolve defenses against their own toxin.&nbsp; But they can’t evolve aposematic coloring, because that’ll just lead to the snakes gobbling them all up.&nbsp; And finally, they can’t go back to being not-very-toxic, because the snakes will just eat more of them to gain the same amount of tetrodotoxin.&nbsp; They can’t win, they can’t break even, and they can’t leave the game.<img loading=\"lazy\" decoding=\"async\" src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fcaliforniaherps.com%2Fsalamanders%2Fimages%2Ftgranulosaventmend.jpg&amp;f=1&amp;nofb=1&amp;ipt=3790a4834b4a97caa8b5adfb847fac5f6910139893a2e6b08515baa8fbceb8fd\" alt=\"Rough-skinned Newt - Taricha granulosa\" width=\"351\" height=\"234\">[Copyright Gary Nafis, 2019]<p>There is even more going on here.&nbsp; There are literally dozens of papers about this snake-newt interaction.&nbsp; And we still haven’t reached the end of it!&nbsp; Just a few examples:</p><p>— The newts that live in the northern end of their range, up in Alaska, don’t have garter snakes around.&nbsp; As expected, they mostly aren’t very toxic.&nbsp; But only mostly!&nbsp; One paper found </p><a href=\"https://onlinelibrary.wiley.com/doi/pdf/10.1002/ece3.2068\">odd little pockets of unexpectedly toxic newts</a> up there.&nbsp; Why?&nbsp; We don’t know.<p>— Meanwhile, the newts of Vancouver Island, offshore, also aren’t very toxic.&nbsp; Because there are no snakes there?&nbsp; Ha ha, no.&nbsp; There are three different species of garter snake on Vancouver.&nbsp; But&nbsp; for some reason, the newts and snakes there seem to be living in harmony.&nbsp; Well, relative harmony.&nbsp; The snakes of Vancouver do eat newts.&nbsp; But so far, the snakes and newts don’t seem to have started an arms race like they have on the mainland.&nbsp; Why not?&nbsp; We don’t know.</p><p>— A question that occurred, digging through these papers:&nbsp; if the garter snakes are becoming toxic from eating newts, might the </p>&nbsp; begin to evolve aposematic coloring?&nbsp; And sure enough, when I look at photos of Oregon garter snakes, a lot of them seem to have bright orange markings that look a bit aposematic:<img loading=\"lazy\" decoding=\"async\" src=\"https://2img.net/h/stevenbolgartersnakes.com/wp-content/uploads/2012/09/Thamnophis-sirtalis-concinnus-11.jpg\" width=\"423\" height=\"282\">[copyright Stephen Bol, 2023]<p>But on the other hand garter snake markings vary wildly.&nbsp; Lots of garter snakes outside the Pacific Northwest have orange spots or stripes, and lots of snakes within the region don’t.&nbsp; And as far as I can tell, nobody has even tried to research this yet.</p><p>— A thing to keep in mind: the Pacific Northwest, where all this is playing out, is a very young ecosystem in geological terms.&nbsp; Just 20,000 years ago, during the last Ice Age, the Pacific coast of Washington and Oregon looked a lot like Greenland today: a thin coastal strip of cold tundra,&nbsp; everything else covered by an ice cap.&nbsp; The newts and the snakes are relatively recent colonists.&nbsp; So we may be catching a snapshot of a relationship that is still evolving, and that may not be long-term stable.</p><p>— And finally, I have oversimplified this whole thing, because there are other species of newt in the genus </p>that are pretty toxic — not as crazy deadly as their Rough-Skinned cousins, but still more toxic than normal newts — while the garter snake genus is just a taxonomic mess.&nbsp;&nbsp;<p>In other words, we’ve learned a lot, but mysteries still abound.&nbsp;</p><p>And that is probably enough about newts for now.</p></p>","contentLength":9384,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44191620"},{"title":"Show HN: Air Lab – A portable and open air quality measuring device","url":"https://networkedartifacts.com/airlab/simulator","date":1749109345,"author":"256dpi","guid":184,"unread":true,"content":"<!DOCTYPE html>","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44189329"},{"title":"Tesla seeks to guard crash data from public disclosure","url":"https://www.reuters.com/legal/government/musks-tesla-seeks-guard-crash-data-public-disclosure-2025-06-04/","date":1749080447,"author":"kklisura","guid":229,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44186780"},{"title":"OpenAI slams court order to save all ChatGPT logs, including deleted chats","url":"https://arstechnica.com/tech-policy/2025/06/openai-says-court-forcing-it-to-save-all-chatgpt-logs-is-a-privacy-nightmare/","date":1749073653,"author":"ColinWright","guid":228,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44185913"},{"title":"Cursor 1.0","url":"https://www.cursor.com/en/changelog/1-0","date":1749069593,"author":"ecz","guid":227,"unread":true,"content":"<h2>BugBot, Background Agent access to everyone, and one-click MCP install</h2><p>This release brings BugBot for code review, a first look at memories, one-click MCP setup, Jupyter support, and general availability of Background Agent.</p><h3></h3><p>BugBot automatically reviews your PRs and catches potential bugs and issues.</p><p>When an issue is found, BugBot leaves a comment on your PRs in GitHub. You can click \"\" to move back to the editor with a pre-filled prompt to fix the issue.</p><h3></h3><p>Since we released Background Agent, our remote coding agent, in early access a few weeks ago, early signals have been positive.</p><p>We're now excited to expand Background Agent to all users! You can start using it right away by clicking the cloud icon in chat or hitting  if you have privacy mode disabled. For users with privacy mode enabled, we'll soon have a way to enable it for you too!</p><h3></h3><p>Cursor can now implement changes in Jupyter Notebooks!</p><p>Agent will now create and edit multiple cells directly inside of Jupyter, a significant improvement for research and data science tasks. Only supported with Sonnet models to start.</p><p>With Memories, Cursor can remember facts from conversations and reference them in the future. Memories are stored per project on an individual level, and can be managed from Settings.</p><p>We're rolling out Memories as a beta feature. To get started, enable from Settings → Rules.</p><h3></h3><p>You can now set up MCP servers in Cursor with one click, and together with OAuth support, you can easily authenticate servers that support it.</p><p>If you're an MCP developer, you can easily make your server available to developers by adding a  button in your documentation and READMEs. Generate one at <a target=\"_blank\" href=\"https://docs.cursor.com/deeplinks\">docs.cursor.com/deeplinks</a>.</p><p>Cursor can now render visualizations inside of a conversation. In particular, Mermaid diagrams and Markdown tables can now be generated and viewed in the same place!</p><h3></h3><p>The setting and dashboard page have gotten some polish with this release.</p><p>With the new Dashboard, you can view your individual or team's usage analytics, update your display name, and view detailed statistics broken down by tool or model.</p>","contentLength":2077,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44185256"},{"title":"A proposal to restrict sites from accessing a users’ local network","url":"https://github.com/explainers-by-googlers/local-network-access","date":1749060954,"author":"doener","guid":226,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44183799"},{"title":"IRS Direct File on GitHub","url":"https://chrisgiven.com/2025/05/direct-file-on-github/","date":1749053799,"author":"nickthegreek","guid":225,"unread":true,"content":"<p>Releasing Direct File’s source code demonstrates that the IRS is fulfilling its obligations under the <a href=\"https://www.congress.gov/bill/118th-congress/house-bill/9566\">SHARE IT Act</a> (three weeks ahead of schedule!). Now that Direct File has paved the way, I hope that more of the IRS’s code, paid for with taxpayer dollars, will soon be available to all of us.</p><p>Open sourcing Direct File has long been planned, and even longer desired. Explaining last May why open source is particularly important for Direct File, <a href=\"https://www.irs.gov/pub/irs-pdf/p5969.pdf\">the team wrote</a>:</p><blockquote><p>The IRS could take further steps to build public trust and enable independent assessment of its work. The Direct File product team was given the mandate to develop software that ensures every taxpayer receives the full benefit of any tax provisions for which they are eligible. Releasing components of Direct File as open-source software would enable the team to demonstrate this commitment.</p></blockquote><p>Establishing trust with taxpayers was core to our approach for designing and building Direct File. By creating the most accurate option for filing, by making taxes accessible to all, by keeping taxpayer data secure, and now, by publicly sharing Direct File’s code, the Direct File team showed our dedication to earning taxpayers’ trust.</p><p><em>Please note: As of two weeks ago, I no longer work at the IRS. I am writing solely in my personal capacity.</em></p>","contentLength":1303,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44182356"},{"title":"Prompt engineering playbook for programmers","url":"https://addyo.substack.com/p/the-prompt-engineering-playbook-for","date":1749052737,"author":"vinhnx","guid":224,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44182188"},{"title":"FFmpeg merges WebRTC support","url":"https://git.ffmpeg.org/gitweb/ffmpeg.git/commit/167e343bbe75515a80db8ee72ffa0c607c944a00","date":1749052730,"author":"Sean-Der","guid":223,"unread":true,"content":"\navformat/whip:&nbsp;Add&nbsp;WHIP&nbsp;muxer&nbsp;support&nbsp;for&nbsp;subsecond&nbsp;latency&nbsp;streaming\n1.&nbsp;The&nbsp;WHIP&nbsp;muxer&nbsp;has&nbsp;been&nbsp;renamed&nbsp;and&nbsp;refined,<p>\n&nbsp;&nbsp;&nbsp;&nbsp;with&nbsp;improved&nbsp;logging&nbsp;context&nbsp;and&nbsp;error&nbsp;messages&nbsp;for&nbsp;SSL,&nbsp;DTLS,&nbsp;and&nbsp;RTC.</p>\n2.&nbsp;Magic&nbsp;numbers&nbsp;have&nbsp;been&nbsp;replaced&nbsp;with&nbsp;macros&nbsp;and&nbsp;extracted&nbsp;to&nbsp;functions,<p>\n&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;log&nbsp;levels&nbsp;have&nbsp;been&nbsp;altered&nbsp;for&nbsp;better&nbsp;clarity.</p>\n3.&nbsp;DTLS&nbsp;curve&nbsp;list&nbsp;has&nbsp;been&nbsp;updated,<p>\n&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;SRTP&nbsp;profile&nbsp;names&nbsp;have&nbsp;been&nbsp;refined&nbsp;for&nbsp;FFmpeg&nbsp;and&nbsp;OpenSSL.</p>\n4.&nbsp;ICE&nbsp;STUN&nbsp;magic&nbsp;number&nbsp;has&nbsp;been&nbsp;refined,<p>\n&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;RTP&nbsp;payload&nbsp;types&nbsp;have&nbsp;been&nbsp;updated&nbsp;based&nbsp;on&nbsp;Chrome's&nbsp;definition.</p>\n5.&nbsp;Fixed&nbsp;frame&nbsp;size&nbsp;has&nbsp;been&nbsp;refined&nbsp;to&nbsp;rtc-&gt;audio_par-&gt;frame_size,<p>\n&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;h264_mp4toannexb&nbsp;is&nbsp;now&nbsp;used&nbsp;to&nbsp;convert&nbsp;MP4/ISOM&nbsp;to&nbsp;annexb.</p>\n6.&nbsp;OPUS&nbsp;timestamp&nbsp;issue&nbsp;has&nbsp;been&nbsp;addressed,<p>\n&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;marker&nbsp;setting&nbsp;has&nbsp;been&nbsp;corrected&nbsp;after&nbsp;utilizing&nbsp;BSF.</p>\n7.&nbsp;DTLS&nbsp;handshake&nbsp;and&nbsp;ICE&nbsp;handling&nbsp;have&nbsp;been&nbsp;optimized&nbsp;for&nbsp;improved&nbsp;performance,<p>\n&nbsp;&nbsp;&nbsp;&nbsp;with&nbsp;a&nbsp;single&nbsp;handshake&nbsp;timeout&nbsp;and&nbsp;server&nbsp;role&nbsp;to&nbsp;prevent&nbsp;ARQ.</p>\n8.&nbsp;Consolidated&nbsp;ICE&nbsp;request/response&nbsp;handling&nbsp;and&nbsp;DTLS&nbsp;handshake&nbsp;into&nbsp;a&nbsp;single&nbsp;function,<p>\n&nbsp;&nbsp;&nbsp;&nbsp;and&nbsp;fixed&nbsp;OpenSSL&nbsp;build&nbsp;errors&nbsp;to&nbsp;work&nbsp;with&nbsp;Pion.</p>\n9.&nbsp;Merge&nbsp;TLS&nbsp;&amp;&nbsp;DTLS&nbsp;implementation,&nbsp;shared&nbsp;BIO&nbsp;callbacks,&nbsp;read,&nbsp;write,<p>\n&nbsp;&nbsp;&nbsp;&nbsp;print_ssl_error,&nbsp;openssl_init_ca_key_cert,</p>\n&nbsp;&nbsp;&nbsp;&nbsp;init_bio_method&nbsp;function&nbsp;and&nbsp;shared&nbsp;same&nbsp;data&nbsp;structure<p>\n10.&nbsp;Modify&nbsp;configure&nbsp;that&nbsp;whip&nbsp;is&nbsp;enabled&nbsp;only&nbsp;dtls&nbsp;is</p>\n&nbsp;&nbsp;&nbsp;&nbsp;enabled(just&nbsp;support&nbsp;openssl&nbsp;for&nbsp;now)&nbsp;to&nbsp;fix&nbsp;build&nbsp;error","contentLength":1608,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44182186"},{"title":"The Right to Repair Is Law in Washington State","url":"https://www.eff.org/deeplinks/2025/06/right-repair-law-washington-state","date":1749049229,"author":"doener","guid":222,"unread":true,"content":"<p>Thanks in part <a href=\"https://www.eff.org/deeplinks/2025/05/washingtons-right-repair-bill-heads-governor\">to your support</a>, the right to repair is now law in Washington.</p><p>Gov. Bob Ferguson signed two bills guaranteeing Washingtonians' right to access tools, parts, and information so they can fix personal electronics, appliances, and wheelchairs. This is the epitome of common-sense legislation. When you own something, you should have the final say about who fixes, adapts, or modifies it—and how.</p><p>When you own something, you should have the final say about who fixes, adapts, or modifies it—and how.</p><p>Advocates in Washington have worked for years to pass a strong right-to-repair law in the state. In addition to Washington’s <a href=\"https://pirg.org/washington/updates/washington-becomes-eighth-state-with-right-to-repair-law-on-the-books/\">Public Interest Research Group</a>, the consumer electronics bill moved forward with a growing group of supporting organizations, including environmental advocates, consumer advocates, and manufacturers such as Google and Microsoft. Meanwhile, advocacy from groups including&nbsp; <a href=\"https://disabilityrightswa.org/\">Disability Rights Washington</a>&nbsp;and the <a href=\"https://www.hereandnowproject.org/\">Here and Now Project</a> made the case for the wheelchair's inclusion in the right-to-repair bill, bringing their personal stories to Olympia to show why this bill was so important.</p><p>And it’s not just states that recognize the need for people to be able to fix their own stuff.&nbsp; Earlier this month, U.S. Secretary of Defense Pete Hegseth&nbsp;<a href=\"https://media.defense.gov/2025/May/01/2003702281/-1/-1/1/ARMY-TRANSFORMATION-AND-ACQUISITION-REFORM.PDF\">issued a memo</a> stating that the Army should “[identify] and propose contract modifications for right to repair provisions where intellectual property constraints limit the Army's ability to conduct maintenance and access the appropriate maintenance tools, software, and technical data – while preserving the intellectual capital of American industry.” The memo said that the Army should seek this in future procurement contracts and also to amend existing contracts to include the right to repair.</p><p>This is a bedrock of sound procurement with a long history in America. President Lincoln only bought rifles with standardized tooling to outfit the Union Army, for the obvious reason that it would be a little embarrassing for the Commander in Chief to have to pull his troops off the field because the Army’s sole supplier had decided not to ship this week’s delivery of ammo and parts. Somehow, the Department of Defense forgot this lesson over the ensuing centuries, so that today, billions of dollars in public money are spent on material and systems that the US military can only maintain by buying service from a “beltway bandit.”</p><p>This recognizes what millions of people have said repeatedly: limiting people’s ability to fix their own stuff stands in the way of needed repairs and maintenance. That’s true whether you’re a farmer with a broken tractor during harvest, a homeowner with a misbehaving washing machine or a cracked smartphone screen, a hospital med-tech trying to fix a ventilator, or a soldier struggling with a broken generator.</p><p>The right to repair is gaining serious momentum. All 50 states have now considered some form of right-to-repair legislation. Washington is the eighth state to pass one of these bills into law—let’s keep it up.</p><p><em>Correction: An earlier version of this post misstated that Secretary of the Army Dan Driscoll issued the memo, rather than U.S. Secretary of Defense Pete Hegseth. This post has been corrected.</em></p>","contentLength":3254,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44181421"},{"title":"The time bomb in the tax code that's fueling mass tech layoffs","url":"https://qz.com/tech-layoffs-tax-code-trump-section-174-microsoft-meta-1851783502","date":1749043821,"author":"booleanbetrayal","guid":221,"unread":true,"content":"<p>For the past two years, it’s been a ghost in the machine of American tech.</p><p> Between 2022 and today, a little-noticed tweak to the U.S. tax code has quietly rewired the financial logic of how American companies invest in research and development. Outside of , almost no one knew it existed. “I work on these tax write-offs and still hadn’t heard about this,” a chief operating officer at a private-equity-backed tech company told Quartz. “It’s just been so weirdly silent.”</p><p>Still, the delayed change to a decades-old tax provision — buried deep in the 2017 tax law — has contributed to the loss of hundreds of thousands of high-paying, white-collar jobs. That’s the picture that emerges from a review of corporate filings, public financial data, analysis of timelines, and interviews with industry insiders. One accountant, working in-house at a tech company, described it as a “niche issue with broad impact,” echoing sentiments from venture capital investors also interviewed for this article. Some spoke on condition of anonymity to discuss sensitive political matters.</p><p>Since the start of 2023, more than half-a-million tech workers have been laid off, according to . Headlines have blamed over-hiring during the pandemic and, more recently, . But beneath the surface was a hidden accelerant: a change to what’s known as Section 174 that helped gut in-house software and product development teams everywhere from tech giants such as Microsoft () and Meta () to much smaller, private, direct-to-consumer and other internet-first companies.</p><p>Now, as a  to repeal the Section 174 change moves through Congress, bigger questions are surfacing: How did a single line in the tax code help trigger a tsunami of mass layoffs? And why did no one see it coming? </p><h2>A tax break that built the modern tech economy</h2><p>For almost 70 years, American companies could deduct 100% of qualified research and development spending in the year they incurred the costs. Salaries, software, contractor payments — if it contributed to creating or improving a product, it came off the top of a firm’s taxable income.</p><p>The subsequent rise of smartphones, cloud computing, and mobile apps also happened in an America where companies could immediately write off their investments in engineering, infrastructure, and experimentation. It was a baseline assumption — innovation and risk-taking subsidized by the tax code — that shaped how founders operated and how investors made decisions.</p><p>In turn, tech companies largely built their products in the U.S. </p><p>Microsoft’s operating systems were coded in Washington state. Apple’s early hardware and software teams were in California. Google’s search engine was born at Stanford and scaled from Mountain View. Facebook’s entire social architecture was developed in Menlo Park. The deduction directly incentivized keeping R&amp;D close to home, rewarding companies for investing in American workers, engineers, and infrastructure.</p><p>That’s what makes the politics of Section 174 so revealing. For  about bringing jobs back and making things in America, the first Trump administration’s major tax bill arguably helped accomplish the opposite.</p><h2>Undercutting the incentive structure</h2><p>When Congress passed the  (TCJA), the signature legislative achievement of President Donald Trump’s first term, it slashed the corporate tax rate from 35% to 21% — a massive revenue loss on paper for the federal government.</p><p>To make the 2017 bill comply with Senate budget rules, lawmakers needed to offset the cost. So they added future tax hikes that wouldn’t kick in right away, wouldn’t provoke immediate backlash from businesses, and could, in theory, be quietly repealed later.</p><p>The delayed change to Section 174 — from immediate expensing of R&amp;D to mandatory amortization, meaning that companies must spread the deduction out in smaller chunks over five or even 15-year periods — was that kind of provision. It didn’t start affecting the budget until 2022, but it helped the TCJA appear “deficit neutral” over the 10-year window used for legislative scoring.</p><p>The delay wasn’t a technical necessity. It was a political tactic. Such moves are. Phase-ins and delayed provisions let lawmakers game how the Congressional Budget Office (CBO) — Congress’ nonpartisan analyst of how bills impact budgets and deficits — scores legislation, pushing costs or revenue losses outside official forecasting windows.</p><p>And so, on schedule in 2022, the change to Section 174 went into effect. Companies filed their 2022 tax returns under the new rules in early 2023. And suddenly, R&amp;D wasn’t a full, immediate write-off anymore. The tax benefits of salaries for engineers, product and project managers, data scientists, and even some user experience and marketing staff — all of which had previously reduced taxable income in year one — now had to be spread out over five- or 15-year periods. </p><p>To understand the impact, imagine a personal tax code change that allowed you to deduct 100% of your biggest source of expenses, and that becoming a 20% deduction. For cash-strapped companies, especially those not yet profitable, the result was a painful tax bill just as venture funding dried up and interest rates soared.</p><p>It’s no coincidence that Meta announced its “Year of Efficiency”  the Section 174 change took effect. Ditto Microsoft laying off 10,000 employees in  despite strong earnings, or Google parent Alphabet 12,000 jobs around the same time.</p><p>Amazon () also laid off almost 30,000 people, with  not just on logistics but on Alexa and internal cloud tools — precisely the kinds of projects that would have once qualified as immediately deductible R&amp;D. Salesforce ()  10% of its staff, or 8,000 people, including entire product teams.</p><p>In public, companies blamed bloat and AI. But inside boardrooms, spreadsheets were telling a quieter story. And  notes — management’s notes on the numbers — buried deep in 10-K filings recorded the change, too. R&amp;D had become more expensive to carry. Headcount, the leading R&amp;D expense across the tech industry, was the easiest thing to cut.</p><p>In its , Meta described salaries as its single biggest R&amp;D expense. Between the first and second years that the Section 174 change began affecting tax returns, Meta cut its total workforce by almost 25%. Over the same period, Microsoft reduced its global headcount by about 7%, with cuts concentrated in product-facing, engineering-heavy roles.</p><p>Smaller companies without the fortress-like balance sheets of Big Tech have arguably been hit even harder. Twilio () 22% of its workforce in 2023 alone. Shopify () (headquartered in Canada but with much of its R&amp;D teams in the U.S.) in 2022 and 2023. Coinbase ()  by 36% across a pair of brutal restructuring waves.</p><p>Since going into effect, the provision has hit at the very heart of America’s economic growth engine: the tech sector.</p><p>By market cap, tech giants dominate the S&amp;P 500, with  alone accounting for  of the index’s total value. Workforce numbers tell a similar story, with tech employing millions of Americans directly and supporting the employment of tens of millions more. As measured by GDP, contributes about 10% of national output.</p><p>It’s not just that tech layoffs were large, it’s that they were massively disproportionate. Across the broader U.S. economy, job cuts hovered around in low single digits across most sectors. But in tech, entire divisions vanished, with a  in layoffs between 2022 and 2023. Some cuts reflected real inefficiencies — a response to over-hiring during the zero-interest rate boom. At the same time, many of the roles eliminated were in R&amp;D, product, and engineering, precisely the kind of functions that had once benefitted from generous tax treatment under Section 174.</p><h2>A crippling change even outside tech</h2><p>Throughout the 2010s, a broad swath of startups, direct-to-consumer brands, and internet-first firms — basically every company you recognize from Instagram or Facebook ads — built their growth models around a kind of engineered break-even.</p><p>The tax code allowed them to spend aggressively on product and engineering, then write it all off as R&amp;D, keeping their taxable income close to zero by design. It worked because taxable income and actual cash flow were often notquitethe same thing under what’s known as  accounting practices. Basically, as long as spending counted as R&amp;D, companies could report losses to investors while owing almost nothing to the IRS.</p><p>But the Section 174 change broke that model. Once those same expenses had to be spread out, or amortized, over multiple years, the tax shield vanished. Companies that were still burning cash suddenly looked profitable on paper, triggering real tax bills on imaginary gains.</p><p>The logic that once fueled a generation of digital-first growth collapsed overnight.</p><p>So it wasn’t just tech experiencing effects. From 1954 until 2022, the U.S. tax code had encouraged businesses of all stripes to behave like tech companies. From retail to logistics, healthcare to media, if firms built internal tools, customized a software stack, or invested in business intelligence and data-driven product development, they could expense those costs. The write-off incentivized in-house builds and fast growth well outside the capital-T tech sector. This lines up with  showing that immediate deductions foster innovation more than spread-out ones.</p><p>And American companies ran with that logic. According to government data, U.S. businesses reported about $500 billion in  in 2019 alone, and almost half of that came from industries outside traditional tech. The Bureau of Economic Analysis estimates that this sector, the broader digital economy,  for another 10% of GDP.</p><p>Add that to core tech’s contribution, and the Section 174 shift has likely touched at least 20% of the U.S. economy.</p><p>The result? A tax policy aimed at raising short-term revenue effectively hid a time bomb inside the growth engines of thousands of companies. And when it detonated, it kneecapped the incentive for hiring American engineers or investing in American-made tech and digital products.</p><p>It made building tech companies in America look irrational on a spreadsheet.</p><p>A bipartisan group of lawmakers is  the Section 174 change, with business groups, CFOs, crypto executives, and venture capitalists lobbying hard for retroactive relief. But the politics are messy. Fixing 174 would mean handing a tax break to the same companies many voters in both parties see as symbols of corporate excess. Any repeal would also come too late for the hundreds of thousands of workers already laid off.</p><p>And of course, the losses don’t stop at Meta’s or Google’s campus gates. They ripple out. When high-paid tech workers disappear, so do the lunch orders. The . The contract gigs. The spending habits that sustain entire urban economies and thousands of other jobs. Sandwich artists. Rideshare drivers. Realtors. Personal trainers. House cleaners. In tech-heavy cities, the fallout runs deep — and it’s still unfolding.</p><p>Washington is now poised to pass a second Trump tax bill — one packed with more, more , more quiet redistribution. And it comes as analysts are only just beginning to understand the real-world effects of the last round.</p><p>The Section 174 change “significantly increased the tax burden on companies investing in innovation, potentially stifling economic growth and reducing the United States’ competitiveness on the global stage,” according to the tax consulting firm KBKG. </p><p>Whether the U.S. will reverse course — or simply adapt to a new normal — remains to be seen.</p>","contentLength":11630,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44180533"},{"title":"Why I wrote the BEAM book","url":"https://happihacking.com/blog/posts/2025/why_I_wrote_theBEAMBook/","date":1749033409,"author":"lawik","guid":220,"unread":true,"content":"<h2> Why I Wrote the BEAM Book </h2><h3> Post-mortems, coffee, and a decade of stubborn curiosity </h3>\n\n\tPosted:  2025-06-03<h2>Why I wrote the Beam Book</h2><p>After ten years of keeping Klarna’s core system upright I know this: a 15\nmillisecond pause in the BEAM can stall millions of peak-shopping payments, trigger a 3 a.m. Christmas-Eve post-mortem, and earn you a very awake call from the CEO. I wrote  so the next engineer fixes that pause before the coffee cools.</p><img src=\"https://happihacking.com/images/thebeambooks.jpg\" alt=\"A picture of two printed BEAM Books.\"><p>I opened the project on 12 October 2012 with a lone DocBook file with four lines of text and an oversized sense of optimism.\nAfter two weeks, the commit log is mostly me adding structure, moving\nheadings, and updating metadata. Most of it is scaffolding. The actual\ncontent is still just a few hopeful lines.</p><p>By November I had abandoned DocBook for AsciiDoc, written a custom build\nscript, and convinced myself the book could be wrapped up in six months.\nThose early commits glow with energy: adds, rewrites, then more\nrewrites to fix the rewrites.\nDelusion is underrated.</p><p>In 2013 I managed to convince O’Reilly to publish. Moving the repo to their\nAtlas system sounded simple until Atlas began hiding my main file and\noverwriting half-finished chapters.</p><p>The Git history reads like a diary of frustration:\n“Moving files to top level to cope with Atlas,” “Atlas seems to be\noverwriting book.asciidoc”. Word count shot past 120 000 while actual\nprogress crawled. On 10 March 2015 I was literally “Smashing chapters into sections” just to keep the build green.</p><p>The quiet cancellation came two months later. No drama, just a polite call and a line through the contract. Relief mingled with embarrassment, I had spent two years rearranging files rather than finishing sentences.</p><p>Pragmatic Bookshelf took over that same year. I kept working in CVS for\ntheir production system, but progress was slow. Eventually, they cancelled\ntoo. On 20 January 2017, I imported everything into a new repo in one\nmassive commit: 6,622 files, over a million lines.\nThe rewrite stalled, and so did the project.</p><p>On 23 March 2017 I started fresh with Asciidoctor in a private GitHub repo, copy-pasting\nonly the parts that still made sense. Two weeks later, on April 7, minutes before\na lecture at Chalmers, I flipped the repository public. Within twenty-four\nhours strangers fixed typos, added diagrams, and merged a Creative Commons\nBY-4.0 license.</p><img src=\"https://api.star-history.com/svg?repos=happi/theBeamBook&amp;type=Date\" alt=\"A picture of the stars on GitHub passing 3000.\"><p>I kept going because I wanted to understand the BEAM properly. There’s\nvalue in following the real logic, not just the surface explanations.</p><p>Community feedback made a difference. As soon as the repo was public,\npeople began sending corrections, examples, and improvements.</p><p>Seeing the numbers of people starring the repo on GitHub kept me going.\nOne highlight: <strong>Issue #113 - “Please continue being awesome.”</strong>\nThat emoji-laced drive-by encouragement (August 2018) still pops into my\nhead whenever motivation dips.</p><p>The book started showing up as a reference in Erlang and BEAM conference\ntalks, sometimes several times in the same event. That was a clear signal\nthat others needed this as much as I did.</p><p>Even Twitter (in the good old days of Twitter) played a role. Whenever\nsomeone mentioned the book or shared a\nlink, it was an extra nudge to keep at it.</p><p>Mostly, I just wanted a manual I could trust myself, a reference for the\nparts of the VM that matter when things go wrong. That’s reason enough to\nkeep writing, even after the third rewrite.</p><h3>What’s Inside the Book &amp; Who It Helps</h3><p>The book covers what I wish I’d had when building and operating large\nErlang systems:</p><ul><li>Schedulers and process management: How the BEAM schedules,\nprioritizes, and balances processes under real load.</li><li>Processes and their memory: How process heaps,\nstack, messages, and binaries are managed and\nwhy these details matter in production.</li><li>Garbage collection and memory: What actually happens\nwith per-process and global garbage collectors, binary references,\nand memory leaks.</li><li>Tagging schemes and terms: How the BEAM represents data-integers,\nfloats, tuples, binaries, references-down to the tagging bits.</li><li>The compiler and the VM: How code is turned into instructions,\nwhat the compiler does (and doesn’t do), and how the emulator executes it.</li><li>Tracing and debugging: Practical use of dbg, erlang:trace,\nand other tools to follow messages, events, and identify bottlenecks.</li><li>Performance tuning: What matters when profiling real code,\nunderstanding reductions, and tracking down real-world latency problems.</li><li>System architecture: How ERTS, the BEAM VM, and their subsystems\nactually work together in a running node.</li></ul><p>If you build or operate Erlang or Elixir systems, especially under any kind\nof scale-this book is for you. It saves you from hunting through mailing\nlists, scattered docs, and code comments just to answer, “Why is the VM\nbehaving like this?”</p><p>Persistence beats perfection. Two cancelled publishing deals look bad on a\nrésumé, but an unfinished idea looks worse.</p><p>Boundaries matter. I made progress by blocking time for writing, turning\noff notifications, and treating focus like a real deadline. Fika at 14:30\nis non-negotiable.</p><p>The crowd helps. Making the repo public brought in corrections,\nencouragement, and the occasional nudge when motivation was low.</p><p>Scope is everything. I cut the details on dirty schedulers, the new JIT,\nand the debugger. Maybe those will end up in an appendix, but not in the\ncore.</p><p>Ship, then iterate. The BEAM changes every year. A living Git repo keeps\nup.</p><p>A real deadline helps. This January, during my yearly review, I\ndecided to print the book in time for Code Beam Stockholm. I thought I had\nuntil autumn, turns out the conference was June 2. That’s how you find out\nwhat’s truly essential.</p><p>Holding the print in my hands, it finally feels finished, at least for now. Years of scattered commits are bound into something real, so I’m calling it done.</p><p>You can now get the paperback-The BEAM Book 1.0 is live on Amazon. Buy it\nhere.&nbsp;<a href=\"https://www.amazon.com/dp/9153142535\">Amazon</a></p><p>If you spot an error, want to improve something, or just want to see how it\nworks under the hood, star or fork the repo. File an issue or, even better,\nsubmit a pull request. Contributors are credited in the acknowledgments.\n<a href=\"https://github.com/happi/theBeamBook\">GitHub: theBeamBook</a></p><p>If you read the book, please leave an honest review.\nAlgorithms notice real feedback more than marketing copy.</p><p>If your team wants a deep dive, I run hands-on BEAM internals\nworkshops, tailored for real systems, not just hello world.\nEmail me if that’s what you need.\n<a href=\"mailto:happi@happihacking.com\">happi@happihacking.com</a></p>","contentLength":6464,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44179257"},{"title":"Merlin Bird ID","url":"https://merlin.allaboutbirds.org/","date":1749005920,"author":"twitchard","guid":219,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44176829"},{"title":"Deep learning gets the glory, deep fact checking gets ignored","url":"https://rachel.fast.ai/posts/2025-06-04-enzyme-ml-fails/index.html","date":1748986316,"author":"chmaynard","guid":218,"unread":true,"content":"<p>Deep learning is glamorous and highly rewarded. If you train and evaluate a Transformer (a state-of-the-art language model) on a dataset of 22 million enzymes and then use it to predict the function of 450 unknown enzymes, you can publish your results in Nature Communications (a very well-regarded publication). Your paper will be viewed 22,000 times and will be in the top 5% of all research outputs scored by Altmetric (a rating of how much attention online articles receive).</p><p>However, if you do the painstaking work of combing through someone else’s published work, and discovering that they are riddled with serious errors, including hundreds of incorrect predictions, you can post a pre-print to bioRxiv that will not receive even a fraction of the citations or views of the original. In fact, this is exactly what happened in the case of these two papers:</p><div><figure><figcaption>A Tale of two Altmetric Scores</figcaption></figure></div><p>This pair of papers on enzyme function prediction make for a fascinating case study on the limits of AI in biology and the harms of current publishing incentives. I will walk through some of the details below, although I encourage you to read the papers for yourself. This contrast is a stark reminder of how hard it can be to evaluate the legitimacy of AI results without deep domain expertise.</p><section><h2 data-anchor-id=\"the-problem-of-determining-enzyme-function\">The Problem of Determining Enzyme Function</h2><p>Enzymes are what catalyze reactions, so they are crucial for making things happen in living organisms. Enzyme Commission (EC) numbers provide a hierarchical classification system for thousands of different functions. Given a sequence of amino acids (the building blocks of all proteins, including enzymes), can you predict what the EC number (and thus, the function) is? This seems like a problem that is custom-made for machine learning, with clearly defined inputs and outputs. Moreover, there is a rich dataset available, with over 22 million enzymes and their EC numbers listed in the online database UniProt.</p></section><section><p>The Transformer model in the Nature Communications paper made hundreds of “novel” predictions that are almost certainly erroneous. The paper had followed a standard methodology of evaluating performance on a held-out test set, and did quite well on that (although later investigation suggests there may have been <a href=\"https://www.kaggle.com/code/alexisbcook/data-leakage\">data leakage</a>). The results claimed for enzymes where no ground truth is known were full of errors.</p><p>For instance, the gene  YjhQ was predicted to be a mycothiol synthase, but mycothiol is not synthesized by  at all! The gene yciO, which evolved from the gene TsaC, had already been shown a decade earlier  to not have the same function as TsaC, yet the Nature Communications paper concluded it did have the same function.</p><p>Of the 450 “novel” results given in the paper, 135 of these results were not novel at all; they were already listed in the online database UniProt. Another 148 showed unreasonably high levels of repetition, with the same very specific enzyme functions reappearing up to 12 times for genes of , which biologically implausible.</p><div><figure><figcaption>Most of the “novel” results from the transformer paper were either not novel, unusually repetitious, or incorrect paralogs (Fig 5 from de Crecy, et al.)</figcaption></figure></div></section><section><h2 data-anchor-id=\"the-microbiology-detective\">The Microbiology Detective</h2><p>How did these errors come to light? After the model had been trained, validated, and evaluated on a dataset involving millions of entries, it was used to make ~450 novel predictions, and three of these were tested in vitro. It just so happens that one of the enzymes selected for in vitro testing, yciO, had already been studied extensively over a decade earlier by Dr.&nbsp;de Crécy-Lagard. When Dr.&nbsp;de Crécy-Lagard read that deep learning had predicted that yciO had the same function of another gene, TsaC, she knew from her long years in the lab that this was incorrect. Her previous research had shown that the TsaC gene is essential in  even if yciO is present in the same genome and even when yciO gene is overexpressed. Moreover, the yciO activity reported by Kim et al.&nbsp;is more than four orders of magnitude (i.e.&nbsp;10,000 times) weaker than that of TsaC. All this suggests that yciO does NOT serve the same key function as TsaC.</p><div><figure><figcaption>Two enzymes with a common evolutionary ancestor, but different functions (Fig 7 from de Crecy, et al.)</figcaption></figure></div><p>YciO and TsaC do have structural similarities, and YciO evolved from an ancestor of TsaC. Decades of research on protein and enzyme evolution have shown that new functions often evolve via duplication of an existing gene, followed by diversification of its function. This poses a common pitfall in determining enzyme function, because the genes will have many similarities with the ones they duplicated and then diversified from.</p><p>Thus, looking at structural similarities is only one type of evidence for considering enzyme function. It is also crucial to look at other types of evidence, such as neighborhood context of the genes, substrate docking, gene co-occurrence in metabolic pathways, and other features of the enzymes.</p><div><figure><figcaption>It is important to look at multiple types of evidence when classifying enzyme function (Fig 2 from de Crecy, et al.)</figcaption></figure></div></section><section><h2 data-anchor-id=\"hundreds-of-likely-erroneous-results\">Hundreds of Likely Erroneous Results</h2><p>Spotting this one error inspired de Crécy-Lagard and her co-authors to take a closer look at all of the enzymes found to have novel results in the Kim, et al, paper. They found that 135 of these results were already listed in the online database used to build the training set and thus not actually novel. An additional 148 of the results contained a very high level of repetition, with the same highly specific functions reappearing up to 12 times. Biases, data imbalance, lack of relevant features, architectural limitations, or poor uncertainty calibration can all lead models to “force” the most common labels from the training data.</p><p>Other examples were proven wrong via biological context or a literature search. For instance, the gene YjhQ was predicted to be a mycothiol synthase but mycothiol is not synthesized by . YrhB was predicted to synthesize a particular compound, which was already predicted to be synthesized by the enzyme QueD. A form of  with a QueD mutant was unable to synthesize the compound, showing that this is not in fact the function of YrhB.</p></section><section><h2 data-anchor-id=\"rethinking-enzyme-classification-and-true-unknowns\">Rethinking Enzyme Classification and “True Unknowns”</h2><p>Identifying enzyme function actually consists of two quite different problems which are commonly conflated:</p><ul><li>propagating known function labels to enzymes in the same functional family</li><li>discovering truly unknown functions</li></ul><p>The authors of the second paper observe, “By design, supervised ML-models cannot be used to predict the function of true unknowns.” While machine learning can be useful for propagating known functions to additional enzymes, there are many types of errors that can occur: including failing to propagate labels when they should, propagating labels when they should not, curation mistakes, and experimental mistakes. Unfortunately, erroneous functions are being entered into key online databases such as UniProt, and this incorrect data may be further propagated if it is used to train prediction models. This is a problem that increases over time.</p></section><section><h2 data-anchor-id=\"need-for-domain-expertise\">Need for Domain Expertise</h2><p>It is not news that AI work will be more highly rewarded and supported than work that closely inspects the underlying data and integrates deep domain knowledge. The aptly titled <a href=\"https://research.google/pubs/everyone-wants-to-do-the-model-work-not-the-data-work-data-cascades-in-high-stakes-ai/\">“Everyone Wants to do the Model Work, not the Data Work”</a> paper involving dozens of machine learning practitioners working on high-stakes AI projects and found that inadequate-application domain expertise was one of a few key causes of catastrophic failures.</p><div><figure><figcaption>Sources of cascading failures in machine learning systems (Fig 1 from Sambasivan, et al.)</figcaption></figure></div><p>These papers also serve as a reminder of how challenging (or even impossible) it can be to evaluate AI claims in work outside our own area of expertise. I am not a domain expert in the enzyme functions of . And for most deep learning papers I read, domain experts have not gone through the results with a fine-tooth comb inspecting the quality of the output. How many other seemingly-impressive papers would not stand up to scrutiny? The work of checking hundreds of enzyme predictions is less glamorous than the work of building the AI model that generated them, yet it is even more important. How can we better incentivize this type of error-checking research?</p><p>At a time when funding is being slashed, I believe we should be doing the opposite and investing even more into a range of scientific and biomedical research, from a variety of angles. And we need to push back on an incentive system that is disproportionately focused on flashy AI solutions at the expense of quality results.</p></section><p><i>I look forward to reading your responses. Create a free GitHub account to comment below.</i></p>","contentLength":8729,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44174965"},{"title":"Covert web-to-app tracking via localhost on Android","url":"https://localmess.github.io/","date":1748952748,"author":"sebastian_z","guid":217,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44169115"},{"title":"EU Commission refuses to disclose authors behind its mass surveillance proposal","url":"https://old.reddit.com/r/europe/comments/1l2655n/the_eu_commission_refuses_to_disclose_the/","date":1748943743,"author":"nickslaughter02","guid":216,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44168134"},{"title":"Quarkdown: A modern Markdown-based typesetting system","url":"https://github.com/iamgio/quarkdown","date":1748937988,"author":"asicsp","guid":215,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44167592"},{"title":"My AI skeptic friends are all nuts","url":"https://fly.io/blog/youre-all-nuts/","date":1748898593,"author":"tabletcorry","guid":214,"unread":true,"content":"<div><p>A heartfelt provocation about AI-assisted programming.</p></div><p>Tech execs are mandating LLM adoption. That’s bad strategy. But I get where they’re coming from.</p><p>Some of the smartest people I know share a bone-deep belief that AI is a fad —  the next iteration of NFT mania. I’ve been reluctant to push back on them, because, well, they’re smarter than me. But their arguments are unserious, and worth confronting. Extraordinarily talented people are doing work that LLMs already do better, out of  spite.</p><p>All progress on LLMs could halt today, and LLMs would remain the 2nd most important thing to happen over the course of my career.</p><div><p>: I’m discussing only the implications of LLMs for software development. For art, music, and writing? I got nothing. I’m inclined to believe the skeptics in those fields. I just don’t believe them about mine.</p></div><p>Bona fides: I’ve been shipping software since the mid-1990s. I started out in boxed, shrink-wrap C code.  Survived an ill-advised <a href=\"https://www.amazon.com/Modern-Design-Generic-Programming-Patterns/dp/0201704315\" title=\"\">Alexandrescu</a> C++ phase. Lots of Ruby and Python tooling.  Some kernel work. A whole lot of server-side C, Go, and Rust. However you define “serious developer”, I qualify. Even if only on one of your lower tiers.</p><div><p>† (or, God forbid, 2 years ago with Copilot)</p></div><p>First, we need to get on the same page. If you were trying and failing to use an LLM for code 6 months ago †, you’re not doing what most serious LLM-assisted coders are doing.</p><p>People coding with LLMs today use agents. Agents get to poke around your codebase on their own. They author files directly. They run tools. They compile code, run tests, and iterate on the results. They also:</p><ul><li>pull in arbitrary code from the tree, or from other trees online, into their context windows,\n</li><li>run standard Unix tools to navigate the tree and extract information,\n</li><li>run existing tooling, like linters, formatters, and model checkers, and\n</li><li>make essentially arbitrary tool calls (that you set up) through MCP.\n</li></ul><div><p>The code in an agent that actually “does stuff” with code is not, itself, AI. This should reassure you. It’s surprisingly simple systems code, wired to ground truth about programming in the same way a Makefile is. You could write an effective coding agent in a weekend. Its strengths would have more to do with how you think about and structure builds and linting and test harnesses than with how advanced o3 or Sonnet have become.</p></div><p>If you’re making requests on a ChatGPT page and then pasting the resulting (broken) code into your editor, you’re not doing what the AI boosters are doing. No wonder you’re talking past each other.</p><p>LLMs can write a large fraction of all the tedious code you’ll ever need to write. And most code on most projects is tedious. LLMs drastically reduce the number of things you’ll ever need to Google. They look things up themselves. Most importantly, they don’t get tired; they’re immune to inertia.</p><p>Think of anything you wanted to build but didn’t. You tried to home in on some first steps. If you’d been in the limerent phase of a new programming language, you’d have started writing. But you weren’t, so you put it off, for a day, a year, or your whole career.</p><p>I can feel my blood pressure rising thinking of all the bookkeeping and Googling and dependency drama of a new project. An LLM can be instructed to just figure all that shit out. Often, it will drop you precisely at that golden moment where shit almost works, and development means tweaking code and immediately seeing things work better. That dopamine hit is why I code.</p><p>There’s a downside. Sometimes, gnarly stuff needs doing. But you don’t wanna do it. So you refactor unit tests, soothing yourself with the lie that you’re doing real work. But an LLM can be told to go refactor all your unit tests. An agent can occupy itself for hours putzing with your tests in a VM and come back later with a PR. If you listen to me, you’ll know that. You’ll feel worse yak-shaving. You’ll end up doing… real work.</p><h3><a href=\"https://fly.io/blog/youre-all-nuts/#but-you-have-no-idea-what-the-code-is\" aria-label=\"Anchor\"></a></h3><p>Are you a vibe coding Youtuber? Can you not read code? If so: astute point. Otherwise: what the fuck is wrong with you?</p><p>You’ve always been responsible for what you merge to . You were five years go. And you are tomorrow, whether or not you use an LLM.</p><p>If you build something with an LLM that people will depend on, read the code. In fact, you’ll probably do more than that. You’ll spend 5-10 minutes knocking it back into your own style. LLMs are <a href=\"https://github.com/PatrickJS/awesome-cursorrules\" title=\"\">showing signs of adapting</a> to local idiom, but we’re not there yet.</p><p>People complain about LLM-generated code being “probabilistic”. No it isn’t. It’s code. It’s not Yacc output. It’s knowable. The LLM might be stochastic. But the LLM doesn’t matter. What matters is whether you can make sense of the result, and whether your guardrails hold.</p><p>Reading other people’s code is part of the job. If you can’t metabolize the boring, repetitive code an LLM generates: skills issue! How are you handling the chaos human developers turn out on a deadline?</p><div><p>† (because it can hold 50-70kloc in its context window)</p></div><p>For the last month or so, Gemini 2.5 has been my go-to †. Almost nothing it spits out for me merges without edits. I’m sure there’s a skill to getting a SOTA model to one-shot a feature-plus-merge! But I don’t care. I like moving the code around and chuckling to myself while I delete all the stupid comments. I have to read the code line-by-line anyways.</p><p>If hallucination matters to you, your programming language has let you down.</p><p>Agents lint. They compile and run tests. If their LLM invents a new function signature, the agent sees the error. They feed it back to the LLM, which says “oh, right, I totally made that up” and then tries again.</p><p>You’ll only notice this happening if you watch the chain of thought log your agent generates. Don’t. This is why I like <a href=\"https://zed.dev/agentic\" title=\"\">Zed’s agent mode</a>: it begs you to tab away and let it work, and pings you with a desktop notification when it’s done.</p><p>I’m sure there are still environments where hallucination matters. But “hallucination” is the first thing developers bring up when someone suggests using LLMs, despite it being (more or less) a solved problem.</p><h3><a href=\"https://fly.io/blog/youre-all-nuts/#but-the-code-is-shitty-like-that-of-a-junior-developer\" aria-label=\"Anchor\"></a></h3><p>Does an intern cost $20/month? Because that’s what Cursor.ai costs.</p><p>Part of being a senior developer is making less-able coders productive, be they fleshly or algebraic. Using agents well is both a both a  skill and an engineering project all its own, of prompts, indices, <a href=\"https://fly.io/blog/semgrep-but-for-real-now/\" title=\"\">and (especially) tooling.</a> LLMs only produce shitty code if you let them.</p><div><p>† (Also: 100% of all the Bash code you should author ever again)</p></div><p>Maybe the current confusion is about who’s doing what work. Today, LLMs do a lot of typing, Googling, test cases †, and edit-compile-test-debug cycles. But even the most Claude-poisoned serious developers in the world still own curation, judgement, guidance, and direction.</p><p>Also: let’s stop kidding ourselves about how good our human first cuts really are.</p><p>It’s hard to get a good toolchain for Brainfuck, too. Life’s tough in the aluminum siding business.</p><div><p>† (and they surely will; the Rust community takes tooling seriously)</p></div><p>A lot of LLM skepticism probably isn’t really about LLMs. It’s projection. People say “LLMs can’t code” when what they really mean is “LLMs can’t write Rust”. Fair enough! But people select languages in part based on how well LLMs work with them, so Rust people should get on that †.</p><p>I work mostly in Go. I’m confident the designers of the Go programming language didn’t set out to produce the most LLM-legible language in the industry. They succeeded nonetheless. Go has just enough type safety, an extensive standard library, and a culture that prizes (often repetitive) idiom. LLMs kick ass generating it.</p><p>All this is to say: I write some Rust. I like it fine. If LLMs and Rust aren’t working for you, I feel you. But if that’s your whole thing, we’re not having the same argument.</p><p>Do you like fine Japanese woodworking? All hand tools and sashimono joinery? Me too. Do it on your own time.</p><div><p>† (I’m a piker compared to my woodworking friends)</p></div><p>I have a basic wood shop in my basement †. I could get a lot of satisfaction from building a table. And, if that table is a workbench or a grill table, sure, I’ll build it. But if I need, like, a table? For people to sit at? In my office? I buy a fucking table.</p><p>Professional software developers are in the business of solving practical problems for people with code. We are not, in our day jobs, artisans. Steve Jobs was wrong: we do not need to carve the unseen feet in the sculpture. Nobody cares if the logic board traces are pleasingly routed. If anything we build endures, it won’t be because the codebase was beautiful.</p><p>Besides, that’s not really what happens. If you’re taking time carefully golfing functions down into graceful, fluent, minimal functional expressions, alarm bells should ring. You’re yak-shaving. The real work has depleted your focus. You’re not building: you’re self-soothing.</p><p>Which, wait for it, is something LLMs are good for. They devour schlep, and clear a path to the important stuff, where your judgement and values really matter.</p><p>As a mid-late career coder, I’ve come to appreciate mediocrity. You should be so lucky as to  have it flowing almost effortlessly from a tap.</p><p>We all write mediocre code. Mediocre code: often fine. Not all code is equally important. Some code should be mediocre. Maximum effort on a random unit test? You’re doing something wrong. Your team lead should correct you.</p><p>Developers all love to preen about code. They worry LLMs lower the “ceiling” for quality. Maybe. But they also raise the “floor”.</p><p>Gemini’s floor is higher than my own.  My code looks nice. But it’s not as thorough. LLM code is repetitive. But mine includes dumb contortions where I got too clever trying to DRY things up.</p><p>And LLMs aren’t mediocre on every axis. They almost certainly have a bigger bag of algorithmic tricks than you do: radix tries, topological sorts, graph reductions, and LDPC codes. Humans romanticize  (<a href=\"https://www.andrew.cmu.edu/course/15-749/READINGS/required/cas/tridgell96.pdf\" title=\"\">Andrew Tridgell</a> wrote a paper about it!). To an LLM it might not be that much more interesting than a SQL join.</p><p>But I’m getting ahead of myself. It doesn’t matter. If truly mediocre code is all we ever get from LLMs, that’s still huge. It’s that much less mediocre code humans have to write.</p><p>Smart practitioners get wound up by the AI/VC hype cycle. I can’t blame them. But it’s not an argument. Things either work or they don’t, no matter what Jensen Huang has to say about it.</p><p>We’re a field premised on automating other people’s jobs away. “Productivity gains,” say the economists. You get what that means, right? Fewer people doing the same stuff. Talked to a travel agent lately? Or a floor broker? Or a record store clerk? Or a darkroom tech?</p><p>When this argument comes up, libertarian-leaning VCs start the chant: lamplighters, creative destruction, new kinds of work. Maybe. But I’m not hypnotized. I have no fucking clue whether we’re going to be better off after LLMs. Things could get a lot worse for us.</p><p>LLMs really might displace many software developers. That’s not a high horse we get to ride. Our jobs are just as much in tech’s line of fire as everybody else’s have been for the last 3 decades. We’re not <a href=\"https://en.wikipedia.org/wiki/2024_United_States_port_strike\" title=\"\">East Coast dockworkers</a>; we won’t stop progress on our own.</p><p>Artificial intelligence is profoundly — and probably unfairly — threatening to visual artists in ways that might be hard to appreciate if you don’t work in the arts.</p><p>We imagine artists spending their working hours pushing the limits of expression. But the median artist isn’t producing gallery pieces. They produce on brief: turning out competent illustrations and compositions for magazine covers, museum displays, motion graphics, and game assets.</p><p>LLMs easily — alarmingly — clear industry quality bars. Gallingly, one of the things they’re best at is churning out just-good-enough facsimiles of human creative work.  I have family in visual arts. I can’t talk to them about LLMs. I don’t blame them. They’re probably not wrong.</p><p>Meanwhile, software developers spot code fragments <a href=\"https://arxiv.org/abs/2311.17035\">seemingly lifted</a> from public repositories on Github and lose their shit. What about the licensing? If you’re a lawyer, I defer. But if you’re a software developer playing this card? Cut me a little slack as I ask you to shove this concern up your ass. No profession has demonstrated more contempt for intellectual property.</p><p>The median dev thinks Star Wars and Daft Punk are a public commons. The great cultural project of developers has been opposing any protection that might inconvenience a monetizable media-sharing site. When they fail at policy, they route around it with coercion. They stand up global-scale piracy networks and sneer at anybody who so much as tries to preserve a new-release window for a TV show.</p><p>Call any of this out if you want to watch a TED talk about how hard it is to stream  on LibreWolf. Yeah, we get it. You don’t believe in IPR. Then shut the fuck up about IPR. Reap the whirlwind.</p><p>It’s all special pleading anyways. LLMs digest code further than you do. If you don’t believe a typeface designer can stake a moral claim on the terminals and counters of a letterform, you sure as hell can’t be possessive about a red-black tree.</p><p>When I started writing a couple days ago, I wrote a section to “level set” to the  state of the art of LLM-assisted programming. A bluefish filet has a longer shelf life than an LLM take. In the time it took you to read this, everything changed.</p><p>Kids today don’t just use agents; they use asynchronous agents. They wake up, free-associate 13 different things for their LLMs to work on, make coffee, fill out a TPS report, drive to the Mars Cheese Castle, and then check their notifications. They’ve got 13 PRs to review. Three get tossed and re-prompted. Five of them get the same feedback a junior dev gets. And five get merged.</p><p><em>“I’m sipping rocket fuel right now,”</em> a friend tells me. <em>“The folks on my team who aren’t embracing AI? It’s like they’re standing still.”</em> He’s not bullshitting me. He doesn’t work in SFBA. He’s got no reason to lie.</p><p>There’s plenty of things I can’t trust an LLM with. No LLM has any of access to prod here. But I’ve been first responder on an incident and fed 4o — not o4-mini, 4o — log transcripts, and watched it in seconds spot LVM metadata corruption issues on a host we’ve been complaining about for months. Am I better than an LLM agent at interrogating OpenSearch logs and Honeycomb traces? No. No, I am not.</p><p>To the consternation of many of my friends, I’m not a radical or a futurist. I’m a statist. I believe in the haphazard perseverance of complex systems, of institutions, of reversions to the mean. I write Go and Python code. I’m not a Kool-aid drinker.</p><p>But something real is happening. My smartest friends are blowing it off. Maybe I persuade you. Probably I don’t. But we need to be done making space for bad arguments.</p><h3><a href=\"https://fly.io/blog/youre-all-nuts/#but-im-tired-of-hearing-about-it\" aria-label=\"Anchor\"></a></h3><p>And here I rejoin your company. I read <a href=\"https://simonwillison.net/\" title=\"\">Simon Willison</a>, and that’s all I really need. But all day, every day, a sizable chunk of the front page of HN is allocated to LLMs: incremental model updates, startups doing things with LLMs, LLM tutorials, screeds against LLMs. It’s annoying!</p><p>But AI is also incredibly — a word I use advisedly — important. It’s getting the same kind of attention that smart phones got in 2008, and not as much as the Internet got. That seems about right.</p><p>I think this is going to get clearer over the next year. The cool kid haughtiness about “stochastic parrots” and “vibe coding” can’t survive much more contact with reality. I’m snarking about these people, but I meant what I said: they’re smarter than me. And when they get over this affectation, they’re going to make coding agents profoundly more effective than they are today.</p>","contentLength":15913,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44163063"},{"title":"Cloudlflare builds OAuth with Claude and publishes all the prompts","url":"https://github.com/cloudflare/workers-oauth-provider/","date":1748874294,"author":"gregorywegory","guid":213,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44159166"},{"title":"Show HN: Kan.bn – An open-source alterative to Trello","url":"https://github.com/kanbn/kan","date":1748857668,"author":"henryball","guid":212,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44157177"},{"title":"If you are useful, it doesn't mean you are valued","url":"https://betterthanrandom.substack.com/p/if-you-are-useful-it-doesnt-mean","date":1748854777,"author":"weltview","guid":211,"unread":true,"content":"","contentLength":0,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44156935"},{"title":"How to post when no one is reading","url":"https://www.jeetmehta.com/posts/thrive-in-obscurity","date":1748836860,"author":"j4mehta","guid":210,"unread":true,"content":"<p>The path to creative mastery begins with years of silence. Publish anyway.</p><p>Most things take  to bear fruit.</p><p>Even the most successful creators have spent years (if not decades) putting content out in obscurity. Just a complete total void. Youtube videos with 4 views. Newsletters with 3 subscribers. Podcasts with 10 listeners. Blogs with 6 readers. Songs with 4 downloads. No one but their parents and their spouse consuming their work. And sometimes not even that.</p><p>If you’re in it purely for the promised land of love, praise, followers, and fame from millions of people - it’s impossible to sustain. In every field, it takes years of practice, repetition, and “failed performances” before the first hit. In the worst case, artists go their entire life without ever receiving the praise they deserved. Look at Van Gogh - an incredible artist who died unappreciated &amp; broke, in a mental asylum. All of his fame came after his death.</p><h3>So how do you keep going?</h3><p>How do you keep hitting that publish button, over and over again, knowing there’s no one on the other side?</p><p>I don’t know. I’m still trying to figure it out.</p><p>But I have come across a few frameworks and quotes that I’ve found useful, so I’m sharing them below.</p><h3>1 — Do things you like, and sometimes the world will agree</h3><p>After writing music for 10 years — since the age of 6 — Mike’s single  blew up. No one other than his mom had heard any of his previous songs.  hit #6 on the Billboard Top 100 — while he was still in college at Duke.</p><p>Mike spent the next 7 years trying to chase the same hit, and every song ended up worse than the last. The chase pushed him into depression, drugs, a near-fatal snake bite, a walking journey across the US, and climbing Everest.</p><p>Ultimately, he came out with a much healthier attitude (that led to more hits).</p><blockquote><p>Do things that you like, and sometimes the world will agree.</p></blockquote><p>Instead of chasing hits, Mike only produces music he likes.\nMusic he thinks is good.Music he’d listen to..</p><p>And sometimes, the world agrees.</p><p>Similar to Mike Posner’s mindset: Instead of trying to figure out , just create what  like.</p><p>That’ll help sustain motivation when your audience doesn’t really exist. You’ll be more likely to push through plateaus, and you’ll enjoy the process. You’ll also just produce  work.</p><p>Best of all? It’ll attract like-minded followers — people who love the work  like to create.</p><blockquote><p>Your audience is just , pushed outwards.</p></blockquote><h3>3 — Build your Binge Bank</h3><p>Instead of being disappointed when no one consumes your content, treat these initial pieces of content as an investment. An investment in your . What’s that?</p><p>Your Binge Bank is the collection of content that your  fans will want to consume. It’s the rabbit hole of content they'll go down. Your audience might not exist now, but when it does in the future (and you can bet it will), they’ll want to go back in time and see everything you’ve produced.</p><p>This is why YouTubers with millions of followers have hundreds of thousands of views on their first few videos. Those videos didn’t get any views when they were first published. They were revisited  they became famous, by their most loyal fans.</p><p>So if you (like me) are publishing into obscurity, this is your gentle reminder.</p>","contentLength":3249,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":"https://news.ycombinator.com/item?id=44155746"}],"tags":["dev","hn"]}