{"id":"x7L2VSNEiyAJGtud3y69oo8X5Yu7UTGdrrATKd6xdinpKXPqHXYB5PwAm7nJVBn76sTY8qcH1NwExUJ","title":"Trends in Cognitive Sciences","displayTitle":"Trends in Cognitive Sciences","url":"https://www.cell.com/trends/cognitive-sciences/inpress.rss","feedLink":"https://www.cell.com/cognitive-sciences/archive?publicationCode=tics&rss=yes","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":8,"items":[{"title":"Imagining and building wise machines: the centrality of AI metacognition","url":"https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(26)00002-1?rss=yes","date":1772064000,"author":"Samuel G.B. Johnson, Amir-Hossein Karimi, Yoshua Bengio, Nick Chater, Tobias Gerstenberg, Kate Larson, Sydney Levine, Melanie Mitchell, Iyad Rahwan, Bernhard Schölkopf, Igor Grossmann","guid":157,"unread":true,"content":"<article>Although artificial intelligence (AI) has become increasingly smart, its wisdom has not kept pace. In this opinion article, we examine what is known about human wisdom and sketch a vision of its AI counterpart. We introduce human wisdom as strategies for solving intractable problems—those outside the scope of analytic techniques—including both ‘object-level’ strategies, such as heuristics (for managing problems), and ‘metacognitive’ strategies, such as intellectual humility, perspective-taking, or context adaptability (for managing object-level task fit). We argue that AI systems particularly struggle with this type of metacognition. Wise metacognition would lead to AI that is more robust to novel environments, explainable to users, cooperative with others, and safer by risking fewer misaligned goals with human users. We discuss how wise AI might be benchmarked, trained, and implemented.</article>","contentLength":912,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Intuitive theories of truth","url":"https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(26)00001-X?rss=yes","date":1771891200,"author":"Kerem Oktar, Isaac J. Handley-Miner, Max Kleiman-Weiner, Kevin J.S. Zollman, Liane Young","guid":156,"unread":true,"content":"<article>Cognitive science has recently begun exploring how people conceptualize and reason about truth. We offer the field a framework that can guide inquiry into intuitive theories of truth, centered on three core questions: how do people judge whether statements could be true, whether statements are true, and whether to assert them as true.</article>","contentLength":336,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Producing more while understanding less with large language models","url":"https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(26)00006-9?rss=yes","date":1771459200,"author":"M.J. Crockett, Lisa Messeri","guid":155,"unread":true,"content":"<article>Many scientists are enthusiastic about the potentials of 'Artificial Intelligence' (AI) for research. We recently examined the vision of ‘AI Surrogates’ [1]: computer models [including but not limited to large language models (LLMs)] designed to simulate human participants for the purpose of generating knowledge about human cognition and behavior. Some scientists believe that AI Surrogates can improve the generalizability of cognitive science: first, by simulating diverse populations that are not readily accessible, overcoming the field’s overreliance on Western, Educated, Industrialized, Rich, Democratic (WEIRD) samples; and second, by enabling researchers to quickly and cheaply explore vast experimental design spaces, expanding the diversity of situations that can be probed experimentally.</article>","contentLength":808,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Reminders that chatbots are not human can be risky","url":"https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(25)00356-0?rss=yes","date":1771372800,"author":"Linnea I. Laestadius, Celeste Campos-Castillo","guid":153,"unread":true,"content":"<article>Concerns about mental and physical health harms from chatbots are prompting policies mandating ongoing reminders that chatbots are not human. While well-intended, evidence suggests that reminders may be either ineffective or harmful to users. Discovering how to best remind people that chatbots are not human is a critical research priority.</article>","contentLength":341,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Moral decision-making with bounded cognitive resources and limited information","url":"https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(25)00359-6?rss=yes","date":1771372800,"author":"Maximilian Maier, Vanessa Cheung, Falk Lieder","guid":154,"unread":true,"content":"<article>Real-world moral decisions are constrained by limited information and bounded cognitive resources, necessitating heuristic strategies. We argue that choices in moral dilemmas should be analysed in terms of decision strategies rather than ethical theories and show how resource rationality and the bias–variance trade-off explain when people rely on particular strategies.</article>","contentLength":373,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"How AI tools can enhance generalizability","url":"https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(25)00318-3?rss=yes","date":1771286400,"author":"Zhicheng Lin","guid":152,"unread":true,"content":"<article>Using large language models (LLMs) to replace human participants suffers from fundamental fallacies: overgeneralization from Western, Educated, Industrialized, Rich, Democratic (WEIRD) samples; conflation of linguistic form with psychological content; and neglect of embodied and social dimensions of cognition [1]. In their recent article in TiCS [2], Crockett and Messeri extend this critique, arguing that ‘AI Surrogates’ perpetuate generalizability problems by entrenching WEIRD samples and decontextualized tasks [3].</article>","contentLength":526,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The making of number: from content to representation","url":"https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(25)00360-2?rss=yes","date":1770854400,"author":"Andreas Nieder","guid":151,"unread":true,"content":"<article>Despite their importance to human thought, the origins of numerical abilities remain debated. Numerical quantity is a property of physical objects and events, and both humans and many animals show an innate sensitivity to this numerical content. Yet how this content is represented is a separate question: it may be encoded nonsymbolically by an innate estimation system or symbolically through culturally developed formats, such as numeral notations and number words. Distinguishing content from representational format reconciles the views that numbers are innate (nativism), learned (empiricism), or constructed (emergentism). Converging evidence from developmental psychology, comparative cognition, neuroscience, and computation suggests that number is dynamically coconstructed by biological predispositions and cultural practices, a framework that generalizes to other domains of human cognition, such as geometry and language.</article>","contentLength":934,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Communicating risks more comprehensively using simulated experience","url":"https://www.cell.com/trends/cognitive-sciences/fulltext/S1364-6613(25)00353-5?rss=yes","date":1770249600,"author":"Kevin E. Tiede, Ralph Hertwig, Rui Mata, Dirk U. Wulff","guid":150,"unread":true,"content":"<article>Traditional risk communication emphasizes the probability of possible outcomes but neglects other crucial dimensions of risks. We propose a taxonomy of risk information and illustrate how simulated experience can convey overlooked aspects. We conclude with a research agenda to advance the theory and practice of risk communication across domains.</article>","contentLength":347,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["cognitive-neuroscience","review"]}