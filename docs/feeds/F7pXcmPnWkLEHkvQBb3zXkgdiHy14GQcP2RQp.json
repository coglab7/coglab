{"id":"F7pXcmPnWkLEHkvQBb3zXkgdiHy14GQcP2RQp","title":"Aphyr: Posts","displayTitle":"Dev - Aphyr","url":"http://aphyr.com/posts.atom","feedLink":"http://aphyr.com/posts.atom","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":3,"items":[{"title":"The Future of Comments is Lies, I Guess","url":"https://aphyr.com/posts/388-the-future-of-comments-is-lies-i-guess","date":1748540176,"author":"Aphyr","guid":316,"unread":true,"content":"<p>I’ve been involved in content moderation since roughly 2004. I’ve built spam prevention for corporate and personal e-mail, moderated open-source mailing lists and IRC channels, worked at a couple social media networks, and help moderate a Mastodon instance for a few hundred people. In the last few years I’ve wasted more time fighting blog comment spam, and I’m pretty sure Large Language Models (LLMs) are to blame.</p><p>I think of spam as a space with multiple equilibria. Producing spam takes work. Spammers are willing to invest that work because each message has a small chance to make money, or achieve political or emotional goals. Some spam, like the endless identical Viagra scams in my email spam folder, or the PHPBB comment spam I filter out here on aphyr.com, is cheap to generate and easy to catch. I assume the spammers make it up in volume. Other spam, like <a href=\"https://www.ibm.com/think/topics/spear-phishing\">spear phishing attacks</a>, is highly time-consuming: the spammer must identify a target, carefully craft a plausible message using, say, the identity of the target’s co-workers, or construct a facade of a bank’s log-in page, and so on. This kind of spam is more likely to make it through filters, but because it takes a lot of human work, is generally only worth it for high-value targets.</p><p>LLMs seem to be changing these equilibria. Over the last year I’ve seen a new class of comment spam, using what I’m fairly sure is LLM-generated text. These comments make specific, plausible remarks about the contents of posts and images, and work in a link to some web site or mention a product. Take this one I caught a few months back:</p><blockquote><p>\"Walking down a sidewalk lined with vibrant flowers is one of life’s simple joys! It reminds me of playing the [link redacted] slope game, where you have to navigate through colorful landscapes while dodging obstacles.</p></blockquote><p>Before 2023, you’d likely have paid a human a few cents to write and post that. Now, thanks to LLMs, this sort of thing is trivially automated. The model will happily fabricate relatable personal experiences in service of a spam campaign:</p><blockquote><p>That photo reminds me of the first time I tried macro photography in my backyard. I spent an hour trying to get a clear shot of a red flower, experimenting with angles and lighting. It was so much fun discovering the little details up close! If you ever need a break from photography, I recommend playing Snow Rider 3D for a bit of quick, light-hearted fun.</p></blockquote><p>Other spam seems to glue together LLM remarks with what I think is a hand-written snippet of ad copy. Note the abrupt shift in grammar, diction, and specificity.</p><blockquote><p>This piece masterfully blends technical depth with mythological storytelling, transforming a standard Haskell programming interview into an epic narrative. It cleverly critiques the complexity and absurdity of some technical interviews by illustrating how type-level Haskell can be pushed to esoteric extremes beautiful, powerful, and largely impractical. A fascinating and relevant read for anyone interested in the intersection of programming, language design, and narrative. I’m James Maicle, working at Cryptoairhub where we run a clear and insightful crypto blog. I’ll be bookmarking your site and following the updates. Glad to see so much valuable information shared here looking forward to exploring more strategies together. Thanks for sharing. If you interest about Crypto please visit my website and read my article [link redacted] Crypto Blog.</p></blockquote><p>The same thing is happening on aggregators like Hacker News, where commenters post more-or-less-obviously LLM output for… I’m not sure, exactly. Karma? Weirder still are bots like <a href=\"https://bsky.app/profile/hackerbriefs.bsky.social\">Hacker Briefs</a>, which I suspect use an LLM to summarize trending HN posts. Here’s <a href=\"https://bsky.app/profile/hackerbriefs.bsky.social/post/3lnz4kirkpv25\">its summary of a recent article I wrote</a>:</p><blockquote><p>“Jepsen: Amazon RDS for PostgreSQL 17.4”</p><p>New multi-AZ clusters in Amazon RDS for PostgreSQL offer better failure recovery but may return outdated data when reading after writes. Caution is needed.</p></blockquote><p>This is a totally plausible summary of <a href=\"https://jepsen.io/analyses/amazon-rds-for-postgresql-17.4\">the article</a>, and it is utterly, laughably wrong. Multi-AZ clusters are not new, and they do not return outdated data when reading after writes. As the abstract succinctly explains, they allow Long Fork, a different anomaly which does not involve real-time orders at all. The bot ignored the actual problem and invented a different one. This sort of spam isn’t obviously motivated by commercial interest, but it is nevertheless depressing: one more drop in the misinformation slurry.</p><p>Of course this is not news. Product reviews are inundated with LLM slop, as are social media networks. LLMs allow for cheap, fast, and automated generation of unique spam which is difficult for machines and humans to identify. The cost falls on me and other moderators, who must sift through LLM bullshit trying to sieve “awkward but sincere human” from “automated attack”. Thanks to OpenAI et al I read more spam, and each message takes longer to check.</p><p>This problem is only going to get worse as LLMs improve and spammers develop more sophisticated ways to use them. In recent weeks I’ve received vague voice messages from strangers with uncanny speech patterns just asking to catch up—a sentence which, had I uttered it prior to 2023, would have been reasonably interpreted as a sign of psychosis. I assume these too are LLM-generated scams, perhaps a <a href=\"https://dfpi.ca.gov/wp-content/uploads/2025/03/Pig-Butchering-Scam-Playbook.pdf\">pig butchering</a> scheme. So far these are from strangers, but it’s not hard to imagine an attacker using text and voice synthesis to impersonate a friend, colleague, or lover in a detailed conversation. Or one’s doctor, or bank.</p><p>As the cost of generating slop decreases, it’s easy to imagine LLMs generating personae, correspondence, even months-long relationships with real humans before being deployed for commercial or political purposes. <a href=\"https://www.techtransparencyproject.org/articles/for-sale-on-facebook-accounts-that-can-run-u.s.-election-ads\">Creating plausible accounts and selling them</a> has been a successful business model in social media for some time; likewise, we have strong clues that <a href=\"https://arxiv.org/pdf/2307.16336\">LLMs are already used for social media bots</a>. Social networks have responded to these attacks via out-of-band mechanisms: IP reputation analysis, javascript and mobile app fingerprinting, statistical correlation across multiple accounts, and so on. I’m not sure how to translate these defenses to less centralized and more privacy-oriented networks, like email or blog spam. I strongly suspect the only reason Mastodon hasn’t been eaten alive by LLM spambots is because we’re just not big enough to be lucrative. But those economics are shifting, and even obscure ecological niches can be worth filling.</p><p>As a moderator, that keeps me up at night.</p>","contentLength":6585,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Future of Customer Support is Lies, I Guess","url":"https://aphyr.com/posts/387-the-future-of-customer-support-is-lies-i-guess","date":1747829561,"author":"Aphyr","guid":315,"unread":true,"content":"<p><em>Update, 2025-05-22: TrueNAS was kind enough to reach out and let me know that their support process does not normally incorporate LLMs. They’re talking about what happened internally, and intend to prevent it from happening again through improved documentation and reviewing the support process as a whole. I’m happy to hear it!</em></p><p><a href=\"https://www.truenas.com/\">TrueNAS</a> makes file servers, also known as Network Attached Storage (NAS). I bought one of their smaller boxes to house backups, and it’s a great little NAS. For many years TrueNAS sold boxes with a BSD-based operating system, but in the last few years they’ve released a new, Linux-backed operating system called <a href=\"https://www.truenas.com/truenas-scale/\">TrueNAS SCALE</a>, also called “Community Edition”. I was considering migrating to TrueNAS SCALE, but the docs <a href=\"https://web.archive.org/web/20250408163343/https://www.truenas.com/docs/scale/gettingstarted/migrate/migrate-community/\">started off with this warning</a>:</p><blockquote><p>TrueNAS Enterprise customers should consult with TrueNAS Enterprise Support before attempting migrate.</p><p>The process requires an extended maintenance window, requires executing steps in the correct order to prevent issues with system configuration and operation, and additional system review post-migration to catch and correct any configuration issues.</p></blockquote><p>Since I’d actually purchased their hardware, I wrote to their support email. I asked whether the BSD-based OS was reaching end-of-life, and if there was anything special I should know about the upgrade process for my particular machine. The response came from a customer success coordinator, whose name I’ll omit for privacy. It began:</p><blockquote><p>It sounds like you’re at an important crossroads with your TrueNAS Mini 3.0-X+ system as it transitions from the traditional BSD-based OS to the Linux-based SCALE platform, now known as TrueNAS Community Edition.</p><p>Understanding the Transition\nEnd-of-Life for Certain Versions: The BSD-based version of TrueNAS you’re currently using (TrueNAS-13.0-U6.7) may be reaching its end-of-life phase, prompting a move to newer systems like TrueNAS SCALE, which is based on Linux and offers more modern features.</p><p>Community Edition: The Community edition represents the transition towards a more flexible, open-source platform that leverages FreeBSD jails (similar in concept to containers) for virtualization, providing scalability and extensibility.</p></blockquote><p>The phrase “may be reaching its end-of-life phase” was immediately worrying: how does a TrueNAS support agent not know whether their own products are EOL? But what really shocked me was the blatant lie in the third paragraph: they told me that the new OS was based on Linux, then immediately turned around and said that the new system was based on FreeBSD. FreeBSD jails were TrueNAS’s old approach to virtualization; the new Community Edition <a href=\"https://www.truenas.com/truenas-community-edition/\">uses Docker containers</a>. I could not believe that a human being had actually skimmed this response, let alone written it. I was, I think, talking to a Large Language Model (LLM) wearing the face of a person.</p><p>The response went on, coining odd phrases and warning of unspecified risks. “Non-HA (Non-Redundant Array of Independent Disks) TrueNAS hardware can sometimes have specific requirements or limitations when migrating to TrueNAS Community Edition,” they said. RAID and HA are different things in TrueNAS. Moreover, the reason I wrote to support in the first place was to ask what those “specific requirements” were. I was hoping for a support article I’d somehow missed, or a canned response. Instead I got my own question, regurgitated as a warning.</p><p>I wrote with followup questions, and got more nonsense in response. When I asked how TrueNAS Community Edition used FreeBSD jails, a different customer success coordinator replied:</p><blockquote><p>FreeBSD jails are similar to containers (like Docker) but built into the FreeBSD system. TrueNAS uses them to run isolated apps and services. For example, you can run Plex, Nextcloud, or other apps safely and separately using jails — all within your TrueNAS system.</p><p>They’re lightweight, secure, and don’t need a full virtual machine to run each service. It’s a great way to expand what your system can do without using much extra power or memory.</p></blockquote><p>This is all lies. TrueNAS CORE, the old FreeBSD OS, ran jails. TrueNAS SCALE / Community Edition runs Docker containers.</p><p>Quoting their HA/RAID confusion, I asked whether for TrueNAS hardware, the two were actually the same.</p><blockquote><p>Good question — they’re different:</p><ul><li><p>RAID protects your data by spreading it across multiple disks, so if one disk fails, your data is still safe.</p></li><li><p>HA (High Availability) means the system has two controllers. If one fails, the other takes over so the system keeps running. This is used in high-end enterprise systems (like our TrueNAS M-series), not in the MINI line.</p></li></ul></blockquote><p>This is, I believe, accurate, but betrays no sign that the original response conflated the two.</p><p>I asked what specific limitations my NAS model had that would cause issues migrating to Community Edition. They replied:</p><blockquote><p>The MINI-3.0-X+ is compatible with Community Edition (TrueNAS CORE), but there are a few things to know:</p><ul><li><p>No Enterprise-only features: Some features like enclosure management and support alerts are only available in the Enterprise version.</p></li><li><p>No HA support: Not an issue for the MINI, since it’s a single-controller system anyway.</p></li><li><p>Support level: CORE is community-supported, so it doesn’t come with iXsystems support like the Enterprise version does.</p></li></ul><p>But overall — the MINI runs CORE just fine for most use cases!</p></blockquote><p>This sounds like a reasonable response, but it too is complete nonsense. TrueNAS CORE is a completely different operating system. I asked whether it would run Community Edition, also known as SCALE.</p><p>I worked support for many years, helping people with desktops, systems and networking, and occasionally for web services. I’m used to knowledge base articles and canned responses on both ends—and indeed, that’s exactly what I was hoping TrueNAS would provide. All I needed to know was why the documentation warned their customers to contact support before upgrading. Instead I got a pile of vague nonsense and lies.</p><p>I get it. Support is often viewed as a cost center, and agents are often working against a brutal, endlessly increasing backlog of tickets. There is pressure at every level to clear those tickets in as little time as possible. Large Language Models create plausible support responses with incredible speed, but their output must still be reviewed by humans. Reviewing large volumes of plausible, syntactically valid text for factual errors is exhausting, time-consuming work, and every few minutes a new ticket arrives.</p><p>Companies must do more with less; what was once a team of five support engineers becomes three. Pressure builds, and the time allocated to review the LLM’s output becomes shorter and shorter. Five minutes per ticket becomes three. The LLM gets it mostly right. Two minutes. Looks good. Sixty seconds. Click submit. There are one hundred eighty tickets still in queue, and behind every one is a disappointed customer, and behind that is the risk of losing one’s job. Thirty seconds. Submit. Submit. The metrics do not measure how many times the system has lied to customers.</p>","contentLength":7095,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Future of Newspapers is Lies, I Guess","url":"https://aphyr.com/posts/386-the-future-of-newspapers-is-lies-i-guess","date":1747828300,"author":"Aphyr","guid":314,"unread":true,"content":"<p><em>Update, 2023-05-23: Added a paragraph about Dr. Howard Whiteman’s non-existent quote.</em></p><p><em>I subscribe to the Chicago Sun-Times, a non-profit newspaper. This week they sent me a sixty-four page special insert, branded with the Chicago Sun-Times logo, full of LLM nonsense. Yesterday I wrote the following letter to the Chicago Sun-Times. That evening, they published <a href=\"https://chicago.suntimes.com/news/2025/05/20/syndicated-content-sunday-print-sun-times-ai-misinformation\">this followup</a>.</em></p><p>Dear Mr. Buscaglia and the Chicago Sun-Times,</p><p>The May 18th “Heat Index” summer insert feels remarkably like “AI slop”: text generated by a large language model. The unusually enthusiastic use of adjectives coats the entire insert with an oily sheen, but I’m also concerned that there may be wholesale fabrications in the text.</p><p>For instance, “Summer soundtracks” cites Dr. Daniel Levitin, in an interview with Scientific American, as saying “Music activates the brain’s reward centers in ways similar to other pleasurable experiences. When paired with meaningful activities, these songs become powerful memory anchors that can transport us back to those moments for decades”. These phrases, and substrings thereof, return zero matches on Kagi or Google. Scientific American’s archives include a <a href=\"https://www.scientificamerican.com/article/exploring-the-musical-bra/\">January 22, 2001 article</a> with several quotes from Levitin, but nothing like the purported quotes.</p><p>The “Nightfall adventures” article cites Dr. Howard Whiteman, professor at Murray State University. “Understanding nocturnal adaptations helps us appreciate the complexity of ecosystems. Even common backyard species display fascinating behaviors that most people never witness.” I checked with Dr. Whiteman, who confirmed that he had never said these words:</p><blockquote><p>I have never spoken to the Chicago Sun-Times or any other Chicago paper, and I can’t recall ever saying any of those words to anyone, ever.</p><p>I write for some regional papers, some of which is online, and I could see an AI putting all of my writing together somehow into those words, but I’ve never actually written about nocturnal behavior per se.</p></blockquote><p>The “Summer food trends” article cites an interview in Bon Appetit, claiming Padma Lakshmi said, “What distinguishes this summer’s global food exploration is how these international flavors are being adapted to local, seasonal ingredients.” Lakshmi  published in <a href=\"https://www.bonappetit.com/story/padma-lakshmi\">an interview with BA</a>, but I can’t find any use of the uncanny marketer-speak “this summer’s global food exploration”.</p><p>The same article also cites the National Ice Cream Retailers Association as forecasting “unexpected savory notes” and “hyperlocal ingredient sourcing” as the “fastest-growing segments in premium frozen desserts”. I find it hard to believe these are segments at all—nor do these phrases appear anywhere on the <a href=\"https://icecreamassociation.org/general/custom.asp?page=Aboutus\">NICRA web site</a>.</p><p>The “Summer reading list for 2025” recommends books like “The Rainmakers”, by Percival Everett—a real author, but as far as I can tell, not a real text. Immediately thereafter it offers “Salt and Honey”, by “Delia Owens”—again, a real writer, not a real book. I started reaching out to some of the experts cited in the insert to ask whether their quotes were real, then realized <a href=\"https://www.theverge.com/ai-artificial-intelligence/670510/chicago-sun-times-ai-generated-reading-list\">the Verge beat me to it</a>.</p><p>These examples are just from a cursory skim; the insert fails my LLM “sniff test” on essentially every page. How did this happen? How do you print and distribute a full-color, sixty-four page special edition without anyone reading it first? Many of the articles have no byline, but those that do are purportedly by Marco Buscaglia. Was he responsible? Or is he too, like so many of the people cited in this nonsense publication, a victim of confabulatory applied statistics? This would be a great project for the Sun-Times newsroom, assuming OpenAI hasn’t eaten them yet.</p>","contentLength":3738,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["dev"]}