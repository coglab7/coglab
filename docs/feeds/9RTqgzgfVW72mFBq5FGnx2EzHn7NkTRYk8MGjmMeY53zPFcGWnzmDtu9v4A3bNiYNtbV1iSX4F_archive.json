{"id":"9RTqgzgfVW72mFBq5FGnx2EzHn7NkTRYk8MGjmMeY53zPFcGWnzmDtu9v4A3bNiYNtbV1iSX4F","title":"Journal of Neuroscience Behavioral/Cognitive","displayTitle":"Journalof Neuroscience","url":"https://www.jneurosci.org/rss/Behavioral_Cognitive.xml","feedLink":"http://www.jneurosci.org/","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":15,"items":[{"title":"Spatiotemporal Evidence Accumulation Through Saccadic Sampling for Object Recognition","url":"http://www.jneurosci.org/cgi/content/short/45/44/e2453242025?rss=1","date":1761755428,"author":"Zheng, Z., Hu, J., Okazawa, G.","guid":290,"unread":true,"content":"<p>Visual object recognition has been extensively studied under fixation conditions, but our natural viewing involves frequent saccadic eye movements that scan multiple local informative features within an object (e.g., eyes and mouth in a face image). These saccades would contribute to object recognition by subserving the integration of sensory information across local features, but mechanistic models underlying this process have yet to be established due to the presumed complexity of the interactions between the visual and oculomotor systems. Here, we employ a framework of perceptual decision making and show that human object categorization behavior with saccades can be quantitatively explained by a model that simply accumulates the sensory evidence available at each moment. Human participants of both sexes performed face and object categorization while they were allowed to freely make saccades to scan local features. Our model could successfully fit the data even during such a free viewing condition, departing from past studies that required controlled eye movements to test trans-saccadic integration. Moreover, further experimental results confirmed that active saccade commands (efference copy) do not substantially contribute to evidence accumulation. Therefore, we propose that object recognition with saccades can be approximated by a parsimonious decision-making model without assuming complex interactions between the visual and oculomotor systems.</p>","contentLength":1472,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Evidence for an Active Handoff between Hemispheres during Target Tracking","url":"http://www.jneurosci.org/cgi/content/short/45/44/e0841252025?rss=1","date":1761755428,"author":"Broschard, M. B., Roy, J. E., Brincat, S. L., Mahnke, M. K., Miller, E. K.","guid":291,"unread":true,"content":"<p>The brain has somewhat separate cognitive resources for the left and right sides of our visual field. Despite this lateralization, we have a smooth and unified perception of our environment. This raises the question of how the cerebral hemispheres are coordinated to transfer information between them. We recorded neural activity in the lateral prefrontal cortex, bilaterally, as two male nonhuman primates covertly tracked a target that moved from one visual hemifield (i.e., from one hemisphere) to the other. Beta (15–30&nbsp;Hz) power, gamma (30–80&nbsp;Hz) power, and spiking information reflected sensory processing of the target. In contrast, alpha (10–15&nbsp;Hz) power, theta (4–10&nbsp;Hz) power, and spiking information seemed to reflect an active handoff of attention as target information was transferred between hemispheres. Specifically, alpha power and spiking information ramped up in anticipation of the hemifield cross. Theta power peaked after the cross, signaling its completion. Our results support an active handoff of information between hemispheres. This \"handshaking\" operation may be critical for minimizing information loss, much like how mobile towers handshake when transferring calls between them.</p>","contentLength":1220,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Exposure to Bullying Engages Social Distress Circuits in the Adolescent and Adult Brain","url":"http://www.jneurosci.org/cgi/content/short/45/44/e0738252025?rss=1","date":1761755428,"author":"Paranko, B., Garandeau, C. F., Seppa&#x0308;la&#x0308;, K., Putkinen, V., Santavirta, S., Hirvonen, J., Salmivalli, C., Nummenmaa, L.","guid":292,"unread":true,"content":"<p>Despite advances in understanding the psychological and social consequences of peer victimization, the immediate effects of bullying on the central nervous system remain elusive. Here we mapped the neural, affective, and attentional responses to simulated bullying in adolescents and adults and tested whether these responses are associated with real-life victimization experiences. Fifty-one adolescents (29 females, 22 males) aged 11–14&nbsp;years and 47 adults (29 females, 18 males) underwent a functional MRI (fMRI) while watching first-person videos of bullying (victimization) in the school environment, as well as neutral and positive social interactions in a similar setting. Additionally, 57 adults (36 females, 21 males) watched the same videos during an eye tracking experiment. Exposure to bullying versus positive social interaction engaged the socioemotional and threat response systems, as well as regions related to social cognition, sensory and interoceptive processing, and motor control. These responses were consistent across adolescents and adults and were associated with the current and past victimization experiences of the participants. This large-scale activation of neural systems subserving socioemotional, somatosensory, and interoceptive processing was in line with the amplified emotional and attentional responses revealed by larger pupil size and higher fixation frequency during simulated bullying in the eye tracking experiment. Altogether these results highlight how peer victimization evokes a state of stress and alarm in the central nervous system.</p>","contentLength":1586,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Alpha-Band Activity Tracks Reflexive Changes in the Breadth of the Zoom Lens of Attention","url":"http://www.jneurosci.org/cgi/content/short/45/44/e0706252025?rss=1","date":1761755428,"author":"van Moorselaar, D., Theeuwes, J., Van der Stigchel, S.","guid":293,"unread":true,"content":"<p>Spatial attention is often conceptualized as a flexible \"zoom lens\" that can dynamically adjust its focus, but most evidence stems from studies of voluntary attention. Our study investigates whether involuntary, reflexive attention exhibits similar adaptability in attentional scope. Using behavioral and electroencephalographic (EEG) experiments with exogenous cues of varying spatial extent, we examined how attentional gradients dynamically adjust when attention is involuntarily captured. Male and female human participants performed visual search tasks preceded by narrow- or broad-cue displays at different onset asynchronies. We applied inverted encoding models to alpha-band neural activity to precisely track the locus and breadth of attentional tuning. Across experiments, we found that reflexive attentional gradients flexibly adapt to match cue characteristics. Behaviorally, narrow cues yielded progressively sharper attentional gradients compared with broad cues, with differences emerging over time. Critically, EEG analyses revealed that alpha-band activity tracked these dynamic adjustments, with differences in spatial selectivity emerging rapidly (±200&nbsp;ms postcue) and continuing to evolve. Contrary to previous suggestions that involuntary attention primarily influences response efficiency, our results demonstrate that exogenous cues modulate attentional resources across the visual field at early processing stages.</p>","contentLength":1440,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Forewarned Is Forearmed: The Single- and Dual-Brain Mechanisms in Detectors from Dyads of Varying Social Distance during Deceptive Outcome Evaluation","url":"http://www.jneurosci.org/cgi/content/short/45/43/e2129242025?rss=1","date":1761150634,"author":"Huang, R., Gao, X., Zhang, C., Liu, J., Zhang, Y., Zhong, Y., Chen, Y., Wang, H., Wei, X., Liu, Y.","guid":288,"unread":true,"content":"<p>Preventing deception requires understanding how lie detectors process social information across social distance. Although the outcomes of such information are crucial, how detectors evaluate gains or losses from close versus distant others remains unclear. Using a sender–receiver paradigm and functional near-infrared spectroscopy hyperscanning, we recruited 66 healthy adult dyads (32 male and 34 female dyads) to investigate how perceived social distance modulates the neural basis in receivers (the detector) during deceptive gain/loss evaluation. The results showed that detectors were more prone to deception in gain contexts, with these differences mediated by connectivity in risk evaluation (dorsolateral prefrontal cortex, DLPFC), reward-processing (orbitofrontal cortex, OFC), and intention-understanding regions (frontal pole area). Hyperscanning analyses revealed that friend dyads exhibited higher interpersonal neural synchrony (INS) in these regions than stranger dyads. In gain contexts, friend dyads showed enhanced INS in the OFC, whereas in loss contexts, enhanced INS was observed in the DLPFC. Trial-level analysis revealed that the INS during the current trial effectively predicted the successful deception of that trial. We constructed a series of regression models and found that INS provides superior predictive power over single-brain measures. The INS-based support vector regression model achieved an accuracy of 86.66% in predicting deception. This indicates that increased trust at closer social distances reduces vigilance and fosters relationship-oriented social information processing. As the first to identify INS as a neural marker for deception from the detector's perspective, this work advances interpersonal deception theory and offers a neuroscientific basis for credit risk management.</p>","contentLength":1830,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Neural Signature of the Bias Toward Self-Focus","url":"http://www.jneurosci.org/cgi/content/short/45/43/e0037252025?rss=1","date":1761150634,"author":"Geisler, D., Meyer, M. L.","guid":289,"unread":true,"content":"<p>People are remarkably self-focused, disproportionately choosing to think about themselves relative to other topics. Self-focus can be adaptive, helping individuals fulfill their needs. It can also be maladaptive, with self-focus a risk and maintenance factor for internalizing disorders like depression. Yet, the drive to focus on the self remains to be fully characterized. We discovered a brain pattern that when spontaneously brought online during a quick mental break predicts the desire to focus on oneself just a few seconds later. In Study 1 (19 female and 13 male human subjects), we identified a default network neural signature from pre-trial activity that predicts multiple indicators of self-focus within our sample. In Study 2 (588 female and 498 male human subjects), we applied our neural signature to independent resting-state data from the Human Connectome Project. We found that individuals who score high on internalizing, a form of maladaptive self-focus, similarly move in and out of this pattern during rest, suggesting a systematic trajectory toward self-focused thought. This is the first work to \"decode\" the bias to focus on the self and paves the way toward stopping maladaptive self-focus in its course.</p>","contentLength":1231,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Large-Scale Color Biases in the Retinotopic Functional Architecture Are Region Specific and Shared across Human Brains","url":"http://www.jneurosci.org/cgi/content/short/45/42/e2717202025?rss=1","date":1760545828,"author":"Bannert, M. M., Bartels, A.","guid":283,"unread":true,"content":"<p>Despite the functional specialization in visual cortex, there is growing evidence that the processing of chromatic and spatial visual features is intertwined. While past studies focused on visual field biases in retina and behavior, large-scale dependencies between coding of color and retinotopic space are largely unexplored in the cortex. Using a sample of male and female volunteers, we asked whether spatial color biases are shared across different human observers and whether they are idiosyncratic for distinct areas. We tested this by predicting the color a person was seeing using a linear classifier that has never been trained on chromatic responses from that same brain, solely by taking into account: (1) the chromatic responses in other individuals’ brains and (2) commonalities between the spatial coding in brains used for training and the test brain. We were able to predict the color (and luminance) of stimuli seen by an observer based on other subjects’ activity patterns in areas V1–V3, hV4, and LO1. In addition, we found that different colors elicited systematic, large-scale retinotopic biases that were idiosyncratic for distinct areas and common across brains. The area-specific spatial color codes and their conservation across individuals suggest functional or evolutionary organization pressures that remain to be elucidated.</p>","contentLength":1360,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Competitive Cortical Prioritization Emerges for Trained Objects across the First Year of Life","url":"http://www.jneurosci.org/cgi/content/short/45/42/e2314242025?rss=1","date":1760545828,"author":"Boylan, M. R., Tebbe, A.-L., Newland, J., Sanches Braga Figueira, J., Keil, A., Scott, L. S.","guid":284,"unread":true,"content":"<p>Learning to detect and recognize a broad range of visual objects is a crucial developmental task during the first year of life. However, many of the neurophysiological changes underlying the emergence of this cognitive ability remain poorly understood. The current study tested the hypothesis that training infants to recognize novel objects leads to selectively enhanced visuocortical responses and a competitive advantage that prioritizes the processing of trained relative to untrained objects. A cross-sectional sample of parent–infant dyads at 6, 9, and 12&nbsp;months of age read books in which novel objects were associated with different types of labels. The next day, EEG was recorded while infants ( = 51, 24 females and 26 males, 1 unknown) were concurrently presented with trained objects (i.e., from the book) and untrained objects (i.e., novel objects not in the book). Trained and untrained objects flickered at distinct frequencies (5&nbsp;Hz, 6&nbsp;Hz) to evoke frequency-tagged steady-state visual evoked potentials (ssVEPs). Analyses of the visuocortical response showed training-related competition effects that increased with age. Specifically, responses to trained stimuli increased while responses to untrained stimuli decreased with age. At 6&nbsp;months, infants showed no visuocortical bias for trained objects, but by 9 and 12&nbsp;months, visuocortical responses favored trained objects. This pattern suggests that competitive neural interactions between trained and untrained stimuli may support the development of object recognition and that experience with objects guides attentional prioritization in the infant brain.</p>","contentLength":1633,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Phasic Alertness Impairs Cognitive Control by Amplifying Competition between Evidence Accumulators","url":"http://www.jneurosci.org/cgi/content/short/45/42/e1595242025?rss=1","date":1760545828,"author":"Tromp, J., Wurm, F., Lucchi, F., de Kleijn, R., Nieuwenhuis, S.","guid":285,"unread":true,"content":"<p>Although phasic alertness generally benefits cognitive performance, it often increases the impact of distracting information, resulting in impaired decision-making and cognitive control. However, it is unclear why phasic alertness has these negative effects. Here, we present a novel, biologically informed account, according to which phasic alertness generates a transient, evidence-independent input (TEI) to the decision process. This shortens overall response times but also amplifies competition between evidence accumulators, thus slowing down decision-making and impairing cognitive control. The key hypotheses of this account are supported with pupil measurements and electrophysiological data from human decision-makers of either sex performing an arrow flanker task. We also show that a computational model of the flanker task that incorporates a TEI can reproduce the behavioral effects of phasic alertness but only when the evidence accumulators compete with each other through lateral inhibition. Our results reveal a close interplay between dynamic changes in alertness, cognitive control, and evidence accumulation.</p>","contentLength":1130,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Competition between Tool and Hand Motion Impairs Movement Planning in Limb Apraxia","url":"http://www.jneurosci.org/cgi/content/short/45/42/e0692252025?rss=1","date":1760545828,"author":"Thibault, S., Yates, J. B., Buxbaum, L. J., Wong, A. L.","guid":286,"unread":true,"content":"<p>Tool use is a complex motor planning problem. Prior research suggests that planning to use tools involves resolving competition between different tool-related action representations. We therefore reasoned that competition may also be exacerbated with tools for which the motions of the tool and the hand are incongruent (e.g., pinching the fingers to open a clothespin). If this hypothesis is correct, we should observe marked deficits in planning the use of incongruent as compared with congruent tools in individuals with limb apraxia following left hemisphere stroke (LCVA), a disorder associated with abnormal action competition. We asked 34 individuals with chronic LCVA (14 females) and 16 matched neurotypical controls (8 females) to use novel tools in which the correspondence between the motions of the hand and tool-tip were either congruent or incongruent. Individuals with LCVA also completed background assessments to quantify apraxia severity. We observed increased planning time for incongruent as compared with congruent tools as a function of apraxia severity. Further analysis revealed that this impairment predominantly occurred early in the task when the tools were first introduced. Lesion-symptom mapping analyses revealed that lesions to posterior temporal and inferior parietal areas were associated with impaired planning for incongruent tools. A second experiment on the same individuals with LCVA revealed that the ability to gesture the use of conventional tools was impaired for tools rated as more incongruent by a normative sample. These findings suggest that tool-hand incongruence evokes action competition and influences the tool-use difficulties experienced by people with apraxia.</p>","contentLength":1716,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Largely Intact But Less Reliable and Distributed Neural Representations of Subjective Value in Human Opioid Addiction","url":"http://www.jneurosci.org/cgi/content/short/45/42/e0679252025?rss=1","date":1760545828,"author":"LoFaro, F. M., Gueguen, M. C. M., Kapoor, A., Alvarez, E. E., Bonagura, D., Konova, A. B.","guid":287,"unread":true,"content":"<p>Addiction, particularly opioid use disorder (OUD), is often characterized by heightened propensity for risk-taking. While tolerance for risk and uncertainty varies across individuals, the elevated risk-taking in people with OUD is assumed to stem from altered cognitive decision-making processes beyond differences due to idiosyncratic yet lawful tolerances. Specifically, the prevailing assumption is that people with addiction exhibit impairments in the internal representation and integration of information that should guide decisions and judgments about what is valuable. Using model-based functional magnetic resonance imaging, we examined how the choice behavior of treatment-engaged male and female participants with chronic OUD aligns with the neural encoding of their inferred subjective value (SV) of uncertain (risky and ambiguous) rewards and the evidence for impairment in this neural process. Using both univariate and multivariate analyses, we found that canonical value regions [ventromedial prefrontal cortex (vmPFC), striatum, and posterior cingulate cortex] track the SV of uncertain choice options in both participants with OUD and comparison controls, irrespective of their tolerance for uncertainty. This speaks against a fundamentally impaired subjective valuation process in OUD. However, value representations were less reliably decodable in people with OUD in some value regions (vmPFC) and throughout the brain, especially within the limbic and salience/ventral-attention networks. Thus, while people with OUD engage a neurocomputationally similar process during risky decision-making to controls, they may differ in the fidelity and distribution of SV signals across brain networks.</p>","contentLength":1711,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"A Common Representational Code for Event and Object Concepts in the Brain","url":"http://www.jneurosci.org/cgi/content/short/45/41/e2166242025?rss=1","date":1759941038,"author":"Tong, J.-Q., Binder, J. R., Conant, L. L., Mazurchuk, S., Anderson, A. J., Fernandino, L.","guid":279,"unread":true,"content":"<p>Events and objects are two fundamental ways in which humans conceptualize their experience of the world. Despite the significance of this distinction for human cognition, it remains unclear whether the neural representations of object and event concepts are categorically distinct or, instead, can be explained in terms of a shared representational code. We investigated this question by analyzing fMRI data acquired from human participants (males and females) while they rated their familiarity with the meanings of individual words (all nouns) denoting object and event concepts. Multivoxel pattern analyses indicated that both categories of lexical concepts are represented in overlapping fashion throughout the association cortex, even in the areas that showed the strongest selectivity for one or the other type in univariate contrasts. Crucially, in these areas, a feature-based model trained on neural responses to individual event concepts successfully decoded object concepts from their corresponding activation patterns (and vice versa), showing that these two categories share a common representational code. This code was effectively modeled by a set of experiential feature ratings, which also accounted for the mean activation differences between these two categories. These results indicate that neuroanatomical dissociations between events and objects emerge from quantitative differences in the cortical distribution of more fundamental features of experience. Characterizing this representational code is an important step in the development of theory-driven brain–computer interface technologies capable of decoding conceptual content directly from brain activity.</p>","contentLength":1685,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Time Course of Phonological Encoding: Insights from Time-Resolved MVPA","url":"http://www.jneurosci.org/cgi/content/short/45/41/e0546252025?rss=1","date":1759941038,"author":"Li Calzi, G., Meyer, A. S., van der Burght, C. L.","guid":280,"unread":true,"content":"<p>To produce a word, speakers need to decide which concept to express, select an appropriate item from the mental lexicon, and spell out its phonological form. The temporal dynamics of these processes remain a subject of debate. We investigated the time course of lexical access in picture naming with electroencephalography (EEG). Thirty participants (23 female) named pictures using simple nouns. The pictures varied in conceptual category (animate or inanimate), stress pattern (first or second syllable), and the structure of the first syllable (open or closed). Using time-resolved multivariate pattern analysis (MVPA), we decoded the time course in which each dimension was available during speech preparation. The results demonstrated above-chance decoding of animacy within 100&nbsp;ms after picture onset, confirming early access to conceptual information. This was followed by stress pattern and syllable structure, at approximately 150 and 250&nbsp;ms after picture onset, respectively. These results suggest that a word's stress pattern can be retrieved before syllable structure information becomes available. An exploratory analysis demonstrated the availability of the word-initial phoneme within 100&nbsp;ms after picture onset. This result hints at the possibility that during picture naming, conceptual, phonological, and phonetic information may be accessed rapidly and in parallel.</p>","contentLength":1387,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Dissociable Neural Connectome Mapping of Reward and Punishment Responsiveness in Young Adults: Associations with Genetic Variability and Neurotransmitter Profiles","url":"http://www.jneurosci.org/cgi/content/short/45/41/e0195252025?rss=1","date":1759941038,"author":"Xu, T., Zhu, C., Zhou, X., Chen, Z., Gan, X., Cui, X., Zhou, F., Zhang, R., Zhao, W., Zhang, X., Chen, H., He, Q., Lei, X., Qiu, J., Feng, T.","guid":281,"unread":true,"content":"<p>While the hyper- and hypo-reward or punishment sensitivities (RS, PS) have received considerable attention as prominent transdiagnostic features of psychopathology, the lack of an overarching neurobiological characterization currently limits their early identification and neuromodulation. Here we combined microarray data from the Allen Human Brain Atlas with a multimodal fMRI approach to uncover the neurobiological signatures of RS and PS in a discovery-replication design ( = 655 healthy participants, 442 females). Both RS and PS were mapped separately in the brain, with the functional connectome in the fronto-striatal network encoding reward responsiveness, while the fronto-insular system was particularly engaged in punishment sensitivity. These dissociable functional connectome patterns also exhibited high specificity in differentiating decisions driven by social or monetary reward and punishment motivations. Further imaging transcriptomic analyses revealed that functional connectome variations for RS and PS were associated with topography of specific gene sets enriched in ontological pathways, including synaptic transmission, dopaminergic metabolism, immune response, and stress adaptation. On the neurotransmitter level, the serotonin neuromodulator emerged as a pivotal hub regulating the intrinsic functional connectome patterns of RS and PS, with its modulatory effects dependent on interactions with the dopaminergic, opioid, and GABAergic systems. Overall, these findings indicate dissociable neural connectome mapping of RS and PS and highlight their linkage with transcriptomic profiles, which may inform future investigations on early identification of vulnerability and risk factors for psychopathological conditions.</p>","contentLength":1748,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Cholinergic Dynamics in the Septo-hippocampal System Provide Phasic Multiplexed Signals for Spatial Novelty and Correlate with Behavioral States","url":"http://www.jneurosci.org/cgi/content/short/45/41/e0133252025?rss=1","date":1759941038,"author":"Moghadam, F. F., Gutierrez-Guzman, B. E., Zheng, X., Parsa, M., Hozyen, L. M., Dannenberg, H.","guid":282,"unread":true,"content":"<p>In the hippocampal formation, cholinergic modulation from the medial septum/diagonal band of Broca is known to correlate with the speed of an animal's movements at subsecond timescales and also supports spatial memory formation. Yet, the extent to which subsecond cholinergic dynamics, if at all, align with transient behavioral and cognitive states supporting the encoding of novel spatial information remains unknown. In this study, we used fiber photometry to record the temporal dynamics in the population activity of septo-hippocampal cholinergic neurons at subsecond resolution during a hippocampus-dependent object location memory task using ChAT-Cre mice of both sexes. Using a linear mixed-effects model, we quantified the extent to which cholinergic dynamics were explained by changes in movement speed; behavioral states such as locomotion, grooming, and rearing; and hippocampus-dependent cognitive states such as recognizing a novel location of a familiar object. The data show that cholinergic dynamics contain a multiplexed code of fast and slow signals (1) coding for the logarithm of movement speed at subsecond timescales, (2) providing a phasic spatial novelty signal during the brief periods of exploring a novel object location, and (3) coding for recency of environmental change at a seconds-long timescale. Furthermore, behavioral event-related phasic cholinergic activity demonstrates that fast cholinergic transients correlate with a switch in cognitive and behavioral states. These findings enhance understanding of the mechanisms by which cholinergic modulation contributes to the coding of movement speed and encoding of novel spatial information.</p>","contentLength":1675,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["cognitive-neuroscience"]}