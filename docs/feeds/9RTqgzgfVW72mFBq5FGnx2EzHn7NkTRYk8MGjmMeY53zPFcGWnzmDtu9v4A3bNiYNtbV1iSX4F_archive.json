{"id":"9RTqgzgfVW72mFBq5FGnx2EzHn7NkTRYk8MGjmMeY53zPFcGWnzmDtu9v4A3bNiYNtbV1iSX4F","title":"Journal of Neuroscience Behavioral/Cognitive","displayTitle":"Journal of Neuroscience","url":"https://www.jneurosci.org/rss/Behavioral_Cognitive.xml","feedLink":"http://www.jneurosci.org/","isQuery":false,"isEmpty":false,"isHidden":false,"itemCount":35,"items":[{"title":"The Amygdala Regulates Social Motivation for Selective Vocal Imitation in Zebra Finches","url":"http://www.jneurosci.org/cgi/content/short/45/24/e2435242025?rss=1","date":1749659428,"author":"Fujii, T. G., Tanaka, M.","guid":503,"unread":true,"content":"<p>Imitation plays a key role in the acquisition of speech and cultural behaviors. Studies suggest that social interaction facilitates imitative learning, indicating that neural circuits involved in social behaviors can also influence the process of imitation. Vocal imitation in juvenile songbirds serves as a valuable model to investigate this idea. Here, we explore the mechanisms of tutor–pupil social interaction and selective song learning in male zebra finches, with a particular focus on the amygdala, which can regulate social behaviors via its processing of values and emotions in mammals. When sequentially exposed to two tutors, normal pupils selectively learned song from the tutor who sang longer but less frequently. When hearing songs, pupils preferentially approached the selected tutor. Excitotoxic lesions of the amygdala increased pupils’ social motivation toward tutors yet diminished their song-responsive approach, especially to the selected tutor. Whereas the pupils with amygdala lesions retained their ability to imitate song, the tutor selection became more unpredictable with diminished preference for a specific tutor. Neuronal tracing confirmed that the zebra finch amygdala is connected to the circuits involved in social functions but lacks direct connections to those critical for song control and learning. These results suggest that the amygdala regulates social motivation and tutor selection in juvenile zebra finches, highlighting its role in imitative learning.</p>","contentLength":1501,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Functional and Regional Specificity of Noradrenergic Signaling for Encoding and Retrieval of Associative Recognition Memory in the Rat","url":"http://www.jneurosci.org/cgi/content/short/45/24/e2408242025?rss=1","date":1749659428,"author":"Tran, S., Barker, G. R. I., Mathiasen, M. L., Aggleton, J. P., Warburton, E. C.","guid":504,"unread":true,"content":"<p>Recognition of a familiar object in a novel location requires retrieval of the former object–place association and encoding of novel information. Such object-in-place (OiP) memory recruits a neural network including the hippocampus (HPC), medial prefrontal cortex (mPFC), and nucleus reuniens of the thalamus (NRe); however, the underlying cellular mechanisms are not understood. Locus ceruleus (LC) noradrenergic neurons signal novelty; thus here we focused on the contribution of LC–forebrain projections and noradrenaline (NA) receptor subtypes to OiP encoding compared with retrieval, using an arena-based OiP task in male rats. The NRe was found to receive a catecholaminergic input from LC, with the strongest innervation directed to rostral NRe. Interestingly optogenetic inactivation of the LC-&gt;NRe pathway impaired OiP retrieval but was without effect on encoding, while inactivation of the LC-&gt;HPC selectively impaired encoding. Consistent with this double dissociation, pharmacological blockade of NRe α1-adrenoreceptors selectively impaired memory retrieval, while blockade of HPC β-adrenoreceptors impaired encoding. Finally, pharmacological attenuation of noradrenergic signaling in the NRe and HPC through the infusion of the α2-adrenergic receptor agonist UK 14,304 impaired retrieval and encoding, respectively. Surprisingly, antagonism or agonism of adrenoreceptor subtypes in the mPFC had no effect on memory performance. Together these results reveal the importance of NA within the HPC and NRe for OiP, whereby selectivity of function is achieved via spatially distinct LC output projections and NA receptor subtypes consistent with a modular view of NA function. These results are also important in demonstrating the distinct neuronal mechanisms by which encoding and retrieval are achieved.</p>","contentLength":1820,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Zooming In and Out: Selective Attention Modulates Color Signals in Early Visual Cortex for Narrow and Broad Ranges of Task-Relevant Features","url":"http://www.jneurosci.org/cgi/content/short/45/24/e2097242025?rss=1","date":1749659428,"author":"O&#x0308;zkan, M., Chapman, A. F., Sto&#x0308;rmer, V. S.","guid":505,"unread":true,"content":"<p>Research on feature-based attention has shown that selecting a specific visual feature (e.g., the color red) results in enhanced processing in early visual cortex, providing the neural basis for the efficient identification of relevant features in many everyday tasks. However, many situations require the selection of entire feature ranges instead of just a single feature value, and recent accounts have proposed that broadly tuned attentional templates are often critical for guiding selection in cluttered visual scenes. To assess the neural implementation of such broad tuning of feature-based attention, we here recorded frequency-tagged potentials in human observers (male and female) while participants attended to narrow or broad ranges of colors of spatially intermingled dot fields. Our results show clear increases in the signal strength for the attended colors relative to unattended colors for both narrow and broad color ranges, though this increase was reduced for the broad-range condition, suggesting that limits in the breadth of attentional tuning arise at early processing stages. Overall, the present findings indicate that feature-selective attention can amplify multiple contiguous color values in early visual cortex, shedding light onto the neural mechanisms underlying broad search templates. More generally, they illustrate how feature-based attention can dynamically \"zoom in\" and \"zoom out\" in feature space, mirroring models of spatial attention.</p>","contentLength":1477,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Target Selection Signals Causally Influence Human Perceptual Decision-Making","url":"http://www.jneurosci.org/cgi/content/short/45/24/e2048242025?rss=1","date":1749659428,"author":"Pearce, D. J., Loughnane, G. M., Chong, T. T.- J., Demeyere, N., Mattingley, J. B., Moore, M. J., New, P. W., OConnell, R. G., ONeill, M. H., Rangelov, D., Stolwyk, R. J., Webb, S. S., Zhou, S.-H., Brosnan, M. B., Bellgrove, M. A.","guid":506,"unread":true,"content":"<p>The ability to form decisions is a foundational cognitive function which is impaired across many psychiatric and neurological conditions. Understanding the neural processes underpinning clinical deficits may provide insights into the fundamental mechanisms of decision-making. The N2c has been identified as an EEG signal indexing the efficiency of early target selection, which subsequently influences the timing of perceptual reports through modulating neural evidence accumulation rates. Evidence for the contribution of the N2c to human decision-making however has thus far come from correlational research in neurologically healthy individuals. Here, we capitalized on the superior temporal resolution of EEG to show that unilateral brain lesions in male and female humans were associated with specific deficits in both the timing and strength of the N2c in the damaged hemisphere, with corresponding deficits in the timing of perceptual reports contralaterally. The extent to which the N2c influenced clinical deficits in perceptual reporting speed depended on neural rates of evidence accumulation. This work provides causal evidence that the N2c indexes an early, hemisphere-specific process supporting human decision-making. This noninvasive EEG marker could be used to monitor novel approaches for remediating clinical deficits in perceptual decision-making across a range of brain disorders.</p>","contentLength":1402,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Neural Signatures of Flexible Multiple Timing","url":"http://www.jneurosci.org/cgi/content/short/45/24/e2041242025?rss=1","date":1749659428,"author":"Haim, S., Ofir, N., Deouell, L. Y., Landau, A. N., Lottem, E.","guid":507,"unread":true,"content":"<p>The human ability to track overlapping and asynchronous time intervals is crucial for a myriad of tasks, from engaging in conversation to driving a car. Additionally, unexpected events can trigger rapid, on-the-fly adjustments, necessitating quick updating of both timing intervals and action planning. Such events require immediate recalibration of decision variables to allow the system to promptly adapt to new stimuli and update the timing mechanisms accordingly. In this study, we assessed human male and female participants’ ability to track two simultaneous and asynchronous beep trains and determine which one ended first. Due to the stochastic nature of the beeps, participants frequently had to reorient their intended actions in order to identify which train was more likely to have ended. We found that they were able to do this accurately, demonstrating timing performance that was comparable with that of a single train. At the neural level, we recorded slowly evolving EEG potentials that encoded a single interval, the one associated with the currently intended action. Upon an intention switch, when participants had to reorient to a previously unintended action, the EEG response amplitude was reset to reflect the new intended interval. In contrast, when participants were instructed to disregard one of the beep trains, EEG responses solely reflected the intervals of the sequence they attended to. This flexibility in response highlights the brain's ability to dynamically reconfigure cognitive processes in real time, ensuring that actions remain contextually appropriate despite sudden changes in the environment.</p>","contentLength":1638,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Continuous Diffusion-Detected Neuroplasticity during Motor Learning","url":"http://www.jneurosci.org/cgi/content/short/45/24/e1152242025?rss=1","date":1749659428,"author":"Friedman, N., Malovani, C., Perets, I., Kenin, E., Bernstein-Eliav, M., Tavor, I.","guid":508,"unread":true,"content":"<p>How does our brain transform when we encounter a new task? To fully answer this question, comparing brain states before and after learning may not be enough, but rather an ongoing, continuous monitoring of brain changes during learning is required. While such continuous examinations of functional learning-induced changes are widely available using functional magnetic resonance imaging (MRI), a continuous investigation of diffusion-detected brain modifications during learning is yet to be reported. Here, we continuously acquire diffusion MRI images during task performance. We then compute the mean diffusivity (MD) using a sliding-window approach, resulting in a continuous measure of diffusivity changes throughout learning. We demonstrate the utility of this method on a motor sequence learning (finger tapping) task ( = 58, 30 females). MD decrease was detected in task-related brain regions, including the parahippocampal gyrus (PHG), hippocampus, inferior temporal gyrus, and cerebellum. Analysis of the temporal patterns of decrease revealed a rapid MD reduction in the right temporal gyrus after 11&nbsp;min of training, with additional decrease in the right PHG and left cerebellum after 22&nbsp;min. We further computed \"neuroplasticity networks\" of brain areas showing similar change patterns and detected similarities between these networks and canonical functional connectivity networks. Our findings offer novel insights on the spatiotemporal dynamics of diffusion-detected neuroplasticity by demonstrating continuous modifications during the encoding phase of learning itself rather than comparing pre- and postlearning states.</p>","contentLength":1639,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Anterior Insula Processes a Time-Resolved Subjective Risk Prediction Error","url":"http://www.jneurosci.org/cgi/content/short/45/23/e2302242025?rss=1","date":1749054628,"author":"Kim, J.-C., Hellrung, L., Nebe, S., Tobler, P. N.","guid":496,"unread":true,"content":"<p>The insula processes errors in the prediction of risky, motivationally relevant outcomes and thereby is thought to respond similarly to better-than-predicted and worse-than-predicted outcomes. However, the nature of the encoded risk prediction error signals remained unclear. Moreover, the insula was proposed to preferentially process events and stimuli in the aversive domain, rather than in a domain-general fashion. Here, we aimed to illuminate these issues. In a Pavlovian task, participants ( = 41; 19 women) rated both cues and outcomes, allowing us to quantify not only objective but also trial-specific subjective risk prediction errors. We found preferential coding of subjective risk prediction errors in the anterior insula and adjacent frontal cortex. This contrasted with preferential coding of objective risk prediction errors in the mid-insula. The anterior insula encoded the subjective risk prediction errors not only at the time of outcomes but also at the time of cues, in line with a temporally fine-grained computation of these prediction errors. Cue-induced subjective risk prediction error signals occurred predominantly in the aversive domain, while outcome-induced subjective risk prediction error signals occurred also in the appetitive domain. Domain-specific analyses of risk prediction errors elicited by the preceding outcome at the time of the next cue indicated that the anterior insula updates risk predictions more strongly in the aversive than the appetitive domain. Together, our findings specify the nature of risk prediction errors processed by the anterior insula as subjective, time-resolved, partly domain-general (outcome), and partly domain-preferential (cue), thereby reconciling apparently disparate lines of research.</p>","contentLength":1764,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Excitability Modulations of Somatosensory Perception Do Not Depend on Feedforward Neuronal Population Spikes","url":"http://www.jneurosci.org/cgi/content/short/45/23/e2280242025?rss=1","date":1749054628,"author":"Stephani, T., Villringer, A., Nikulin, V. V.","guid":497,"unread":true,"content":"<p>Neural states shape perception at earliest cortical processing levels. Previous work in humans showed a relationship between initial cortical excitation, as indicated by the N20 component of the somatosensory evoked potential (SEP), prestimulus alpha oscillations, and the perceived intensity in a somatosensory discrimination paradigm. Here we address the follow-up question whether these excitability dynamics reflect changes in feedforward or feedback signals. To distinguish feedforward neural signals from feedback signals, we leveraged high-frequency oscillations (HFO) which have previously been shown to correspond to neuronal population spiking activity of the first excitatory feedforward volley in the somatosensory cortex. We examined these HFO in electroencephalography (EEG) data of 32 male human participants, performing a somatosensory intensity discrimination task. Spatial filtering and time–frequency analyses allowed to clearly distinguish HFO from the lower-frequency, conventional SEP. Using Bayesian statistics, we found evidence against the involvement of HFO in moment-to-moment variability of perceived stimulus intensity, in contrast to previously observed prestimulus alpha and N20 effects of the conventional SEP. Given that the N20 component presumably reflects backpropagating membrane potentials toward the apical dendrites (distal dendritic sites), we argue that top-down feedback processes (e.g., related to alpha oscillations) may thus rely on activity modulations at those distal dendrites of involved pyramidal cells rather than on synchronous output firing changes at their basal compartments.</p>","contentLength":1633,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Uncertainty, Not Mental Content, Drives Dorsomedial Prefrontal Engagement during Inferences about Others","url":"http://www.jneurosci.org/cgi/content/short/45/23/e1920232025?rss=1","date":1749054628,"author":"Berkay, D., Jenkins, A. C.","guid":498,"unread":true,"content":"<p>To navigate social life, humans make inferences about the intentions, beliefs, emotions, and personalities of other people, i.e., they mentalize. A network of brain regions consistently engages more during mentalizing than during carefully controlled comparison tasks, sometimes cited as evidence of domain-specific mentalizing processes. Here we investigated the possibility that engagement of these regions during mentalizing may be due to uncertainty. We scanned 46 participants (33 female, 13 male) using fMRI as they made mental and non-mental inferences (about human minds, human bodies, and physical objects) under varying levels of uncertainty. Uncertainty explained activation in a key region of the mentalizing network: the dorsal medial prefrontal cortex (DMPFC). Higher uncertainty was associated with greater DMPFC engagement across conditions, and, when controlling for uncertainty, DMPFC engagement did not differentiate mental from non-mental inferences. Results suggest that the apparently selective DMPFC engagement during social inference may be better understood as a response to uncertainty, which is often elevated in social contexts, with implications for the cognitive architecture of the social brain and disorders of social function.</p>","contentLength":1259,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Stimulus Repetition Induces a Two-Stage Learning Process in the Primary Visual Cortex","url":"http://www.jneurosci.org/cgi/content/short/45/23/e1788242025?rss=1","date":1749054628,"author":"Cui, L., Bo, K., Xiong, C., Chen, Y., Keil, A., Ding, M.","guid":499,"unread":true,"content":"<p>Repeated stimulus exposure alters the brain's response to the stimulus. Recording fMRI data from both men and women viewing 120 presentations of two Gabor patches (each Gabor repeating 60 times), we evaluated support for two prominent models of stimulus repetition, the fatigue model and the sharpening model. Our results uncovered a two-stage learning process in the primary visual cortex. In Stage 1, univariate BOLD activation in V1 decreased over the first 14 repetitions of the stimuli, replicating the well known effect of repetition suppression. Applying moving-window multivoxel pattern analysis decoding, we found that (1) the decoding accuracy between the two Gabors decreased from the above-chance level (~60 to ~70%) at the beginning of the stage to the chance level at the end of the stage (~50%). This result, together with the accompanying weight map analysis, suggested that the learning dynamics in Stage 1 were consistent with the predictions of the fatigue model. In Stage 2, univariate BOLD activation for the remaining 46 repetitions of the two stimuli exhibited significant fluctuations but no systematic trend. The moving-window decoding accuracy between the two Gabor patches was at the chance level initially and became progressively higher as stimulus repetition continued, rising above and staying above the chance level starting at the ~36th repetition. Thus, results from the second stage supported the notion that sustained and prolonged stimulus repetition prompts sharpened representations. Additional analyses addressed (1) whether the neural patterns within each learning stage remained stable and (2) whether new neural patterns were evoked in Stage 2 relative to Stage 1.</p>","contentLength":1707,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Neural Processes Linking Interoception to Moral Preferences Aligned with Group Consensus","url":"http://www.jneurosci.org/cgi/content/short/45/23/e1114242025?rss=1","date":1749054628,"author":"Kim, J., Kim, H.","guid":500,"unread":true,"content":"<p>Aligning one's decisions with the prevailing social norms and expectations of those around us constitutes a fundamental facet of moral decision-making. When faced with conflicting moral values, one adaptive approach is to rely on intuitive moral preference. Although theoretical accounts have proposed a link between moral preferences and interoceptive awareness—the capacity to sense internal bodily signals, this connection has not been empirically examined. This study examines the relationship between moral preferences and interoception, measured with self-report, heartbeat counting task, and resting-state functional magnetic resonance imaging. Two independent experiments demonstrate that both male and female participants’ interoceptive awareness and accuracy are associated with their moral preferences aligned with group consensus. In addition, the fractional occupancies of resting-state brain states involving the ventromedial prefrontal cortex and the precuneus mediated this relationship. These findings provide empirical evidence of the neural mechanism linking interoception to moral preferences aligned with group consensus.</p>","contentLength":1146,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Cerebellar Activity Affects Distal Cortical Physiology and Synaptic Plasticity in a Human Parietal-Motor Pathway Associated with Motor Actions","url":"http://www.jneurosci.org/cgi/content/short/45/23/e0404252025?rss=1","date":1749054628,"author":"Goldenkoff, E. R., Brissenden, J. A., Lee, T. G., Michon, K. J., Vesia, M.","guid":501,"unread":true,"content":"<p>Voluntary movement control depends on plasticity in several interconnected brain regions, including the cerebellum (CB), primary motor cortex (M1), and posterior parietal cortex (PPC). It is thought that one role of the CB is to regulate communication between PPC and M1, but causal evidence for this regulatory role in humans remains lacking. Here, we evaluated how transiently altering activity in CB via intermittent theta burst stimulation (iTBS) affects PPC–M1 connectivity and plasticity by assessing the effectiveness of subsequent Hebbian-like cortical paired associative stimulation (cPAS) to PPC and M1. Using a within-subject design, we administered four different single-session stimulation conditions to the CB and parietal–motor pathway of the motor network and measured the aftereffects on plasticity (both sexes). We administered iTBS to the right CB or right visual cortex, followed by cPAS of a parietal–motor circuit in the left hemisphere. In a subset of participants, we performed two additional control conditions to assess the effect of CB iTBS alone and Hebbian-like cPAS of the PPC–M1 circuit alone. We evaluated motor-evoked potentials (MEPs) using single-pulse transcranial magnetic stimulation as a measure of motor cortical excitability before and after each plasticity induction protocol. Cerebellar iTBS reduced cPAS-induced plasticity in the parietal–motor circuit, as evidenced by a decrease in MEPs. These responses were selective, as no decreases in excitability were observed during the control experiments. These findings suggest that CB activity can modify distal neural activity in a network-connected parietal–motor circuit through heterosynaptic metaplasticity.</p>","contentLength":1714,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Relating Scene Memory and Perception Activity to Functional Properties, Networks, and Landmarks of Posterior Cerebral Cortex--A Probabilistic Atlas","url":"http://www.jneurosci.org/cgi/content/short/45/23/e0028252025?rss=1","date":1749054628,"author":"Steel, A., Prasad, D., Garcia, B. D., Robertson, C. E.","guid":502,"unread":true,"content":"<p>Adaptive behavior in complex environments requires integrating visual perception with memory of our spatial environment. Recent work has implicated three brain areas in posterior cerebral cortex—the place memory areas (PMAs) that are anterior to the three visual scene perception areas (SPAs)–in this function. However, PMAs' relationship to the broader cortical hierarchy remains unclear due to limited group-level characterization. Here, we examined the PMA and SPA locations across three fMRI datasets (44 participants, 29 female). SPAs were identified using a standard visual localizer where participants viewed scenes versus faces. PMAs were identified by contrasting activity when participants recalled personally familiar places versus familiar faces (Datasets 1–2) or places versus multiple categories (familiar faces, bodies, and objects, and famous faces; Dataset 3). Across datasets, the PMAs were located anterior to the SPAs on the ventral and lateral cortical surfaces. The anterior displacement between PMAs and SPAs was highly reproducible. Compared with public atlases, the PMAs fell at the boundary between externally oriented networks (dorsal attention) and internally oriented networks (default mode). Additionally, while SPAs overlapped with retinotopic maps, the PMAs were consistently located anterior to mapped visual cortex. These results establish the anatomical position of the PMAs at inflection points along the cortical hierarchy between unimodal sensory and transmodal, apical regions, which informs broader theories of how the brain integrates perception and memory for scenes. We have released probabilistic parcels of these regions to facilitate future research into their roles in spatial cognition.</p>","contentLength":1740,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Decomposing Cognitive Processes in the mPFC during Self-Thinking","url":"http://www.jneurosci.org/cgi/content/short/45/22/e2378242025?rss=1","date":1748449827,"author":"Levorsen, M., Aoki, R., Sedikides, C., Izuma, K.","guid":489,"unread":true,"content":"<p>Past cognitive neuroscience research has demonstrated that thinking about both the self and other activates the medial prefrontal cortex (mPFC), a central hub of the default mode network. The mPFC is also implicated in other cognitive processes, such as introspection and autobiographical memory, rendering elusive its exact role during thinking about the self. Specifically, it is unclear whether the same cognitive process explains the common mPFC involvement or distinct processes are responsible for the mPFC activation overlap. In this preregistered functional magnetic resonance imaging study with 35 male and female human participants, we investigated whether and to what extent mPFC activation patterns during self-reference judgment could be explained by activation patterns during the tasks of other-reference judgment, introspection, and autobiographical memory. Multivoxel pattern analysis showed that only in the mPFC were neural responses both concurrently different and similar across tasks. Furthermore, multiple regression and variance partitioning analyses indicated that each task (i.e., other-reference, introspection, and memory) uniquely and jointly explained significant variances in mPFC activation during self-reference. These findings suggest that the self-reference task engages multiple cognitive processes shared with other tasks, with the mPFC serving as a crucial hub where essential information is integrated to support judgments based on internally constructed representations.</p>","contentLength":1510,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Differential Beta and Gamma Activity Modulation during Unimanual and Bimanual Motor Learning","url":"http://www.jneurosci.org/cgi/content/short/45/22/e2187242025?rss=1","date":1748449827,"author":"Wu, M., Schoenfeld, M. J., Lindersson, C., Braeutigam, S., Zich, C., Stagg, C. J.","guid":490,"unread":true,"content":"<p>Movement-related dynamics in the beta and gamma bands have been studied in relation to motor execution and learning during unimanual movements, but their roles in complex bimanual tasks remain largely unexplored. This study aimed to investigate how beta and gamma activity differs between unimanual and bimanual movements and how these neural signatures evolve during the learning process. Our motor task incorporated varying levels of bimanual interaction: unimanual, bimanual-equal, and bimanual-unequal. Magnetoencephalography data were recorded in healthy participants ( = 43, 27 females) during task performance, and beta and gamma activity was quantified. As expected, increasing task complexity from unimanual to bimanual-equal and then to bimanual-unequal movements resulted in slower and less accurate performance. Across all conditions, significant beta event-related desynchronization (ERD) and gamma event-related synchronization (ERS) were observed during movement, as well as beta ERS after movement. Bimanual movements exhibited greater beta ERD, beta ERS, and gamma ERS compared with unimanual movements. With practice, participants demonstrated faster and more accurate movements, accompanied by enhanced beta ERS responses. Furthermore, learning-related reductions in errors correlated with increases in beta ERS. These findings suggest the distinct behavioral and neural demands of unimanual versus bimanual movements and highlight the important role of beta activity in motor performance and learning.</p>","contentLength":1521,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Statistical Context Learning in Visual Search: Distinct Electrophysiological Signatures of Contextual Guidance and Context Suppression","url":"http://www.jneurosci.org/cgi/content/short/45/22/e2186242025?rss=1","date":1748449827,"author":"Chen (&#x9648;&#x601D;&#x4F5A;), S., Merkus, N., Tsai (&#x8521;&#x52AD;&#x626C;), S.-Y., Cheng (&#x7A0B;&#x601D;), S., Mu&#x0308;ller, H. J., Shi (&#x65BD;&#x534E;), Z.","guid":491,"unread":true,"content":"<p>Facilitation of visual search by repeated distractor contexts is typically studied employing distractor configurations that are 100% predictive of the target location. Yet, real-world contexts vary in predictivity. We used electroencephalography (EEG) in human participants of either sex to explore how visual search facilitation arises from two distinct processing modes—contextual guidance and context suppression—that depend on the predictivity of distractor contexts, comparing repeated distractor arrangements that were either predictive or nonpredictive of target location against a baseline of nonrepeated arrangements. In Experiment 1, we manipulated context predictivity by shifting repeated contexts from predictive to nonpredictive and vice versa, while in Experiment 2, we restricted repeated contexts to one side of the display to assess lateralized effects of the two processing modes. Both types of contexts behaviorally facilitated visual search, but facilitation was larger with predictive contexts. Making predictive contexts nonpredictive reduced the facilitation while rendering nonpredictive contexts predictive failed to produce gains. Half-display predictive contexts facilitated target detection on both sides, while nonpredictive contexts facilitated same-side target detection only. EEG analyses revealed that predictive contexts triggered an early N1pc (guidance signal), followed by an enhanced N2pc (attentional selection) and an increased contralateral delay activity (CDA, indexing working memory processing of the target) in occipitoparietal regions, indicative of contextual guidance boosting the entire processing chain. In contrast, nonpredictive contexts produced only an increased N2pc accompanied by reduced CDA, consistent with context suppression. These differential patterns demonstrate contextual guidance and context suppression to operate as electrophysiologically distinct processing modes.</p>","contentLength":1939,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Whole-Brain Dimensions of Intrinsic Connectivity Capture Modality-Specific and Heteromodal Language Representations","url":"http://www.jneurosci.org/cgi/content/short/45/22/e1876242025?rss=1","date":1748449827,"author":"Marin-Marin, L., Eisenhauer, S., Gonzalez Alam, T. R. J., Margulies, D. S., Smallwood, J., Jefferies, E.","guid":492,"unread":true,"content":"<p>Comprehension of spoken and written language involves a hierarchical sequence of modality-specific and heteromodal processes. While these have been localized to different regions, modality-selective responses extend beyond them, implicating large-scale network organization in language comprehension. Dimensions of whole-brain connectivity, derived from intrinsic activity, have been proposed as a general organizing framework for cognition. Here, we test their utility in accounting for the spatial distribution of task-evoked activity during language comprehension. We investigated brain activity in human males and females in response to psycholinguistic variables linked to input processing and meaning in a sentence comprehension task presented both visually and auditorily. Macroscale patterns of brain activity were similar across modalities for sentence-level and semantic variables, but effects of orthographic and phonological distance were negatively correlated between modalities. The first dimension, separating heteromodal and unimodal cortices, showed no differences across modalities for sentence processing and semantic variables and opposite effects of word length and orthographic/phonological distance for spoken and written words, supporting the notion that higher-order processing requires heteromodal resources different to those linked to input processing. The second dimension, separating auditory–motor and visual processes, showed an asymmetry in the recruitment of the unimodal systems—listening to long and semantically dissimilar words involved stronger recruitment of primary auditory–motor regions and low visual engagement. These findings show that the language system is organized according to large-scale axes of intrinsic connectivity, with psycholinguistic processes varying systematically along whole-brain dimensions. This supports the view that language comprehension reflects general principles of cortical organization.</p>","contentLength":1967,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Multimodal MEG and Microstructure-MRI Investigations of the Human Hippocampal Scene Network","url":"http://www.jneurosci.org/cgi/content/short/45/22/e1700242025?rss=1","date":1748449827,"author":"Read, M.-L., Hodgetts, C. J., Lawrence, A. D., Evans, C. J., Singh, K. D., Umla-Runge, K., Graham, K. S.","guid":493,"unread":true,"content":"<p>Although several studies have demonstrated that perceptual discrimination of complex scenes relies on an extended hippocampal posteromedial system, we currently have limited insight into the specific functional and structural properties of this system in humans. Here, combining electrophysiological (magnetoencephalography) and advanced microstructural (multishell diffusion magnetic resonance imaging; quantitative magnetization transfer) imaging in healthy human adults (30 females/10 males), we show that both theta power modulation of the hippocampus and fiber restriction/hindrance (reflecting axon packing/myelination) of the fornix (a major input/output pathway of the hippocampus) were independently related to scene, but not face, perceptual discrimination accuracy. Conversely, microstructural features of the inferior longitudinal fasciculus (a long-range occipitoanterotemporal tract) correlated with face, but not scene, perceptual discrimination accuracy. Our results provide new mechanistic insight into the neurocognitive systems underpinning complex scene discrimination, providing novel support for the idea of multiple processing streams within the human medial temporal lobe.</p>","contentLength":1196,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Neural and Behavioral Correlates of Individual Variability in Rat Helping Behavior: A Role for Social Affiliation and Oxytocin Receptors","url":"http://www.jneurosci.org/cgi/content/short/45/22/e0845242025?rss=1","date":1748449827,"author":"Hazani, R., Breton, J. M., Trachtenberg, E., Ruzal, K., Shvalbo, B., Kantor, B., Maman, A., Bigelman, E., Cole, S., Weller, A., Ben-Ami Bartal, I.","guid":494,"unread":true,"content":"<p>A prosocial response to others in distress is increasingly recognized as a natural behavior for many social species. While prosocial behavior is more frequently observed toward familiar conspecifics, even within the same social context, some individuals are more prone to help than others. In a rat helping behavior test where animals can release a distressed conspecific trapped inside a restrainer, most rats are motivated and consistently release the trapped rat (\"openers\"), yet ~30% do not open the restrainer (\"nonopeners\"). To characterize the difference between these populations, behavioral and neural markers were compared between opener and nonopener rats in males and females. Openers showed significantly more social affiliative behavior both before and after door opening compared with nonopeners. Oxytocin receptor mRNA levels were higher in the nucleus accumbens (NAc), but not the anterior insula, of openers. Several transcription control pathways were significantly upregulated in openers’ NAc. Chemogenetically inhibiting paraventricular oxytocin neurons did not significantly impair helping but reduced sociality measures, indicating that helping does not rely solely on oxytocin signaling. Analysis of brain-wide neural activity based on the immediate-early gene c-Fos in males revealed increased activity in openers in prosocial brain regions compared with nonopeners. These include regions associated with empathy in humans (insula, somatosensory, cingulate, and frontal cortices) and motivation and reward regions such as the NAc. These findings indicate that prosocial behavior may be predicted by affiliative behavior and activity in the prosocial neural network and provide targets for the investigation of causal mechanisms underlying prosocial behavior.</p>","contentLength":1785,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Single-Trial fMRI Decoding of 3D Motion with Stereoscopic and Perspective Cues","url":"http://www.jneurosci.org/cgi/content/short/45/22/e0044252025?rss=1","date":1748449827,"author":"Wen, P., Thompson, L. W., Rosenberg, A., Landy, M. S., Rokers, B.","guid":495,"unread":true,"content":"<p>How does the brain process 3D motion? We focused on the human motion complex (hMT+), extending insights from monkey studies. Using 3D-motion stimuli containing perspective and/or stereoscopic cues, we investigated the hierarchy within the motion complex in humans of both sexes to understand the neural mechanisms underlying motion perception. On each trial we decoded 3D motion direction (toward/away) based on the BOLD response in primary visual cortex (V1), and regions within hMT+ including the middle temporal (MT) and medial superior temporal (MST) areas, and the fundus of the superior temporal sulcus (FST). We found that 3D-motion direction could be reliably decoded from all four areas but accuracy depended on cue content. MT and FST showed greatest decoding accuracy with perspective and stereoscopic cues, respectively. Decoding of motion direction in V1 and MST could be explained by retinotopic biases in the BOLD response to motion stimuli. MT and FST were less impacted by such biases. We also identified significant behavioral differences between participants: some were proficient at using stereoscopic cues and others performed near chance. Good behavioral performance with stereoscopic cues was accompanied by better decoding performance in FST but not MT. A control experiment that eliminated 3D motion percepts for stereoscopic stimuli, but not perspective stimuli, revealed that unlike MT, decoding accuracy in FST was influenced by perceptual components of 3D motion. Our findings support that MT and FST play distinct roles in the analysis of visual motion and are key in the transformation of retinal input into perceptual report.</p>","contentLength":1657,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Functional Heterogeneity within the Primate Ventral Striatum for Motivational Regulation","url":"http://www.jneurosci.org/cgi/content/short/45/21/e2430242025?rss=1","date":1747845026,"author":"Iwaoki, H., Hori, Y., Hori, Y., Mimura, K., Oyama, K., Nagai, Y., Hirabayashi, T., Inoue, K.-i., Takada, M., Higuchi, M., Minamimoto, T.","guid":481,"unread":true,"content":"<p>The ventral striatum (VS) is a key brain region for reward processing and motivation, and its dysfunctions have been implicated in psychiatric disorders such as apathy and obsessive–compulsive disorder. Although functional heterogeneity within the VS has been well established in rodents, its relevance and mechanisms in primates remain unclear. To address this issue, we performed bilateral pharmacological inactivation of the VS in two male macaque monkeys using muscimol, a GABA receptor agonist. Precise targeting was achieved through computed tomography and magnetic resonance imaging. Behavioral effects were evaluated using two methods: a goal-directed task with variable rewards and analysis of spontaneous behavior. Our results demonstrated that anterior (a)VS inactivation induced a hypoactivity state that we termed \"resting,\" whereas posterior (p)VS inactivation elicited compulsive-like \"checking\" behaviors. Notably, neither the aVS nor the pVS inactivation affected reward value or drive processing, thus differentiating aVS and pVS from those involved in incentive motivation, such as the rostromedial caudate and ventral pallidum. Retrograde tracing demonstrated distinct anatomical projection patterns for the aVS and pVS, supporting their functional segregation. Together, the present results suggest the functional heterogeneity of the primate VS along its anterior–posterior axis, with the aVS and pVS participating in distinct motivational control circuits. Our findings may have important implications for understanding the neural mechanisms of psychiatric disorders and for the development of new therapeutic approaches.</p>","contentLength":1648,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"EEG of the Dancing Brain: Decoding Sensory, Motor, and Social Processes during Dyadic Dance","url":"http://www.jneurosci.org/cgi/content/short/45/21/e2372242025?rss=1","date":1747845026,"author":"Bigand, F., Bianco, R., Abalde, S. F., Nguyen, T., Novembre, G.","guid":482,"unread":true,"content":"<p>Real-world social cognition requires processing and adapting to multiple dynamic information streams. Interpreting neural activity in such ecological conditions remains a key challenge for neuroscience. This study leverages advancements in denoising techniques and multivariate modeling to extract interpretable EEG signals from pairs of (male and/or female) participants engaged in spontaneous dyadic dance. Using multivariate temporal response functions (mTRFs), we investigated how music acoustics, self-generated kinematics, other-generated kinematics, and social coordination uniquely contributed to EEG activity. Electromyogram recordings from ocular, face, and neck muscles were also modeled to control for artifacts. The mTRFs effectively disentangled neural signals associated with four processes: (I) auditory tracking of music, (II) control of self-generated movements, (III) visual monitoring of partner movements, and (IV) visual tracking of social coordination. We show that the first three neural signals are driven by event-related potentials: the P50-N100-P200 triggered by acoustic events, the central lateralized movement-related cortical potentials triggered by movement initiation, and the occipital N170 triggered by movement observation. Notably, the (previously unknown) neural marker of social coordination encodes the spatiotemporal alignment between dancers, surpassing the encoding of self- or partner-related kinematics taken alone. This marker emerges when partners can see each other, exhibits a topographical distribution over occipital areas, and is specifically driven by movement observation rather than initiation. Using data-driven kinematic decomposition, we further show that vertical bounce movements best drive observers’ EEG activity. These findings highlight the potential of real-world neuroimaging, combined with multivariate modeling, to uncover the mechanisms underlying complex yet natural social behaviors.</p>","contentLength":1957,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Timing of Speech in Brain and Glottis and the Feedback Delay Problem in Motor Control","url":"http://www.jneurosci.org/cgi/content/short/45/21/e2294242025?rss=1","date":1747845026,"author":"Veillette, J. P., Rosen, J., Margoliash, D., Nusbaum, H. C.","guid":483,"unread":true,"content":"<p>To learn complex motor skills, an organism must be able to assign sensory feedback events to the actions that caused them. This matching problem would be simple if motor neuron output led to sensory feedback with a fixed, predictable lag. However, nonlinear dynamics in the brain and the body's periphery can decouple the timing of critical events from that of the motor output which caused them. During human speech production, for example, phonation from the glottis (a sound source for speech) begins suddenly when subglottal pressure and laryngeal tension cross a sharp threshold (i.e., a bifurcation). Only if the brain can predict the timing of these discrete peripheral events resulting from motor output, then, would it be possible to match sensory feedback to movements based on temporal coherence. We show that event onsets in the (male and female) human glottal waveform, measured using electroglottography, are reflected in the electroencephalogram during speech production, leading up to the time of the event itself. Conversely, glottal event times can be decoded from the electroencephalogram. After prolonged exposure to delayed auditory feedback, subjects recalibrate their behavioral threshold for detecting temporal auditory–motor mismatches and decoded event times decouple from actual movements. This suggests decoding performance is driven by plastic predictions of peripheral timing, providing a missing component for hindsight credit assignment, in which specific feedback events are associated with the neural activity that gave rise to movements. We discuss parallel findings from the birdsong system suggesting that results may generalize across vocal learning species.</p>","contentLength":1698,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Evidence That Respiratory Phase May Modulate Task-Related Neural Representations of Visual Stimuli","url":"http://www.jneurosci.org/cgi/content/short/45/21/e2236242025?rss=1","date":1747845026,"author":"Stetza, L., Hehemann, L., Kayser, C.","guid":484,"unread":true,"content":"<p>We investigate how respiration influences cognition by examining the interaction between respiratory phase and task-related brain activity during two visual categorization tasks. While prior research shows that cognitive performance varies along the respiratory cycle, the underlying neurophysiological mechanisms remain poorly understood. Though some studies have shown that large-scale neural activity reflecting for example changes in the excitation–inhibition balance is comodulated with the respiratory cycle, it remains unclear whether respiration directly shapes the neural signatures reflecting the encoding of task-specific external signals. We address this gap by applying single-trial multivariate analyses to EEG data obtained in humans ( = 25, any gender), allowing us to track how respiration relates to the sensory evidence reflected in this neurophysiological signal. Confirming previous studies, our data show that participant's performance varies with the respiratory phase prior and during a trial. Importantly, they suggest that respiration may directly influence the sensory evidence carried by neurophysiological processes emerging ~300–200&nbsp;ms prior to participant's responses. Hence, respiration and sensory-cognitive processes are not only highly intertwined but respiration may directly facilitate the representation of behaviorally relevant signals in the brain.</p>","contentLength":1393,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Learning Modulates Early Encephalographic Responses to Distracting Stimuli: A Combined SSVEP and ERP Study","url":"http://www.jneurosci.org/cgi/content/short/45/21/e1973242025?rss=1","date":1747845026,"author":"Duncan, D. H., Forschack, N., van Moorselaar, D., Mu&#x0308;ller, M. M., Theeuwes, J.","guid":485,"unread":true,"content":"<p>Through experience, humans can learn to suppress locations that frequently contain distracting stimuli. However, the neural mechanism underlying learned suppression remains largely unknown. In this study, we combined steady-state visually evoked potentials (SSVEPs) with event-related potentials (ERPs) to investigate the mechanism behind statistically learned spatial suppression. Twenty-four male and female human participants performed a version of the additional singleton search task in which one location contained a distractor stimulus frequently. The search stimuli constantly flickered on-and-off the screen, resulting in steady-state entrainment. Prior to search onset, no differences in the SSVEP response were found, though a post hoc analysis did reveal proactive alpha lateralization. Following search onset, clear evoked differences in both the SSVEP and ERP signals emerged at the suppressed location relative to all other locations. Crucially, the early timing of these evoked modulations suggests that learned distractor suppression occurs at the initial stages of visual processing.</p>","contentLength":1101,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Neocortical and Hippocampal Theta Oscillations Track Audiovisual Integration and Replay of Speech Memories","url":"http://www.jneurosci.org/cgi/content/short/45/21/e1797242025?rss=1","date":1747845026,"author":"Biau, E., Wang, D., Park, H., Jensen, O., Hanslmayr, S.","guid":486,"unread":true,"content":"<p>\"Are you talkin’ to me?!\" If you ever watched the masterpiece \"Taxi Driver\" directed by Martin Scorsese, you certainly recall the monologue during which Travis Bickle rehearses an imaginary confrontation in front of a mirror. While remembering this scene, you recollect a myriad of speech features across visual and auditory senses with a smooth sensation of unified memory. The aim of this study was to investigate how the fine-grained synchrony between coinciding visual and auditory features impacts brain oscillations when forming multisensory speech memories. We developed a memory task presenting participants with short synchronous or asynchronous movie clips focused on the face of speakers in real interviews, all the while undergoing magnetoencephalography recording. In the synchronous condition, the natural alignment between visual and auditory onsets was kept intact. In the asynchronous condition, auditory onsets were delayed to present lip movements and speech sounds in antiphase specifically with respect to the theta oscillation synchronizing them in the original movie. Our results first showed that theta oscillations in the neocortex and hippocampus were modulated by the level of synchrony between lip movements and syllables during audiovisual speech perception. Second, theta asynchrony between the lip movements and auditory envelope during audiovisual speech perception reduced the accuracy of subsequent theta oscillation reinstatement during memory recollection. We conclude that neural theta oscillations play a pivotal role in both audiovisual integration and memory replay of speech.</p>","contentLength":1618,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Optogenetic Stimulation of Novel Tph2-Cre Rats Advances Insight into Serotonin's Role in Locomotion, Reinforcement, and Compulsivity","url":"http://www.jneurosci.org/cgi/content/short/45/21/e1424242025?rss=1","date":1747845026,"author":"Robke, R., Sansi, F., Arbab, T., Tunez, A., Moore, M., Bartsch, D., Scho&#x0308;nig, K., Willuhn, I.","guid":487,"unread":true,"content":"<p>Serotonin critically modulates the activity of many brain networks, including circuits that control motivation and responses to rewarding and aversive stimuli. Furthermore, the serotonin system is targeted by first-line pharmacological treatments for several psychiatric disorders, including obsessive–compulsive disorder. However, understanding the behavioral function of serotonin is hampered by methodological limitations: the (brainstem) location of serotonergic neuron cell-bodies is difficult to access, their innervation of the brain is diffuse, and they release serotonin in relatively low concentrations. Here, we advance this effort by developing novel Tph2-Cre rats, which we utilized to study serotonin in the context of motor, compulsive, and reinforced behaviors using optogenetics in both male and female rats. Specificity and sensitivity of Cre recombinase expression and Cre-dependent processes were validated immunohistochemically, and optogenetic induction of in vivo serotonin release was validated with fast-scan cyclic voltammetry. Optogenetic stimulation of serotonin neurons in the dorsal raphe nucleus did not initiate locomotion or alter aversion-induced locomotion, nor did it elicit (real-time) place preference, and it had no measurable effect on compulsive behavior in the schedule-induced polydipsia task. In contrast, this optogenetic stimulation moderately sustained ongoing spontaneous locomotion and robustly reinforced operant lever pressing for self-stimulation of serotonin neurons, which was exacerbated by food restriction. Together, this work both introduces a novel rat Cre line to study serotonin and advances our understanding of serotonin's behavioral functions. Complementing previous findings, we find that brainwide serotonin release has an overall relatively mild effect on behavior, which manifested only in the absence of natural reinforcers and was modulated by physiological state.</p>","contentLength":1936,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Differentiating Reinforcement Learning and Episodic Memory in Value-Based Decisions in Parkinson's Disease","url":"http://www.jneurosci.org/cgi/content/short/45/21/e0911242025?rss=1","date":1747845026,"author":"Montaser-Kouhsari, L., Nicholas, J., Gerraty, R. T., Shohamy, D.","guid":488,"unread":true,"content":"<p>Patients with Parkinson's disease (PD) are impaired at incremental reward-based learning. It is typically assumed that this impairment reflects a loss of striatal dopamine. However, many open questions remain about the nature of reward-based learning deficits in PD. Recent studies have found that even simple reward-based learning tasks rely on a combination of cognitive and computational strategies, including one-shot episodic memory. These findings raise questions about how incremental learning and episodic memory contribute to decision-making in PD. We tested healthy participants ( = 26; 14 males and 12 females) and patients with PD ( = 26; 16 males and 10 females), both on- and off-dopamine replacement medication, on a task designed to differentiate between the contributions of incremental learning and episodic memory to reward-based learning and decision-making. We found that PD patients performed equally well as healthy controls when using episodic memory but were impaired at incremental reward-based learning. Dopamine replacement medication remediated this deficit and enhanced subsequent episodic memory for the value of motivationally relevant stimuli. These results demonstrate that while PD patients are impaired at learning about reward from trial-and-error, their ability to encode memories for the value of one-shot experiences is intact.</p>","contentLength":1367,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Electrophysiological Correlates of Lucid Dreaming: Sensor and Source Level Signatures","url":"http://www.jneurosci.org/cgi/content/short/45/20/e2237242025?rss=1","date":1747240232,"author":"Demirel, C., Gott, J., Appel, K., Lu&#x0308;th, K., Fischer, C., Raffaelli, C., Westner, B., Wang, X., Zavecz, Z., Steiger, A., Erlacher, D., LaBerge, S., Mota-Rolim, S., Ribeiro, S., Zeising, M., Adelho&#x0308;fer, N., Dresler, M.","guid":474,"unread":true,"content":"<p>Lucid dreaming (LD) is a state of conscious awareness of the ongoing oneiric state, predominantly linked to REM sleep. Progress in understanding its neurobiological basis has been hindered by small sample sizes, diverse EEG setups, and artifacts like saccadic eye movements. To address these challenges in characterizing the electrophysiological correlates of LD, we introduced an adaptive multistage preprocessing pipeline, applied to human data (male and female) pooled across laboratories, allowing us to explore sensor- and source-level markers of LD. We observed that, while sensor-level differences between LD and nonlucid REM sleep were minimal, mixed-frequency analysis revealed broad low alpha to gamma power reductions during LD compared with wakefulness. Source-level analyses showed significant beta power (12–30&nbsp;Hz) reductions in right central and parietal areas, including the temporoparietal junction, during LD. Moreover, functional connectivity in the alpha band (8–12&nbsp;Hz) increased during LD compared with nonlucid REM sleep. During initial LD eye signaling compared with the baseline, source-level gamma1 power (30–36&nbsp;Hz) increased in right temporo-occipital regions, including the right precuneus. Finally, functional connectivity analysis revealed increased interhemispheric and inter-regional gamma1 connectivity during LD, reflecting widespread network engagement. These results suggest that distinct source-level power and connectivity patterns characterize the dynamic neural processes underlying LD, including shifts in network communication and regional activation that may underlie the specific changes in perception, memory processing, self-awareness, and cognitive control. Taken together, these findings illuminate the electrophysiological correlates of LD, laying the groundwork for decoding the mechanisms of this intriguing state of consciousness.</p>","contentLength":1890,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Dissociable Causal Roles of Dorsolateral Prefrontal Cortex and Primary Motor Cortex over the Course of Motor Skill Development","url":"http://www.jneurosci.org/cgi/content/short/45/20/e2015232025?rss=1","date":1747240232,"author":"Nguyen, Q. N., Michon, K. J., Vesia, M., Lee, T. G.","guid":475,"unread":true,"content":"<p>Established models of motor skill learning posit that early stages of learning are dominated by an attentionally demanding, effortful mode of control supported by associative corticostriatal circuits involving the dorsolateral prefrontal cortex (DLPFC). As skill develops, automatic and \"effortless\" performance coincides with a transition to a reliance on sensorimotor circuits that include primary motor cortex (M1). However, the dynamics of how control evolves during the transition from novice to expert are currently unclear. This lack of clarity is due, in part, to the fact that most motor learning studies comprise a limited number of training sessions and rely on correlative techniques such as neuroimaging. Here, we train human participants (both sexes) on a discrete motor sequencing task over the course of 6&nbsp;weeks, followed by an assessment of the causal roles of DLPFC and M1 at varying levels of expertise. We use repetitive transcranial magnetic stimulation to transiently disrupt activity in these regions immediately prior to performance in separate sessions. Our results confirm the dissociable importance of DLPFC and M1 as training progresses. DLPFC stimulation leads to larger behavioral deficits for novice skills than more highly trained skills, while M1 stimulation leads to relatively larger deficits as training progresses. However, our results also reveal that prefrontal disruption causes performance deficits at all levels of training. These findings challenge existing models and indicate an evolving rather than a strictly diminishing role for DLPFC throughout learning.</p>","contentLength":1604,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"The Inattentional Rhythm in Audition","url":"http://www.jneurosci.org/cgi/content/short/45/20/e1544242025?rss=1","date":1747240232,"author":"Lui, T. K.-Y., Boglietti, E., Zoefel, B.","guid":476,"unread":true,"content":"<p>The detection of temporally unpredictable visual targets depends on the preceding phase of alpha oscillations (~7–12&nbsp;Hz). In audition, however, such an effect seemed to be absent. Due to the transient nature of its input, the auditory system might be particularly vulnerable to information loss that occurs if relevant information coincides with the low-excitability phase of the oscillation. We therefore hypothesized that effects of oscillatory phase in audition will be restored if auditory events are made task irrelevant and information loss can be tolerated. To this end, we collected electroencephalography (EEG) data from 29 human participants (21F) while they detected pure tones at one sound frequency and ignored others. Confirming our hypothesis, we found that the neural response to task-irrelevant but not to task-relevant tones depends on the prestimulus phase of neural oscillations. Alpha oscillations modulated early stages of stimulus processing, whereas theta oscillations (~3–7&nbsp;Hz) affected later components, possibly related to distractor inhibition. We also found evidence that alpha oscillations alternate between sound frequencies during divided attention. Together, our results suggest that the efficacy of auditory oscillations depends on the context they operate in and demonstrate how they can be employed in a system that heavily relies on information unfolding over time.</p>","contentLength":1408,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Repeated tDCS at Clinically Relevant Field Intensity Can Boost Concurrent Motor Learning in Rats","url":"http://www.jneurosci.org/cgi/content/short/45/20/e1495242025?rss=1","date":1747240232,"author":"Farahani, F., Vo&#x0308;ro&#x0308;slakos, M., Birnbaum, A. M., FallahRad, M., Williams, P. T. J. A., Martin, J. H., Parra, L. C.","guid":477,"unread":true,"content":"<p>Clinical trials with transcranial direct current stimulation (tDCS) use weak electric fields that have yet to demonstrate measurable behavioral effects in animal models. We hypothesized that weak stimulation will produce sizable effects, provided it is applied concurrently with behavioral training and repeated over multiple sessions. We tested this in a rodent model of dexterous motor skill learning using a pellet-reaching task in  behaving rats. The task was automated to minimize experimenter bias. We measured field magnitudes intracranially to calibrate the stimulation current. Male rats were trained for 20&nbsp;min with concurrent epicranial tDCS over 10 daily sessions. We developed a new electrode montage that enabled stable stimulation over the 10 sessions with a field intensity of 2 V/m at the motor cortex. Behavior was recorded with high-speed video to quantify reaching dynamics. We also measured motor-evoked potentials (MEPs) bilaterally with epidural microstimulation. The number of successful reaches improved across days of training, and the rate of learning was higher in the anodal group as compared with sham-control animals ( = 7.12;  = 0.008;  = 24). MEPs were not systematically affected by tDCS. Post hoc analysis suggests that tDCS modulated motor learning only for right-pawed animals, improving success of reaching but limiting stereotypy in these animals. Repeated and concurrent anodal tDCS can boost motor skill learning at clinically relevant field intensities. In this animal model, the effect interacted with paw preference and was not associated with corticospinal excitability.</p>","contentLength":1616,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Similar Computational Hierarchies for Reading and Speech in the Occipital Cortex of Sighed and Blind: Converging Evidence from fMRI and Chronometric TMS","url":"http://www.jneurosci.org/cgi/content/short/45/20/e1153242024?rss=1","date":1747240232,"author":"Matuszewski, J., Bola, &#x0141;ukasz, Collignon, O., Marchewka, A.","guid":478,"unread":true,"content":"<p>High-level perception results from interactions between hierarchical brain systems responsive to gradually increasing feature complexities. During reading, the initial evaluation of simple visual features in the early visual cortex (EVC) is followed by orthographic and lexical computations in the ventral occipitotemporal cortex (vOTC). While similar visual regions are engaged in tactile Braille reading in congenitally blind people, it is unclear whether the visual network maintains or reorganizes its hierarchy for reading in this population. Combining fMRI and chronometric transcranial magnetic stimulation (TMS), our study revealed a clear correspondence between sighted and blind individuals (both male and female) on how their occipital cortices functionally supports reading and speech processing. Using fMRI, we first observed that vOTC, but not EVC, showed an enhanced response to lexical vs nonlexical information in both groups and sensory modalities. Using TMS, we further found that, in both groups, the processing of written words and pseudowords was disrupted by the EVC stimulation at both early and late time windows. In contrast, the vOTC stimulation disrupted the processing of these written stimuli only when applied at late time windows, again in both groups. In the speech domain, we observed TMS effects only for meaningful words and only in the blind participants. Overall, our results suggest that, while the responses in the deprived visual areas might extend their functional response to other sensory modalities, the computational gradients between early and higher-order occipital regions are retained, at least for reading.</p>","contentLength":1657,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"\"What\" and \"When\" Predictions Jointly Modulate Speech Processing","url":"http://www.jneurosci.org/cgi/content/short/45/20/e1049242025?rss=1","date":1747240232,"author":"Auksztulewicz, R., O&#x0308;du&#x0308;l, O. B., Helbling, S., Bo&#x0308;ke, A., Cappotto, D., Luo, D., Schnupp, J., Melloni, L.","guid":479,"unread":true,"content":"<p>Adaptive behavior rests on predictions based on statistical regularities in the environment. Such regularities pertain to stimulus contents (\"what\") and timing (\"when\"), and both interactively modulate sensory processing. In speech streams, predictions can be formed at multiple hierarchical levels of contents (e.g., syllables vs words) and timing (faster vs slower time scales). Whether and how these hierarchies map onto each other remains unknown. Under one hypothesis, neural hierarchies may link \"what\" and \"when\" predictions within sensory processing areas: with lower versus higher cortical regions mediating interactions for smaller versus larger units (syllables vs words). Alternatively, interactions between \"what\" and \"when\" regularities might rest on a generic, sensory-independent mechanism. To address these questions, we manipulated \"what\" and \"when\" regularities at two levels—single syllables and disyllabic pseudowords—while recording neural activity using magnetoencephalography (MEG) in healthy volunteers ( = 22). We studied how neural responses to syllable and/or pseudoword deviants are modulated by \"when\" regularity. \"When\" regularity modulated \"what\" mismatch responses with hierarchical specificity, such that responses to deviant pseudowords (vs syllables) were amplified by temporal regularity at slower (vs faster) time scales. However, both these interactive effects were source-localized to the same regions, including frontal and parietal cortices. Effective connectivity analysis showed that the integration of \"what\" and \"when\" regularity selectively modulated connectivity within regions, consistent with gain effects. This suggests that the brain integrates \"what\" and \"when\" predictions that are congruent with respect to their hierarchical level, but this integration is mediated by a shared and distributed cortical network.</p>","contentLength":1870,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null},{"title":"Orbitofrontal High-Gamma Reflects Spike-Dissociable Value and Decision Mechanisms","url":"http://www.jneurosci.org/cgi/content/short/45/20/e0789242025?rss=1","date":1747240232,"author":"Sharma, D., Lupkin, S. M., McGinty, V. B.","guid":480,"unread":true,"content":"<p>The orbitofrontal cortex (OFC) plays a crucial role in value-based decisions. While much is known about how OFC neurons represent values, far less is known about information encoded in OFC local field potentials (LFPs). LFPs are important because they can reflect subthreshold activity not directly coupled to spiking and because they are potential targets for less invasive forms of brain–machine interface (BMI). We recorded neural activity in the OFC of male macaques performing a two-option value-based decision task. We compared the value- and decision-coding properties of high-gamma LFPs (HG, 50–150&nbsp;Hz) to the coding properties of spiking multiunit activity (MUA) recorded concurrently on the same electrodes. HG and MUA both represented the values of decision targets, but HG signals had value-coding features that were distinct from concurrently measured MUA. On average HG amplitude increased monotonically with value, whereas in MUA the value encoding was net neutral on average. HG encoded a signal consistent with a comparison between target values, a signal which was negligible in MUA. In individual channels, HG could predict choice outcomes more accurately than MUA; however, when channels were combined in a population-based decoder, MUA was more accurate than HG. In summary, HG signals reveal value-coding features in OFC that could not be observed from spiking activity, including representation of value comparisons and more accurate behavioral predictions. These results have implications for the role of OFC in value-based decisions and suggest that high-frequency LFPs may be a viable—or even preferable—target for BMIs to assist cognitive function.</p>","contentLength":1684,"flags":null,"enclosureUrl":"","enclosureMime":"","commentsUrl":null}],"tags":["journal","cognitive-neuroscience"]}